#!/usr/bin/env python3
"""
CineCast å¤§æ¨¡å‹å‰§æœ¬é¢„å¤„ç†å™¨
é˜¶æ®µä¸€ï¼šå‰§æœ¬åŒ–ä¸å¾®åˆ‡ç‰‡ (Script & Micro-chunking)
å®ç°å®è§‚å‰§æœ¬è§£æ -> è‡ªåŠ¨å±•å¼€ä¸ºå¾®åˆ‡ç‰‡å‰§æœ¬
"""

import json
import re
import logging
import requests
import os
from typing import List, Dict

logger = logging.getLogger(__name__)

class LLMScriptDirector:
    def __init__(self, ollama_url="http://127.0.0.1:11434", use_local_mlx_lm=False):
        self.api_url = f"{ollama_url}/api/chat"
        self.model_name = "qwen14b-pro"
        self.max_chars_per_chunk = 60 # å¾®åˆ‡ç‰‡çº¢çº¿
        self.use_local_mlx_lm = use_local_mlx_lm
        
        # æµ‹è¯•Ollamaè¿æ¥
        self._test_ollama_connection()
    
    def _test_ollama_connection(self):
        """æµ‹è¯•OllamaæœåŠ¡è¿æ¥"""
        try:
            response = requests.get(f"{self.api_url.replace('/api/chat', '')}/api/tags", timeout=5)
            if response.status_code == 200:
                logger.info("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
                return True
            else:
                logger.warning("âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸")
                return False
        except Exception as e:
            logger.warning(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
            return False
    
    def _try_ollama_qwen(self) -> bool:
        """å°è¯•ä½¿ç”¨Ollamaçš„Qwen14Bæ¨¡å‹"""
        try:
            import subprocess
            result = subprocess.run(
                ["ollama", "list"], 
                capture_output=True, 
                text=True, 
                timeout=10
            )
            
            if result.returncode == 0 and "qwen14b-pro" in result.stdout:
                logger.info("âœ… æˆåŠŸæ£€æµ‹åˆ°æœ¬åœ°Ollama Qwen14Bæ¨¡å‹")
                self.model_type = "ollama"
                self.model_name = "qwen14b-pro"
                return True
            else:
                logger.info("æœªæ‰¾åˆ°Ollama Qwen14Bæ¨¡å‹")
                return False
                
        except Exception as e:
            logger.warning(f"æ£€æŸ¥Ollamaæ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False
    
    def _chunk_text_for_llm(self, text: str, max_length: int = 1500) -> List[str]:
        """ğŸŒŸ é˜²æ­¢ç« èŠ‚è¿‡é•¿ï¼ŒæŒ‰æ®µè½åˆ‡åˆ†ä¸ºå®‰å…¨å¤§å°ç»™ LLM å¤„ç†"""
        paragraphs = text.split('\n')
        chunks, current_chunk = [], ""
        for para in paragraphs:
            if not para.strip(): continue
            if len(current_chunk) + len(para) > max_length and current_chunk:
                chunks.append(current_chunk)
                current_chunk = para + "\n"
            else:
                current_chunk += para + "\n"
        if current_chunk:
            chunks.append(current_chunk)
        return chunks
    
    def parse_and_micro_chunk(self, text: str, chapter_prefix: str = "chunk") -> List[Dict]:
        """å®è§‚å‰§æœ¬è§£æ -> è‡ªåŠ¨å±•å¼€ä¸ºå¾®åˆ‡ç‰‡å‰§æœ¬
        
        Args:
            text: å¾…å¤„ç†çš„ç« èŠ‚æ–‡æœ¬
            chapter_prefix: ç« èŠ‚åç§°å‰ç¼€ï¼Œç”¨äºé¿å…æ–‡ä»¶åå†²çª
        """
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå®è§‚å‰§æœ¬
        macro_script = self.parse_text_to_script(text)
        micro_script = []
        chunk_id = 1
        
        for unit in macro_script:
            # å®æ–½å¾®åˆ‡ç‰‡
            raw_sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€ï¼š])', unit["content"])
            chunks, temp = [], ""
            for part in raw_sentences:
                if not part.strip(): continue
                if re.match(r'^[ã€‚ï¼ï¼Ÿï¼›ï¼Œã€ï¼š]$', part.strip()):
                    chunks.append(temp + part)
                    temp = ""
                else:
                    temp += part
                    if len(temp) >= self.max_chars_per_chunk:
                        chunks.append(temp)
                        temp = ""
            if temp: chunks.append(temp)
            
            # æ¸…ç†ç©ºå—å¹¶è®¡ç®—åœé¡¿
            valid_chunks = [c.strip() for c in chunks if c.strip()]
            for idx, chunk in enumerate(valid_chunks):
                is_para_end = (idx == len(valid_chunks) - 1)
                pause_ms = self._calculate_pause(chunk, is_para_end)
                
                # ğŸŒŸ ä¿®å¤ï¼šå°†ç« èŠ‚åç§°å‰ç¼€åŠ å…¥IDï¼Œæœç»æ–‡ä»¶è¦†ç›–ï¼
                micro_script.append({
                    "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                    "type": unit["type"],
                    "speaker": unit["speaker"],
                    "gender": unit.get("gender", "male"),
                    "content": chunk,
                    "pause_ms": pause_ms
                })
                chunk_id += 1
                
        return micro_script

    def _calculate_pause(self, chunk_text: str, is_para_end: bool) -> int:
        """æå‰è®¡ç®—å¥½ç‰©ç†åœé¡¿æ—¶é—´"""
        if is_para_end: return 1000
        if chunk_text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')): return 600
        elif chunk_text.endswith(('ï¼›', ';')): return 400
        elif chunk_text.endswith(('ï¼Œ', 'ã€', ',', 'ï¼š', ':')): return 250
        else: return 100

    def parse_text_to_script(self, text: str) -> List[Dict]:
        """é˜¶æ®µä¸€ï¼šå®è§‚å‰§æœ¬è§£æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        # ğŸŒŸ ä¿®å¤æˆªæ–­æ¼æ´ï¼šæŒ‰æ®µè½åˆ‡åˆ†é•¿ç« èŠ‚
        text_chunks = self._chunk_text_for_llm(text)
        full_script = []
        
        for i, chunk in enumerate(text_chunks):
            logger.info(f"   ğŸ§  æ­£åœ¨è§£æå‰§æƒ…ç‰‡æ®µ {i+1}/{len(text_chunks)}...")
            chunk_script = self._request_ollama(chunk)
            full_script.extend(chunk_script)
            
        return full_script
    
    def _request_ollama(self, text_chunk: str) -> List[Dict]:
        """å‘Ollamaå‘é€å•ä¸ªæ–‡æœ¬å—è¯·æ±‚"""
        system_prompt = """
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„æœ‰å£°ä¹¦å¯¼æ¼”ã€‚è¯·å°†æä¾›çš„å°è¯´æ–‡æœ¬æ‹†è§£ä¸ºä¸¥æ ¼çš„ JSON æ•°ç»„ã€‚
        ã€å­—æ®µè¦æ±‚ã€‘
        - "type": "title"(æ ‡é¢˜), "subtitle"(å°æ ‡é¢˜), "narration"(æ—ç™½), "dialogue"(å¯¹ç™½)
        - "speaker": æ—ç™½å’Œæ ‡é¢˜å¡« "narrator"ï¼Œå¯¹ç™½å¡«å…·ä½“äººåï¼ˆéœ€æ¨æ–­ï¼Œä¸”ä¸Šä¸‹æ–‡ç»Ÿä¸€ï¼‰ã€‚
        - "gender": "male" æˆ– "female" æˆ– "unknown"ã€‚
        - "content": å°è¯æˆ–æè¿°ï¼Œå»é™¤å¤–å±‚å¼•å·ã€‚
        ã€è¾“å‡ºæ ¼å¼ã€‘åªè¾“å‡ºåˆæ³•çš„ JSON æ•°ç»„ï¼Œä¸åŒ…å«ä»»ä½• Markdown æ ‡è®°ã€‚
        """
        
        payload = {
            "model": self.model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·æ‹†è§£ä»¥ä¸‹å‰§æƒ…ï¼š\n\n{text_chunk}"}
            ],
            "format": "json",
            "stream": False,
            "keep_alive": "10m",  # ğŸŒŸ ä¿®å¤æ½®æ±æ¼æ´ï¼šä¿æŒæ¨¡å‹åœ¨å†…å­˜ä¸­ 10 åˆ†é’Ÿ
            "options": {
                "num_ctx": 8192,  # ğŸŒŸ ä¿®å¤æˆªæ–­æ¼æ´ï¼šæ‰©å¤§ä¸Šä¸‹æ–‡çª—å£
                "temperature": 0.1 # é™ä½æ¸©åº¦ï¼Œç¡®ä¿ JSON æ ¼å¼ç¨³å®š
            }
        }

        try:
            response = requests.post(self.api_url, json=payload, timeout=180)
            response.raise_for_status()
            content = response.json().get('message', {}).get('content', '[]')
            
            # ğŸŒŸ å¼ºåŠ›å‰¥ç¦» Markdown ä»£ç å—ï¼ˆé˜²æ­¢ LLM å¹»è§‰ï¼‰
            content = re.sub(r'^```(?:json)?\s*', '', content.strip(), flags=re.IGNORECASE)
            content = re.sub(r'\s*```$', '', content.strip())
            
            script = json.loads(content)
            if isinstance(script, list):
                return script
            # Handle case where model returns {"result": [...]} or similar wrapper.
            # The first list value found is used since the prompt requests a single array.
            if isinstance(script, dict):
                for value in script.values():
                    if isinstance(value, list) and len(value) > 0 and isinstance(value[0], dict):
                        return value
            return self._fallback_regex_parse(text_chunk)
            
        except Exception as e:
            logger.error(f"âŒ Ollama è§£æå¤±è´¥ï¼Œè§¦å‘æ­£åˆ™é™çº§: {e}")
            return self._fallback_regex_parse(text_chunk)
    
    def _fallback_regex_parse(self, text: str) -> List[Dict]:
        """ğŸŒŸ é™çº§æ­£åˆ™æ–¹æ¡ˆï¼šå½“å¤§æ¨¡å‹è§£æå¤±è´¥æ—¶çš„ä¿åº•æ–¹æ¡ˆ"""
        units = []
        lines = text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æµ‹æ ‡é¢˜ï¼ˆç« èŠ‚æ ‡é¢˜é€šå¸¸è¾ƒçŸ­ä¸”æœ‰ç‰¹å®šæ ¼å¼ï¼‰
            if self._is_title(line):
                units.append({
                    "type": "title", 
                    "speaker": "narrator", 
                    "content": line
                })
            # æ£€æµ‹å¯¹è¯
            elif self._is_dialogue(line):
                speaker, content = self._extract_dialogue_components(line)
                gender = self._predict_gender(speaker)
                units.append({
                    "type": "dialogue", 
                    "speaker": speaker, 
                    "gender": gender, 
                    "content": content
                })
            # é»˜è®¤ä¸ºæ—ç™½
            else:
                units.append({
                    "type": "narration", 
                    "speaker": "narrator", 
                    "content": line
                })
        
        return units
    
    def _is_title(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜"""
        # æ ‡é¢˜ç‰¹å¾ï¼šè¾ƒçŸ­ã€å¯èƒ½åŒ…å«"ç¬¬"ã€"ç« "ç­‰å­—æ ·
        if len(text) < 30 and re.search(r'[ç¬¬ç« èŠ‚å·éƒ¨é›†]', text):
            return True
        # æˆ–è€…å…¨æ˜¯å¤§å†™å­—æ¯ï¼ˆè‹±æ–‡æ ‡é¢˜ï¼‰
        if text.isupper() and len(text) < 50:
            return True
        return False
        
    def _is_dialogue(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¯¹è¯"""
        # åŒ…å«å¼•å·çš„æ–‡æœ¬
        if ('"' in text or '"' in text or 
            'â€œ' in text or 'â€' in text or
            'ã€' in text or 'ã€' in text):
            return True
        return False
        
    def _extract_dialogue_components(self, text: str) -> tuple:
        """æå–å¯¹è¯çš„è¯´è¯äººå’Œå†…å®¹"""
        # å¤„ç†å¸¸è§çš„å¯¹è¯æ ¼å¼
        patterns = [
            r'^(.*?)\s*[:ï¼š"â€œã€Œã€]\s*(.*?)\s*[:ï¼š"â€œã€ã€]$',
            r'^(.*?)\s*[:ï¼š"â€œ]\s*(.*?)(?=\s*[:ï¼š"â€œ]|$)',
            r'^["â€œ](.*?)["â€]\s*[â€”\-]\s*(.*)$',
        ]
            
        for pattern in patterns:
            match = re.match(pattern, text.strip())
            if match:
                groups = match.groups()
                if len(groups) >= 2:
                    speaker = groups[0].strip()
                    content = groups[1].strip()
                    # æ¸…ç†å†…å®¹ä¸­çš„å¼•å·
                    content = re.sub(r'^["â€œâ€ã€ã€ã€Œã€]|["â€œâ€ã€ã€ã€Œã€]$', '', content)
                    return speaker, content
            
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›é»˜è®¤å€¼
        return "æœªçŸ¥è§’è‰²", text
        
    def _predict_gender(self, speaker_name: str) -> str:
        """
        ç®€å•çš„æ€§åˆ«é¢„æµ‹ï¼ˆå¯æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
        """
        # å¸¸è§çš„å¥³æ€§åå­—ç‰¹å¾
        female_indicators = ['å¥³å£«', 'å°å§', 'å¤«äºº', 'å¦ˆå¦ˆ', 'å§å§', 'å¦¹å¦¹', 'å¥³å„¿']
        male_indicators = ['å…ˆç”Ÿ', 'å°‘çˆ·', 'è€çˆ·', 'çˆ¸çˆ¸', 'å“¥å“¥', 'å¼Ÿå¼Ÿ', 'å„¿å­']
            
        # åŸºäºç§°è°“åˆ¤æ–­
        for indicator in female_indicators:
            if indicator in speaker_name:
                return "female"
        for indicator in male_indicators:
            if indicator in speaker_name:
                return "male"
            
        # åŸºäºå¸¸è§å§“ååº“åˆ¤æ–­ï¼ˆç®€åŒ–ç‰ˆï¼‰
        female_names = ['ç›ä¸½', 'ç³è¾¾', 'èŠ­èŠ­æ‹‰', 'ä¼Šä¸½èç™½', 'çå¦®å¼—', 'æå¨œ', 'ç‹èŠ³', 'å¼ ä¸½']
        male_names = ['çº¦ç¿°', 'è¿ˆå…‹å°”', 'å¤§å«', 'ç½—ä¼¯ç‰¹', 'è©¹å§†æ–¯', 'ææ˜', 'ç‹å¼º', 'å¼ ä¼Ÿ']
            
        for name in female_names:
            if name in speaker_name:
                return "female"
        for name in male_names:
            if name in speaker_name:
                return "male"
            
        # é»˜è®¤è¿”å›ç”·æ€§ï¼ˆå¯æ ¹æ®ç»Ÿè®¡æ•°æ®è°ƒæ•´ï¼‰
        return "male"

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    director = LLMScriptDirector()
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
ç¬¬ä¸€ç«  å‡¯å¤«æ‹‰ç»´å…‹çš„é£é›ª

å¤œå¹•é™ä¸´ï¼Œæ¸¯å£çš„ç¯ç«å¼€å§‹é—ªçƒã€‚

"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ"è€æ¸”å¤«è¯´é“ã€‚

å¹´è½»äººæ‘‡æ‘‡å¤´ï¼š"æˆ‘åªç›¸ä¿¡æµ·ã€‚"

è¿œå¤„ä¼ æ¥æ±½ç¬›å£°ï¼Œåˆ’ç ´äº†å¯‚é™çš„å¤œç©ºã€‚
"""
    
    script = director.parse_text_to_script(test_text)
    print("è§£æç»“æœ:")
    for i, unit in enumerate(script, 1):
        print(f"{i}. {unit}")