#!/usr/bin/env python3
"""
CineCast å¤§æ¨¡å‹å‰§æœ¬é¢„å¤„ç†å™¨
é˜¶æ®µä¸€ï¼šå‰§æœ¬åŒ–ä¸å¾®åˆ‡ç‰‡ (Script & Micro-chunking)
å®ç°å®è§‚å‰§æœ¬è§£æ -> è‡ªåŠ¨å±•å¼€ä¸ºå¾®åˆ‡ç‰‡å‰§æœ¬
"""

import json
import re
import logging
import requests
import os
import tempfile
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)


def atomic_json_write(path: str, data, **kwargs) -> None:
    """Atomic JSON write: write to a temporary file first, then replace.

    This prevents JSON corruption if the process crashes mid-write.
    """
    dir_name = os.path.dirname(path) or "."
    kwargs.setdefault("ensure_ascii", False)
    kwargs.setdefault("indent", 2)
    fd, tmp_path = tempfile.mkstemp(suffix=".tmp", dir=dir_name)
    try:
        with os.fdopen(fd, "w", encoding="utf-8") as f:
            json.dump(data, f, **kwargs)
        os.replace(tmp_path, path)
    except BaseException:
        try:
            os.unlink(tmp_path)
        except OSError:
            pass
        raise


def repair_json_array(raw: str) -> Optional[List[Dict]]:
    """Attempt to repair a truncated or malformed JSON array.

    Tries progressively more aggressive strategies:
    1. Strip trailing garbage after the last ``}`` and close the array.
    2. Use regex to salvage individual JSON objects.

    Returns ``None`` if nothing can be recovered.
    """
    # Strategy 1: find last complete object and close the array
    raw = raw.strip()
    if raw.startswith("["):
        last_brace = raw.rfind("}")
        if last_brace > 0:
            candidate = raw[: last_brace + 1].rstrip().rstrip(",") + "\n]"
            try:
                result = json.loads(candidate)
                if isinstance(result, list) and result:
                    return result
            except json.JSONDecodeError:
                pass

    # Strategy 2: regex salvage individual entries
    return salvage_json_entries(raw)


def salvage_json_entries(raw: str) -> Optional[List[Dict]]:
    """Use regex to extract valid script entries from broken JSON text.

    Each entry is expected to have at least ``speaker`` and ``content`` fields.
    """
    pattern = re.compile(
        r'\{\s*'
        r'"(?:type)"\s*:\s*"([^"]*)"\s*,\s*'
        r'"(?:speaker)"\s*:\s*"([^"]*)"\s*,\s*'
        r'"(?:gender)"\s*:\s*"([^"]*)"\s*,\s*'
        r'"(?:emotion|instruct)"\s*:\s*"([^"]*)"\s*,\s*'
        r'"(?:content)"\s*:\s*"([^"]*)"',
        re.DOTALL,
    )
    entries = []
    for m in pattern.finditer(raw):
        entries.append({
            "type": m.group(1) or "narration",
            "speaker": m.group(2) or "narrator",
            "gender": m.group(3) or "unknown",
            "emotion": m.group(4) or "å¹³é™",
            "content": m.group(5) or "",
        })

    if not entries:
        # Looser pattern: just find speaker + content
        loose = re.compile(
            r'"speaker"\s*:\s*"([^"]*)"\s*[,}].*?"content"\s*:\s*"([^"]*)"',
            re.DOTALL,
        )
        for m in loose.finditer(raw):
            entries.append({
                "type": "narration",
                "speaker": m.group(1) or "narrator",
                "gender": "unknown",
                "emotion": "å¹³é™",
                "content": m.group(2) or "",
            })

    return entries if entries else None


def merge_consecutive_narrators(script: List[Dict], max_chars: int = 800) -> List[Dict]:
    """Merge consecutive narrator entries that share the same emotion.

    This reduces TTS startup overhead and avoids fragmented short sentences
    that cause jarring tonal shifts.
    """
    if not script:
        return script

    merged: List[Dict] = []
    for entry in script:
        if (
            merged
            and entry.get("speaker") == "narrator"
            and merged[-1].get("speaker") == "narrator"
            and entry.get("emotion", "å¹³é™") == merged[-1].get("emotion", "å¹³é™")
            and entry.get("type") == merged[-1].get("type")
            and len(merged[-1].get("content", "")) + len(entry.get("content", "")) <= max_chars
        ):
            merged[-1]["content"] = merged[-1]["content"] + entry["content"]
            # Keep the longer pause
            merged[-1]["pause_ms"] = max(
                merged[-1].get("pause_ms", 0), entry.get("pause_ms", 0)
            )
        else:
            merged.append(entry.copy())

    return merged

class LLMScriptDirector:
    def __init__(self, ollama_url="http://127.0.0.1:11434", use_local_mlx_lm=False, global_cast=None):
        self.api_url = f"{ollama_url}/api/chat"
        self.model_name = "qwen14b-pro"
        self.max_chars_per_chunk = 60 # å¾®åˆ‡ç‰‡çº¢çº¿ï¼ˆæ™ºèƒ½é…éŸ³æ¨¡å¼ï¼‰
        self.pure_narrator_chunk_limit = 100  # çº¯å‡€æ—ç™½æ¨¡å¼åˆ‡ç‰‡ä¸Šé™ï¼ˆæ›´é•¿æ›´æµç•…ï¼‰
        self.use_local_mlx_lm = use_local_mlx_lm
        self.global_cast = global_cast or {}  # ğŸŒŸ å¤–è„‘å…¨å±€è§’è‰²è®¾å®šé›†
        
        # Context sliding window state
        self._prev_characters: List[str] = []
        self._prev_tail_entries: List[Dict] = []
        
        # æµ‹è¯•Ollamaè¿æ¥
        self._test_ollama_connection()
    
    def _test_ollama_connection(self):
        """æµ‹è¯•OllamaæœåŠ¡è¿æ¥"""
        try:
            response = requests.get(f"{self.api_url.replace('/api/chat', '')}/api/tags", timeout=5)
            if response.status_code == 200:
                logger.info("âœ… OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
                return True
            else:
                logger.warning("âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸")
                return False
        except Exception as e:
            logger.warning(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
            return False
    
    def _try_ollama_qwen(self) -> bool:
        """å°è¯•ä½¿ç”¨Ollamaçš„Qwen14Bæ¨¡å‹"""
        try:
            import subprocess
            result = subprocess.run(
                ["ollama", "list"], 
                capture_output=True, 
                text=True, 
                timeout=10
            )
            
            if result.returncode == 0 and "qwen14b-pro" in result.stdout:
                logger.info("âœ… æˆåŠŸæ£€æµ‹åˆ°æœ¬åœ°Ollama Qwen14Bæ¨¡å‹")
                self.model_type = "ollama"
                self.model_name = "qwen14b-pro"
                return True
            else:
                logger.info("æœªæ‰¾åˆ°Ollama Qwen14Bæ¨¡å‹")
                return False
                
        except Exception as e:
            logger.warning(f"æ£€æŸ¥Ollamaæ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False
    
    def _chunk_text_for_llm(self, text: str, max_length: int = 800) -> List[str]:
        """ğŸŒŸ é˜²æ­¢ç« èŠ‚è¿‡é•¿ï¼ŒæŒ‰æ®µè½åˆ‡åˆ†ä¸ºå®‰å…¨å¤§å°ç»™ LLM å¤„ç†"""
        paragraphs = text.split('\n')
        chunks, current_chunk = [], ""
        for para in paragraphs:
            if not para.strip(): continue
            if len(current_chunk) + len(para) > max_length and current_chunk:
                chunks.append(current_chunk)
                current_chunk = para + "\n"
            else:
                current_chunk += para + "\n"
        if current_chunk:
            chunks.append(current_chunk)
        return chunks

    def verify_integrity(self, original_text: str, script_list: List[Dict]) -> bool:
        """ğŸŒŸ å†…å®¹å®Œæ•´æ€§æ ¡éªŒï¼šæ£€æµ‹ LLM è§£ææ˜¯å¦ä¸¥é‡ä¸¢å¤±å†…å®¹

        å¯¹æ¯”åŸæ–‡æ€»å­—æ•°ä¸å‰§æœ¬ content æ€»å­—æ•°ï¼Œå¦‚æœä¸¢å¤±è¶…è¿‡ 10% åˆ™æŠ¥é”™ã€‚

        Args:
            original_text: åŸå§‹è¾“å…¥æ–‡æœ¬
            script_list: LLM è§£æåçš„å‰§æœ¬åˆ—è¡¨

        Returns:
            True è¡¨ç¤ºå†…å®¹å®Œæ•´æ€§è¾¾æ ‡ï¼ŒFalse è¡¨ç¤ºå†…å®¹ä¸¢å¤±ä¸¥é‡
        """
        if not original_text or not script_list:
            return True
        content_text = "".join([item.get("content", "") for item in script_list])
        original_len = len(original_text.strip())
        if original_len == 0:
            return True
        ratio = len(content_text) / original_len
        if ratio < 0.9:
            logger.error(
                f"ğŸš¨ å†…å®¹ä¸¢å¤±ä¸¥é‡ï¼åŸæ–‡{original_len}å­—ï¼Œ"
                f"è§£æåä»…{len(content_text)}å­— (ä¿ç•™ç‡{ratio:.1%})"
            )
            return False
        logger.info(f"âœ… å†…å®¹å®Œæ•´æ€§æ ¡éªŒé€šè¿‡ (ä¿ç•™ç‡{ratio:.1%})")
        return True
    
    def generate_pure_narrator_script(self, text: str, chapter_prefix: str = "chunk") -> List[Dict]:
        """
        çº¯å‡€æ—ç™½æ¨¡å¼ä¸“ç”¨çš„å‰§æœ¬ç”Ÿæˆå™¨ï¼ˆç»•è¿‡LLMï¼Œç§’çº§ç”Ÿæˆï¼Œ100%å¿ å®åŸè‘—ï¼‰
        çº¯å‡€æ—ç™½æ¨¡å¼ä¸‹ï¼Œåˆ‡ç‰‡é•¿åº¦æ”¾å®½åˆ° 100 å­—å·¦å³ï¼Œå‡å°‘åˆ‡ç‰‡æ•°é‡ï¼Œæå‡æœ—è¯»æµç•…åº¦ã€‚
        """
        micro_script = []
        chunk_id = 1

        # ğŸŒŸ çº¯å‡€æ—ç™½æ¨¡å¼ä¸‹ï¼Œåˆ‡ç‰‡ä¸Šé™æ”¾å®½åˆ° ~100 å­—
        pure_chunk_limit = self.pure_narrator_chunk_limit

        # 1. æŒ‰æ®µè½åˆ‡åˆ†
        paragraphs = [p.strip() for p in text.split('\n') if p.strip()]

        for p_idx, para in enumerate(paragraphs):
            # 2. æŒ‰é•¿å¥æ ‡ç‚¹åˆ‡åˆ†ï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰
            sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›.!?;])', para)

            temp_sentence = ""
            for part in sentences:
                if not part.strip() and not re.match(r'[ã€‚ï¼ï¼Ÿï¼›.!?;]', part):
                    continue

                if re.match(r'^[ã€‚ï¼ï¼Ÿï¼›.!?;]$', part.strip()):
                    temp_sentence += part

                    # 3. å¦‚æœå•å¥ä»ç„¶è¶…é•¿ï¼Œå¯åŠ¨é€—å·/é¡¿å·çš„æ¬¡çº§åˆ‡åˆ†
                    if len(temp_sentence) > pure_chunk_limit:
                        sub_parts = re.split(r'([ï¼Œã€ï¼š,:])', temp_sentence)
                        sub_temp = ""
                        for sub in sub_parts:
                            if re.match(r'^[ï¼Œã€ï¼š,:]$', sub):
                                sub_temp += sub
                                pause = self._calculate_pause(sub_temp, False)
                                micro_script.append({
                                    "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                                    "type": "narration",
                                    "speaker": "narrator",
                                    "gender": "male",
                                    "emotion": "å¹³é™",
                                    "content": sub_temp.strip(),
                                    "pause_ms": pause
                                })
                                chunk_id += 1
                                sub_temp = ""
                            else:
                                sub_temp += sub
                        if sub_temp.strip():
                            pause = self._calculate_pause(sub_temp, p_idx == len(paragraphs)-1)
                            micro_script.append({
                                "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                                "type": "narration",
                                "speaker": "narrator",
                                "gender": "male",
                                "emotion": "å¹³é™",
                                "content": sub_temp.strip(),
                                "pause_ms": pause
                            })
                            chunk_id += 1
                    else:
                        # æ­£å¸¸é•¿åº¦çš„å¥å­ç›´æ¥æ¨å…¥
                        pause = self._calculate_pause(temp_sentence, p_idx == len(paragraphs)-1)
                        micro_script.append({
                            "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                            "type": "narration",
                            "speaker": "narrator",
                            "gender": "male",
                            "emotion": "å¹³é™",
                            "content": temp_sentence.strip(),
                            "pause_ms": pause
                        })
                        chunk_id += 1
                    temp_sentence = ""
                else:
                    temp_sentence += part

            # å¤„ç†æ®µè½æœ«å°¾æ²¡æœ‰æ ‡ç‚¹çš„æ®‹ç•™éƒ¨åˆ†
            if temp_sentence.strip():
                pause = self._calculate_pause(temp_sentence, p_idx == len(paragraphs)-1)
                micro_script.append({
                    "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                    "type": "narration",
                    "speaker": "narrator",
                    "gender": "male",
                    "emotion": "å¹³é™",
                    "content": temp_sentence.strip(),
                    "pause_ms": pause
                })
                chunk_id += 1

        return micro_script

    def parse_and_micro_chunk(self, text: str, chapter_prefix: str = "chunk") -> List[Dict]:
        """å®è§‚å‰§æœ¬è§£æ -> è‡ªåŠ¨å±•å¼€ä¸ºå¾®åˆ‡ç‰‡å‰§æœ¬
        
        Args:
            text: å¾…å¤„ç†çš„ç« èŠ‚æ–‡æœ¬
            chapter_prefix: ç« èŠ‚åç§°å‰ç¼€ï¼Œç”¨äºé¿å…æ–‡ä»¶åå†²çª
        """
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå®è§‚å‰§æœ¬
        macro_script = self.parse_text_to_script(text)
        micro_script = []
        chunk_id = 1
        
        for unit in macro_script:
            content = unit.get("content", "")
            if not content or not content.strip():
                continue

            # å®æ–½å¾®åˆ‡ç‰‡
            raw_sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€ï¼š])', content)
            chunks, temp = [], ""
            for part in raw_sentences:
                if not part.strip(): continue
                if re.match(r'^[ã€‚ï¼ï¼Ÿï¼›ï¼Œã€ï¼š]$', part.strip()):
                    chunks.append(temp + part)
                    temp = ""
                else:
                    temp += part
                    if len(temp) >= self.max_chars_per_chunk:
                        chunks.append(temp)
                        temp = ""
            if temp: chunks.append(temp)
            
            # æ¸…ç†ç©ºå—å¹¶è®¡ç®—åœé¡¿
            valid_chunks = [c.strip() for c in chunks if c.strip()]

            # ğŸŒŸ å…œåº•é€»è¾‘ï¼šå¦‚æœæ­£åˆ™åˆ‡åˆ†åæ— æœ‰æ•ˆå—ï¼ŒæŒ‰æ¯60å­—ç¡¬åˆ‡
            if not valid_chunks and content.strip():
                hard_cut_chunk_size = self.max_chars_per_chunk
                stripped = content.strip()
                valid_chunks = [
                    stripped[i:i + hard_cut_chunk_size]
                    for i in range(0, len(stripped), hard_cut_chunk_size)
                ]
                logger.warning(
                    f"âš ï¸ æ­£åˆ™åˆ‡åˆ†æ— ç»“æœï¼Œå·²æŒ‰æ¯{hard_cut_chunk_size}å­—ç¡¬åˆ‡: "
                    f"'{content[:30]}...'"
                )

            for idx, chunk in enumerate(valid_chunks):
                is_para_end = (idx == len(valid_chunks) - 1)
                pause_ms = self._calculate_pause(chunk, is_para_end)
                
                # ğŸŒŸ ä¿®å¤ï¼šå°†ç« èŠ‚åç§°å‰ç¼€åŠ å…¥IDï¼Œæœç»æ–‡ä»¶è¦†ç›–ï¼
                micro_script.append({
                    "chunk_id": f"{chapter_prefix}_{chunk_id:05d}",
                    "type": unit["type"],
                    "speaker": unit["speaker"],
                    "gender": unit.get("gender", "male"),
                    "content": chunk,
                    "pause_ms": pause_ms
                })
                chunk_id += 1
                
        return micro_script

    def _calculate_pause(self, chunk_text: str, is_para_end: bool) -> int:
        """æå‰è®¡ç®—å¥½ç‰©ç†åœé¡¿æ—¶é—´"""
        if is_para_end: return 1000
        if chunk_text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')): return 600
        elif chunk_text.endswith(('ï¼›', ';')): return 400
        elif chunk_text.endswith(('ï¼Œ', 'ã€', ',', 'ï¼š', ':')): return 250
        else: return 100

    def parse_text_to_script(self, text: str) -> List[Dict]:
        """é˜¶æ®µä¸€ï¼šå®è§‚å‰§æœ¬è§£æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        
        Implements a context sliding window: each chunk receives the previous
        chunk's cast list and last three entries as context so that character
        names and speaking styles stay consistent across slices.
        """
        # ğŸŒŸ ä¿®å¤æˆªæ–­æ¼æ´ï¼šæŒ‰æ®µè½åˆ‡åˆ†é•¿ç« èŠ‚
        text_chunks = self._chunk_text_for_llm(text)
        full_script = []
        
        for i, chunk in enumerate(text_chunks):
            logger.info(f"   ğŸ§  æ­£åœ¨è§£æå‰§æƒ…ç‰‡æ®µ {i+1}/{len(text_chunks)}...")
            
            # Build context from previous chunk
            context_parts: List[str] = []
            if self._prev_characters:
                context_parts.append(
                    "å‰ä¸€æ®µå‡ºåœºè§’è‰²: " + ", ".join(self._prev_characters)
                )
            if self._prev_tail_entries:
                try:
                    tail_json = json.dumps(
                        self._prev_tail_entries, ensure_ascii=False
                    )
                    context_parts.append(
                        "\nPrevious section ended with:\n" + tail_json
                    )
                except Exception:
                    pass
            
            chunk_script = self._request_ollama(chunk, context="\n".join(context_parts) if context_parts else None)
            
            # Update sliding window state
            if chunk_script:
                speakers = {
                    e.get("speaker")
                    for e in chunk_script
                    if e.get("speaker") and e.get("speaker") != "narrator"
                }
                if speakers:
                    self._prev_characters = list(speakers)
                self._prev_tail_entries = chunk_script[-3:]
            
            full_script.extend(chunk_script)
        
        # ğŸŒŸ ä¼˜åŒ–ï¼šç§»é™¤ merge_consecutive_narrators è°ƒç”¨ã€‚
        # å› ä¸º parse_and_micro_chunk ä¼šå¯¹ç»“æœè¿›è¡Œä¸¥æ ¼çš„ 60 å­—å¾®åˆ‡ç‰‡ï¼Œ
        # åˆå¹¶åçš„ 800 å­—é•¿æ–‡æœ¬ä¼šè¢«ç«‹å³ç¢¾ç¢ï¼Œå±äºæ— è°“çš„ç®—åŠ›æµªè´¹ã€‚
        
        # å¦‚æœè§£æç»“æœä¸ºç©ºï¼Œç›´æ¥æŠ¥é”™é€€å‡º
        if not full_script or len(full_script) == 0:
            raise RuntimeError("âŒ å‰§æœ¬è§£æç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡æœ¬å’Œå¤§æ¨¡å‹æœåŠ¡æ˜¯å¦æ­£å¸¸ã€‚")

        # ğŸŒŸ å†…å®¹å®Œæ•´æ€§å®ˆé—¨å‘˜ï¼šæ£€æµ‹ LLM æ˜¯å¦ä¸¥é‡åˆ èŠ‚å†…å®¹
        self.verify_integrity(text, full_script)
            
        return full_script
    
    def generate_chapter_recap(self, prev_chapter_text: str) -> str:
        """
        ğŸŒŸ Map-Reduce å‰æƒ…æ‘˜è¦å¼•æ“
        è§£å†³é•¿ç« èŠ‚å¯¼è‡´å¤§æ¨¡å‹ OOM æˆ–æ³¨æ„åŠ›ä¸¢å¤±çš„é—®é¢˜
        - çŸ­æ–‡æœ¬ (<=5000å­—): ç›´æ¥ç”Ÿæˆç»ˆææ‘˜è¦
        - é•¿æ–‡æœ¬ (>5000å­—): åˆ†å—æç‚¼ -> åˆå¹¶ -> ç»ˆææ‘˜è¦
        """
        chunk_size = 5000

        # 1. åŸºç¡€æ¸…ç†
        text = prev_chapter_text.strip()
        if not text:
            return ""

        # 2. å¦‚æœæ–‡æœ¬æé•¿ï¼Œæ‰§è¡Œ Map é˜¶æ®µ (åˆ†å—æ€»ç»“)
        if len(text) > chunk_size:
            logger.info(f"ğŸ”„ ä¸Šä¸€ç« è¶…é•¿ ({len(text)}å­—)ï¼Œå¯åŠ¨ Map-Reduce æ‘˜è¦åˆ†å—å¤„ç†...")
            chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]
            sub_summaries = []

            for idx, chunk in enumerate(chunks):
                map_prompt = ("ä½ æ˜¯ä¸€ä¸ªå‰§æƒ…æç‚¼ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹å°è¯´ç‰‡æ®µå‹ç¼©æˆä¸è¶…è¿‡200å­—çš„çº¯å‰§æƒ…æ‘˜è¦ã€‚"
                              "è¦æ±‚ï¼šåªä¿ç•™æ ¸å¿ƒå†²çªã€å…³é”®äººç‰©åŠ¨ä½œå’Œé‡è¦çº¿ç´¢ã€‚ä¸åŠ ä»»ä½•å‰ç¼€å’ŒåºŸè¯ã€‚")

                payload = {
                    "model": self.model_name,
                    "messages": [
                        {"role": "system", "content": map_prompt},
                        {"role": "user", "content": f"å°è¯´ç‰‡æ®µï¼š\n{chunk}"}
                    ],
                    "stream": False,
                    "options": {"temperature": 0.3}
                }
                try:
                    resp = requests.post(self.api_url, json=payload, timeout=120)
                    resp.raise_for_status()
                    sub_sum = resp.json().get('message', {}).get('content', '').strip()
                    sub_summaries.append(sub_sum)
                    logger.debug(f"   âœ“ å®Œæˆç¬¬ {idx+1}/{len(chunks)} å—æç‚¼")
                except Exception as e:
                    logger.warning(f"åŒºå— {idx+1} æ€»ç»“å¤±è´¥ï¼Œå·²è·³è¿‡: {e}")

            # ç»„åˆæ‰€æœ‰å­æ‘˜è¦ä½œä¸º Reduce é˜¶æ®µçš„è¾“å…¥
            final_input = "\n".join(sub_summaries)
        else:
            final_input = text

        # 3. Reduce é˜¶æ®µ (ç»ˆææ‘˜è¦ + æ‚¬å¿µé’©å­)
        reduce_prompt = (
            'ä½ æ˜¯ä¸€ä½é¡¶çº§çš„æœ‰å£°ä¹¦å‰§æœ¬ç¼–è¾‘å’Œæ‚¬ç–‘å¤§å¸ˆã€‚'
            'è¯·æ ¹æ®æä¾›çš„ä¸Šä¸€ç« å†…å®¹ï¼ˆæˆ–å†…å®¹æ‘˜è¦ï¼‰ï¼Œå†™ä¸€æ®µä¸è¶…è¿‡100å­—çš„\u201cå‰æƒ…æ‘˜è¦\u201dã€‚'
            'ç»å¯¹çºªå¾‹ï¼š'
            '1. è¯­è¨€å¿…é¡»é«˜åº¦å‡ç»ƒï¼Œå…·æœ‰ç¾å‰§ç‰‡å¤´çš„ç”µå½±æ„Ÿï¼ˆ\u201cPreviously on...\u201dçš„é£æ ¼ï¼‰ã€‚'
            '2. åªä¿ç•™æœ€å…·å¼ åŠ›çš„å‰§æƒ…çŸ›ç›¾ã€‚'
            '3. æœ€åä¸€å¥å¿…é¡»æ˜¯ä¸€ä¸ªå¼•å‡ºä¸‹ä¸€ç« çš„\u201cæ‚¬å¿µé’©å­\u201dã€‚'
            '4. ç»å¯¹ä¸è¦è¾“å‡º\u201cå‰æƒ…æè¦ï¼š\u201dè¿™æ ·çš„æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºæ­£æ–‡ã€‚'
        )

        payload = {
            "model": self.model_name,
            "messages": [
                {"role": "system", "content": reduce_prompt},
                {"role": "user", "content": f"ä¸Šä¸€ç« å†…å®¹ï¼š\n{final_input}"}
            ],
            "stream": False,
            "options": {"temperature": 0.5, "top_p": 0.8}
        }

        try:
            response = requests.post(self.api_url, json=payload, timeout=180)
            response.raise_for_status()
            recap_result = response.json().get('message', {}).get('content', '').strip()

            # æ¸…ç†å¤§æ¨¡å‹å¯èƒ½è¿è§„åŠ ä¸Šçš„å‰ç¼€
            recap_result = re.sub(r'^(å‰æƒ…æè¦|å‰æƒ…æ‘˜è¦|å›é¡¾|æ‘˜è¦)[:ï¼š]\s*', '', recap_result)
            return recap_result
        except Exception as e:
            logger.error(f"ç»ˆææ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _request_ollama(self, text_chunk: str, *, context: Optional[str] = None) -> List[Dict]:
        """å‘Ollamaå‘é€å•ä¸ªæ–‡æœ¬å—è¯·æ±‚

        Args:
            text_chunk: The raw text to convert into a script.
            context: Optional sliding-window context from the previous chunk
                     (character list + tail entries) to maintain consistency.
        """
        system_prompt = """
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„æœ‰å£°ä¹¦å¯¼æ¼”å…¼æ•°æ®æ¸…æ´—ä¸“å®¶ï¼Œè´Ÿè´£å°†åŸå§‹å°è¯´æ–‡æœ¬è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„å½•éŸ³å‰§æœ¬ã€‚
        ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹å››å¤§çºªå¾‹ï¼Œä»»ä½•è¿åéƒ½å°†å¯¼è‡´ç³»ç»Ÿå´©æºƒï¼š

        ã€ä¸€ã€ ç»å¯¹å¿ å®åŸåˆ™ï¼ˆIron Ruleï¼‰ã€‘
        - å¿…é¡» 100% é€å­—ä¿ç•™åŸæ–‡å†…å®¹ï¼
        - ä¸¥ç¦ä»»ä½•å½¢å¼çš„æ¦‚æ‹¬ã€æ”¹å†™ã€ç¼©å†™ã€ç»­å†™æˆ–æ¶¦è‰²ï¼
        - ä¸¥ç¦è‡ªè¡Œæ·»åŠ åŸæ–‡ä¸­ä¸å­˜åœ¨çš„å°è¯æˆ–åŠ¨ä½œæå†™ï¼
        - ä¸¥ç¦åœ¨ content ä¸­ä¿ç•™å½’å±æ ‡ç­¾ï¼ˆå¦‚"ä»–è¯´"ã€"å¥¹å«é“"ï¼‰ï¼Œå½’å±ä¿¡æ¯åªèƒ½å‡ºç°åœ¨ speaker å­—æ®µï¼
        - ä¸¥ç¦æ€»ç»“å…¨æ–‡ï¼Œå¿…é¡»ä»ç¬¬ä¸€å¥è¯å¼€å§‹é€å¥æ‹†è§£ã€‚ä¸¥ç¦è¾“å‡ºç« èŠ‚åç§°ä½œä¸ºå”¯ä¸€å†…å®¹ï¼
        - ä¸¥ç¦æ¼æ‰ä»»ä½•ä¸€ä¸ªè‡ªç„¶æ®µï¼å¦‚æœå‘ç°å†…å®¹ç¼ºå¤±ï¼Œç³»ç»Ÿå°†åˆ¤å®šä»»åŠ¡å¤±è´¥å¹¶é‡è¯•ï¼

        ã€äºŒã€ å­—ç¬¦å‡€åŒ–åŸåˆ™ã€‘
        - å‰”é™¤æ‰€æœ‰ä¸å¯å‘éŸ³çš„ç‰¹æ®Šç¬¦å·ï¼ˆå¦‚ Emojiè¡¨æƒ…ã€Markdownæ ‡è®° * _ ~ #ã€åˆ¶è¡¨ç¬¦ \tã€ä¸å¯è§æ§åˆ¶å­—ç¬¦ï¼‰ã€‚
        - ä»…ä¿ç•™åŸºç¡€æ ‡ç‚¹ç¬¦å·ï¼ˆï¼Œã€‚ï¼ï¼Ÿï¼šï¼›ã€""''ï¼ˆï¼‰ï¼‰ã€‚
        - æ•°å­—ã€è‹±æ–‡å­—æ¯å…è®¸ä¿ç•™ï¼Œä½†ç¦æ­¢å‡ºç°å¤æ‚çš„æ•°å­¦å…¬å¼ç¬¦å·ã€‚

        ã€ä¸‰ã€ ç²’åº¦æ‹†åˆ†åŸåˆ™ã€‘
        - å¿…é¡»å°†"å¯¹ç™½"å’Œ"æ—ç™½/åŠ¨ä½œæå†™"ä¸¥æ ¼å‰¥ç¦»ä¸ºç‹¬ç«‹çš„å¯¹è±¡ï¼
        - ä¾‹å¦‚åŸæ–‡ï¼š"ä½ å¥½ï¼Œ"è€æ¸”å¤«ç¬‘ç€è¯´ã€‚
          å¿…é¡»æ‹†åˆ†ä¸ºä¸¤ä¸ªå¯¹è±¡ï¼š1. è§’è‰²å¯¹ç™½("ä½ å¥½ï¼Œ") 2. æ—ç™½æè¿°("è€æ¸”å¤«ç¬‘ç€è¯´ã€‚")

        ã€å››ã€ JSON æ ¼å¼è§„èŒƒï¼ˆç”Ÿæ­»æ”¸å…³ï¼‰ã€‘
        å¿…é¡»ä¸”åªèƒ½è¾“å‡ºåˆæ³•çš„ JSON æ•°ç»„ï¼ˆArrayï¼‰ï¼
        æœ€å¤–å±‚å¿…é¡»æ˜¯ä¸­æ‹¬å· [ ]ï¼Œç»å¯¹ä¸èƒ½æ˜¯å¤§æ‹¬å· { }ï¼
        ä¸¥ç¦å°†æ•´ä¸ªç« èŠ‚åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„ JSON å¯¹è±¡ï¼ä½ å¿…é¡»å°†æ–‡æœ¬é€å¥æ‹†è§£ä¸ºå¤šä¸ªæ•°ç»„å…ƒç´ ï¼
        ç¦æ­¢ä»»ä½•è§£é‡Šæ€§å‰è¨€æˆ–åç¼€ï¼Œç¦æ­¢è¾“å‡º Markdown ä»£ç å—æ ‡è®°ï¼ˆ```jsonï¼‰ã€‚
        æ•°ç»„å…ƒç´ å­—æ®µè¦æ±‚ï¼š
        - "type": ä»…é™ "title"(ç« èŠ‚å), "subtitle"(å°æ ‡é¢˜), "narration"(æ—ç™½), "dialogue"(å¯¹ç™½)ã€‚
        - "speaker": å¯¹ç™½å¡«å…·ä½“çš„è§’è‰²åï¼ˆéœ€æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­å¹¶ä¿æŒå…¨ä¹¦ç»Ÿä¸€ï¼‰ï¼›æ—ç™½å’Œæ ‡é¢˜ç»Ÿä¸€å¡« "narrator"ã€‚
        - "gender": ä»…é™ "male"ã€"female" æˆ– "unknown"ã€‚å¯¹ç™½è¯·æ¨æµ‹æ€§åˆ«ï¼›æ—ç™½å›ºå®šä¸º "male"ã€‚
        - "emotion": æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¦‚"å¹³é™"ã€"æ¿€åŠ¨"ã€"æ²§æ¡‘/å¹æ¯"ã€"æ„¤æ€’"ã€"æ‚²ä¼¤"ç­‰ï¼‰ï¼Œç”¨äºæœªæ¥è¯­éŸ³åˆæˆçš„æƒ…æ„Ÿæ§åˆ¶ã€‚
        - "content": çº¯å‡€çš„æ–‡æœ¬å†…å®¹ã€‚å¦‚æœ type æ˜¯ "dialogue"ï¼Œå¿…é¡»å»æ‰æœ€å¤–å±‚çš„å¼•å·ï¼ˆå¦‚""æˆ–""ï¼‰ã€‚

        ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼ˆOne-Shotï¼‰ã€‘
        [
          {
            "type": "narration",
            "speaker": "narrator",
            "gender": "male",
            "emotion": "å¹³é™",
            "content": "å¤œå¹•é™ä¸´ï¼Œæ¸¯å£çš„ç¯ç«å¼€å§‹é—ªçƒã€‚"
          },
          {
            "type": "dialogue",
            "speaker": "è€æ¸”å¤«",
            "gender": "male",
            "emotion": "æ²§æ¡‘/å¹æ¯",
            "content": "ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ"
          },
          {
            "type": "narration",
            "speaker": "narrator",
            "gender": "male",
            "emotion": "å¹³é™",
            "content": "è€æ¸”å¤«è¯´é“ã€‚"
          }
        ]
        """

        # ğŸŒŸ å…¨å±€é€‰è§’çºªå¾‹æ³¨å…¥ï¼šå¦‚æœæœ‰å¤–è„‘æä¾›çš„è§’è‰²ç™½åå•ï¼Œè¿½åŠ åˆ° system_prompt
        if self.global_cast:
            cast_names = list(self.global_cast.keys())
            cast_info_parts = []
            for name, info in self.global_cast.items():
                if isinstance(info, dict):
                    g = info.get("gender", "unknown")
                    cast_info_parts.append(f'"{name}"(gender={g})')
                else:
                    cast_info_parts.append(f'"{name}"')
            cast_listing = ", ".join(cast_info_parts)
            system_prompt += f"""

        ã€å…¨å±€é€‰è§’çºªå¾‹ï¼ˆCast Whitelistï¼‰ã€‘
        - ä»¥ä¸‹æ˜¯æœ¬ä¹¦çš„å®˜æ–¹è§’è‰²åå•ï¼ˆæ ‡å‡†åï¼‰ï¼š{cast_listing}
        - ä½ åœ¨ speaker å­—æ®µä¸­ä½¿ç”¨çš„è§’è‰²åï¼Œå¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä¸Šè¿°æ ‡å‡†åï¼
        - ä¸¥ç¦è‡ªè¡Œå‘æ˜æˆ–ä½¿ç”¨ä»»ä½•ä¸åœ¨åå•ä¸­çš„è§’è‰²åï¼
        - å¦‚æœé‡åˆ°åå•å¤–çš„é¾™å¥—è§’è‰²ï¼Œç»Ÿä¸€ä½¿ç”¨ "è·¯äºº" ä½œä¸º speakerã€‚
        """

        user_content = "è¯·ä¸¥æ ¼æŒ‰ç…§è§„èŒƒï¼Œå°†ä»¥ä¸‹æ–‡æœ¬æ‹†è§£ä¸ºçº¯å‡€çš„ JSON å‰§æœ¬ï¼ˆç»ä¸æ”¹å†™åŸæ„ï¼‰ï¼š\n\n"
        if context:
            user_content += f"ã€ä¸Šæ–‡å‚è€ƒï¼ˆä»…ä¾›è§’è‰²ä¸€è‡´æ€§å‚è€ƒï¼Œä¸è¦ç¿»è¯‘æ­¤æ®µï¼‰ã€‘\n{context}\n\n"
        user_content += text_chunk

        payload = {
            "model": self.model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            "format": "json",
            "stream": False,
            "keep_alive": "10m",
            "options": {
                "num_ctx": 8192,
                "temperature": 0.0,
                "top_p": 0.1
            }
        }

        try:
            response = requests.post(self.api_url, json=payload, timeout=180)
            response.raise_for_status()
            content = response.json().get('message', {}).get('content', '[]')

            # ğŸŒŸ é¢„å¤„ç†ï¼šæ¸…æ´—å®é™…æ§åˆ¶å­—ç¬¦ï¼ˆé˜²æ­¢ LLM è¾“å‡ºç ´å JSON è§£æï¼‰
            # Only strip real control characters; keep escaped sequences
            # like \n and \t inside JSON strings intact.
            content = content.replace('\t', ' ').replace('\r', '')

            # Strip Markdown code-block wrappers the LLM may hallucinate
            content = re.sub(r'^```(?:json)?\s*', '', content.strip(), flags=re.IGNORECASE)
            content = re.sub(r'\s*```$', '', content.strip())

            try:
                script = json.loads(content)
            except json.JSONDecodeError:
                logger.warning("âš ï¸ JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤æˆªæ–­çš„ JSON ...")
                script = repair_json_array(content)
                if script is None:
                    # ã€ç»ˆæé™çº§ 1ã€‘ï¼šJSONå½»åº•æŸåï¼Œç›´æ¥æ‹¿åŸæ–‡æœ¬åšæ—ç™½
                    logger.warning("âš ï¸ JSONå½»åº•æŸåï¼Œå¯ç”¨ç»ˆæé™çº§æ–¹æ¡ˆï¼šåŸæ–‡æœ¬ä½œä¸ºæ—ç™½ã€‚")
                    return self._validate_script_elements([
                        {"type": "narration", "speaker": "narrator", "content": text_chunk}
                    ])
                return self._validate_script_elements(script)

            if isinstance(script, list):
                return self._validate_script_elements(script)

            if isinstance(script, dict):
                # å®¹é”™ 1: ç©ºå­—å…¸ {}
                if not script:
                    logger.warning("âš ï¸ æ¨¡å‹è¿”å›äº†ç©ºå­—å…¸ï¼Œå¯ç”¨ç»ˆæé™çº§æ–¹æ¡ˆã€‚")
                    return self._validate_script_elements([
                        {"type": "narration", "speaker": "narrator", "content": text_chunk}
                    ])

                # å®¹é”™ 2a: LLM è¿”å›äº† {"name": "...", "content": "..."} ç»“æ„
                if "content" in script and "name" in script:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°éæ•°ç»„ç»“æ„ï¼ˆå« name/contentï¼‰ï¼Œæ­£åœ¨å°†å…¶è½¬æ¢ä¸ºå•æ¡æ—ç™½")
                    script = [{"type": "narration", "speaker": "narrator", "content": script["content"]}]
                    return self._validate_script_elements(script)
                # å®¹é”™ 2b: LLM è¿”å›äº†å•ä¸ª JSON å¯¹è±¡ï¼ˆå¦‚ {"type": "narration", "speaker": "narrator", "content": "..."}ï¼‰
                if "content" in script or "type" in script:
                    logger.warning("âš ï¸ æ¨¡å‹è¿”å›äº†å•ä¸ª JSON å¯¹è±¡è€Œéæ•°ç»„ï¼Œè‡ªåŠ¨ä½¿ç”¨åˆ—è¡¨åŒ…è£¹ä»¥æ¢å¤æµæ°´çº¿ã€‚")
                    return self._validate_script_elements([script])
                # å®¹é”™ 3: LLM è¿”å›äº†åŒ…å«åˆ—è¡¨çš„å­—å…¸ (å¦‚ {"script": [...]})
                for value in script.values():
                    if isinstance(value, list) and len(value) > 0 and isinstance(value[0], dict):
                        return self._validate_script_elements(value)
                
                # ã€ç»ˆæé™çº§ 2ã€‘ï¼šæ¨¡å‹è¿”å›äº†ç‰ˆæƒé¡µã€ä¹¦ç±å…ƒæ•°æ®ç­‰æ— æ³•è¯†åˆ«çš„å­—å…¸
                logger.warning(f"âš ï¸ æ¨¡å‹è¿”å›äº†æ— æ³•è¯†åˆ«çš„å­—å…¸ç»“æ„ï¼ˆå¦‚ç‰ˆæƒä¿¡æ¯ï¼‰ï¼Œå¯ç”¨ç»ˆæé™çº§æ–¹æ¡ˆã€‚")
                return self._validate_script_elements([
                    {"type": "narration", "speaker": "narrator", "content": text_chunk}
                ])
                
            # ã€ç»ˆæé™çº§ 3ã€‘ï¼šå¤§æ¨¡å‹è¿”å›äº†å­—ç¬¦ä¸²æˆ–æ•°å­—ç­‰å®Œå…¨ä¸æ˜¯å¯¹è±¡çš„æ ¼å¼
            logger.warning("âš ï¸ æ¨¡å‹è¿”å›äº†éé¢„æœŸç»“æ„ï¼Œå¯ç”¨ç»ˆæé™çº§æ–¹æ¡ˆã€‚")
            return self._validate_script_elements([
                {"type": "narration", "speaker": "narrator", "content": text_chunk}
            ])

        except RuntimeError:
            raise
        except Exception as e:
            raise RuntimeError(f"âŒ Ollama è§£æå¤±è´¥: {e}") from e
    
    def _validate_script_elements(self, script: List[Dict]) -> List[Dict]:
        """éªŒè¯å¹¶ä¿®å¤è„šæœ¬å…ƒç´ ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ"""
        required_fields = ['type', 'speaker', 'content']
        validated_script = []
        
        for i, element in enumerate(script):
            # ç¡®ä¿æ˜¯å­—å…¸ç±»å‹
            if not isinstance(element, dict):
                logger.warning(f"âš ï¸ è„šæœ¬å…ƒç´  {i} ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œè·³è¿‡: {element}")
                continue
                
            # æ£€æŸ¥å¹¶è¡¥å……ç¼ºå¤±çš„å­—æ®µ
            fixed_element = element.copy()

            # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šå¦‚æœå¤§æ¨¡å‹æŠŠ content å†™æˆäº†æ•°ç»„ï¼Œå¼ºåˆ¶æ‹¼æˆå­—ç¬¦ä¸²
            if 'content' in fixed_element:
                if isinstance(fixed_element['content'], list):
                    fixed_element['content'] = "\n".join(str(x) for x in fixed_element['content'])
                elif not isinstance(fixed_element['content'], str):
                    fixed_element['content'] = str(fixed_element['content'])
            
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            for field in required_fields:
                if field not in fixed_element:
                    if field == 'type':
                        fixed_element['type'] = 'narration'  # é»˜è®¤ä¸ºæ—ç™½
                    elif field == 'speaker':
                        fixed_element['speaker'] = 'narrator'  # é»˜è®¤è¯´è¯è€…
                    elif field == 'content':
                        fixed_element['content'] = ''  # ç©ºå†…å®¹
                    logger.warning(f"âš ï¸ è¡¥å……ç¼ºå¤±å­—æ®µ '{field}' åœ¨å…ƒç´  {i}: {element}")
            
            # å¼ºåŒ–ä¿®å¤é€»è¾‘ï¼šå¤„ç† None å€¼
            if fixed_element.get('speaker') is None:
                fixed_element['speaker'] = 'narrator'
                logger.warning(f"âš ï¸ ä¿®å¤ None å€¼å­—æ®µ 'speaker' åœ¨å…ƒç´  {i}")
            if fixed_element.get('gender') is None:
                fixed_element['gender'] = 'unknown'
                logger.warning(f"âš ï¸ ä¿®å¤ None/ç¼ºå¤±å­—æ®µ 'gender' åœ¨å…ƒç´  {i}")
            
            # ç¡®ä¿ gender å­—æ®µå­˜åœ¨ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
            if 'gender' not in fixed_element:
                fixed_element['gender'] = 'unknown'
                logger.warning(f"âš ï¸ è¡¥å……ç¼ºå¤±å­—æ®µ 'gender' åœ¨å…ƒç´  {i}: {element}")
            
            # ç¡®ä¿ emotion å­—æ®µå­˜åœ¨
            if 'emotion' not in fixed_element:
                fixed_element['emotion'] = 'å¹³é™'
            
            validated_script.append(fixed_element)
            
        return validated_script
    

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    director = LLMScriptDirector()
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
ç¬¬ä¸€ç«  å‡¯å¤«æ‹‰ç»´å…‹çš„é£é›ª

å¤œå¹•é™ä¸´ï¼Œæ¸¯å£çš„ç¯ç«å¼€å§‹é—ªçƒã€‚

"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ"è€æ¸”å¤«è¯´é“ã€‚

å¹´è½»äººæ‘‡æ‘‡å¤´ï¼š"æˆ‘åªç›¸ä¿¡æµ·ã€‚"

è¿œå¤„ä¼ æ¥æ±½ç¬›å£°ï¼Œåˆ’ç ´äº†å¯‚é™çš„å¤œç©ºã€‚
"""
    
    script = director.parse_text_to_script(test_text)
    print("è§£æç»“æœ:")
    for i, unit in enumerate(script, 1):
        print(f"{i}. {unit}")