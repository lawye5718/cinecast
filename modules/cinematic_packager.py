#!/usr/bin/env python3
"""
CineCast æ··éŸ³ä¸å‘è¡Œæ‰“åŒ…å™¨
é˜¶æ®µä¸‰ï¼šç”µå½±çº§æ··éŸ³å‘ç‰ˆ (Cinematic Post-Processing)
æµæ°´çº¿ç¬¬ä¸‰é˜¶æ®µï¼šä»å¹²éŸ³ç¼“å­˜ç»„è£…æˆç”µå½±çº§æœ‰å£°ä¹¦
"""

import os
import logging
import zipfile
from pydub import AudioSegment
from typing import Optional, List, Dict
from tqdm import tqdm

logger = logging.getLogger(__name__)

# Dynamic pause constants (milliseconds)
CROSS_SPEAKER_PAUSE_MS = 500   # ä¸åŒè§’è‰²ä¹‹é—´çš„åœé¡¿
SAME_SPEAKER_PAUSE_MS = 250    # åŒä¸€è§’è‰²è¿ç»­è¯´è¯çš„åœé¡¿


class CinematicPackager:
    FADE_IN_MS = 3000   # æ·¡å…¥æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    FADE_OUT_MS = 2000  # æ·¡å‡ºæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰

    def __init__(self, output_dir="output", target_duration_min=30):
        """
        åˆå§‹åŒ–ç”µå½±çº§æ··éŸ³å°
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            target_duration_min: ç›®æ ‡åˆ†å·æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤30åˆ†é’Ÿ
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.target_duration_ms = target_duration_min * 60 * 1000
        self.min_tail_ms = 10 * 60 * 1000         # 10åˆ†é’Ÿå°¾éƒ¨é˜ˆå€¼
        self.sample_rate = 24000                  # Qwen3-TTS 1.7B é«˜ä¿çœŸé‡‡æ ·ç‡
        self.crossfade_ms = 18                    # äº¤å‰æ·¡åŒ–è¡¥å¿ (15-20ms èŒƒå›´ï¼Œ18ms ä¸º 1.7B æƒ…æ„Ÿæ³¢åŠ¨æœ€ä½³å¹³è¡¡ç‚¹)
        
        self.buffer = AudioSegment.empty()
        self.file_index = 1
        
        # Track per-speaker audio for multi-track export
        self._speaker_tracks: dict = {}
        self._labels: list = []  # [{"start_ms", "end_ms", "speaker", "text"}]
        self._timeline_ms = 0  # current position on the global timeline
        
        logger.info(f"ğŸ›ï¸ å¯åŠ¨åæœŸæ··éŸ³å° (Pydub)ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
    
    def mix_ambient(self, main_audio: AudioSegment, ambient: AudioSegment) -> AudioSegment:
        """
        æ··å…¥æ²‰æµ¸å¼å£°åœº
        
        Args:
            main_audio: ä¸»éŸ³é¢‘
            ambient: ç¯å¢ƒéŸ³èƒŒæ™¯
            
        Returns:
            AudioSegment: æ··åˆåçš„éŸ³é¢‘
        """
        if len(ambient) < 500:
            logger.debug("ç¯å¢ƒéŸ³è¿‡çŸ­ï¼Œè·³è¿‡æ··éŸ³")
            return main_audio  # æ— æœ‰æ•ˆç¯å¢ƒéŸ³
        
        try:
            # å°†ç¯å¢ƒéŸ³é‡é™ä½25dBï¼Œé¿å…å–§å®¾å¤ºä¸»
            ambient = ambient - 25 
            
            # å¾ªç¯ç¯å¢ƒéŸ³ä½¿å…¶ä¸ä¸»éŸ³é¢‘ç­‰é•¿
            loop_count = len(main_audio) // len(ambient) + 1
            ambient_looped = ambient * loop_count
            ambient_looped = ambient_looped[:len(main_audio)]
            
            # æ··åˆéŸ³é¢‘
            mixed_audio = main_audio.overlay(ambient_looped)
            logger.debug("âœ… ç¯å¢ƒéŸ³æ··éŸ³å®Œæˆ")
            return mixed_audio
            
        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒéŸ³æ··éŸ³å¤±è´¥: {e}")
            return main_audio
    
    def process_from_cache(self, micro_script: List[Dict], cache_dir: str, assets, 
                          ambient_bgm=None, chime=None):
        """
        æµæ°´çº¿ç¬¬ä¸‰é˜¶æ®µï¼šä»å¹²éŸ³ç¼“å­˜ç»„è£…æˆç”µå½±çº§æœ‰å£°ä¹¦
        
        Uses dynamic pauses: CROSS_SPEAKER_PAUSE_MS between different speakers,
        SAME_SPEAKER_PAUSE_MS for consecutive lines by the same speaker.
        """
        # ğŸŒŸ å‰ç½®å…¨é‡è·³è¿‡ï¼šå¦‚æœå½“å‰åˆ†å·å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡æ•´ä¸ªå‰§æœ¬çš„æ··éŸ³è®¡ç®—
        output_filename = f"Audiobook_Part_{self.file_index:03d}.mp3"
        output_path = os.path.join(self.output_dir, output_filename)
        if os.path.exists(output_path):
            logger.info(f"â­ï¸  æ£€æµ‹åˆ°åˆ†å·å·²å®Œå…¨è¦†ç›–å½“å‰å‰§æœ¬ï¼Œç›´æ¥è·³è¿‡æ··éŸ³è®¡ç®—: {output_filename}")
            # å¿«è¿› file_index è·³è¿‡æ‰€æœ‰å·²å­˜åœ¨çš„åˆ†å·
            while os.path.exists(os.path.join(self.output_dir, f"Audiobook_Part_{self.file_index:03d}.mp3")):
                self.file_index += 1
            return

        logger.info("ğŸ›ï¸ å¯åŠ¨åæœŸæ··éŸ³å° (Pydub)...")
        
        prev_speaker = None
        
        for item in tqdm(micro_script, desc="æ··éŸ³ç»„è£…ä¸­"):
            wav_path = os.path.join(cache_dir, f"{item['chunk_id']}.wav")
            if not os.path.exists(wav_path):
                logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°å¹²éŸ³ç¼“å­˜: {wav_path}ï¼Œè·³è¿‡è¯¥å¥ã€‚")
                continue
                
            # åŠ è½½å¹²éŸ³
            segment = AudioSegment.from_file(wav_path, format="wav")
            
            # åº”ç”¨è¯­é€Ÿä¸éŸ³è°ƒå˜åŒ– (å¦‚æ ‡é¢˜çš„ 0.8 å€é€Ÿä¸€å­—ä¸€é¡¿)
            voice_cfg = assets.get_voice_for_role(
                item["type"], 
                item.get("speaker"), 
                item.get("gender")
            )
            speed_factor = voice_cfg.get("speed", 1.0)
            
            # ğŸŒŸ æ³¨æ„ï¼šè°ƒé€Ÿåº”åœ¨ TTS ç”Ÿæˆæ—¶æ§åˆ¶ï¼Œä¸åœ¨æ··éŸ³é˜¶æ®µé€šè¿‡ä¿®æ”¹å¸§ç‡å®ç°
            # ç›´æ¥ä¿®æ”¹ frame_rate ä¼šå¯¼è‡´éŸ³è°ƒå¤±çœŸï¼ˆå˜è°ƒå˜å£°ï¼‰ï¼Œå› æ­¤æ­¤å¤„è·³è¿‡é€Ÿåº¦è°ƒæ•´
            
            # ğŸŒŸ åŠ¨æ€åœé¡¿ï¼šåŒè§’è‰²è¿ç»­å¯¹ç™½ç”¨çŸ­åœé¡¿ï¼Œè·¨è§’è‰²åˆ‡æ¢ç”¨é•¿åœé¡¿
            current_speaker = item.get("speaker", "narrator")
            script_pause = item.get("pause_ms", 0)
            if prev_speaker is not None and current_speaker == prev_speaker:
                # Same speaker: use the shorter of script pause and cap
                pause_ms = SAME_SPEAKER_PAUSE_MS
            else:
                # Different speaker: ensure at least CROSS_SPEAKER_PAUSE_MS
                pause_ms = max(script_pause, CROSS_SPEAKER_PAUSE_MS)
            prev_speaker = current_speaker
            
            # Record label for multi-track export
            seg_start = self._timeline_ms
            seg_end = seg_start + len(segment)
            self._labels.append({
                "start_ms": seg_start,
                "end_ms": seg_end,
                "speaker": current_speaker,
                "text": item.get("content", "")[:80],
            })
            
            # Accumulate per-speaker track data
            if current_speaker not in self._speaker_tracks:
                # Pad with silence up to this point
                self._speaker_tracks[current_speaker] = AudioSegment.silent(
                    duration=seg_start
                )
            else:
                # Pad any gap since the last segment from this speaker
                current_len = len(self._speaker_tracks[current_speaker])
                if current_len < seg_start:
                    self._speaker_tracks[current_speaker] += AudioSegment.silent(
                        duration=seg_start - current_len
                    )
            self._speaker_tracks[current_speaker] += segment
            
            # æ‹¼æ¥å…¥ç¼“å†²åŒº
            self.buffer += segment + AudioSegment.silent(duration=pause_ms)
            self._timeline_ms += len(segment) + pause_ms
            
            # æ»¡ 30 åˆ†é’Ÿåˆ™å¯¼å‡º
            if len(self.buffer) >= self.target_duration_ms:
                self.export_volume(ambient=ambient_bgm, chime=chime)
                
        # ç»“å°¾å…œåº•
        self.finalize(ambient=ambient_bgm, chime=chime)
    
    def add_audio(self, audio: AudioSegment, ambient: Optional[AudioSegment] = None, 
                  chime: Optional[AudioSegment] = None):
        """
        å‘ç¼“å†²åŒºæ·»åŠ éŸ³é¢‘ï¼Œæ»¡30åˆ†é’Ÿåˆ™å‘ç‰ˆ
        ä¿ç•™å‘åå…¼å®¹æ€§
        """
        # å¦‚æœæœ‰ç¯å¢ƒéŸ³ï¼Œå…ˆè¿›è¡Œæ··éŸ³
        if ambient:
            audio = self.mix_ambient(audio, ambient)
        
        self.buffer += audio
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ—¶é•¿
        if len(self.buffer) >= self.target_duration_ms:
            self.export_volume(chime=chime)
    
    def export_volume(self, ambient: Optional[AudioSegment] = None,
                     chime: Optional[AudioSegment] = None):
        """
        å¯¼å‡ºä¸€å·ï¼ˆä¸€ä¸ªå®Œæ•´çš„MP3ï¼‰

        å½“é€šè¿‡ process_from_cache è°ƒç”¨æ—¶ï¼Œambient åœ¨æ­¤å¤„æ··å…¥æ•´å·éŸ³é¢‘ã€‚
        å½“é€šè¿‡ add_audio è°ƒç”¨æ—¶ï¼Œambient å·²åœ¨ add_audio ä¸­æŒ‰ç‰‡æ®µæ··å…¥ï¼Œ
        æ­¤å¤„ä¸åº”å†ä¼ å…¥ ambient ä»¥é¿å…é‡å¤æ··éŸ³ã€‚
        
        Args:
            ambient: ç¯å¢ƒéŸ³èƒŒæ™¯ï¼ˆå¯é€‰ï¼Œä»…åœ¨ process_from_cache æµç¨‹ä¸­ä½¿ç”¨ï¼‰
            chime: å¼€å¤´è¿‡æ¸¡éŸ³æ•ˆï¼ˆå¯é€‰ï¼‰
        """
        if len(self.buffer) == 0:
            logger.warning("ç¼“å†²åŒºä¸ºç©ºï¼Œè·³è¿‡å¯¼å‡º")
            return
        
        # ğŸŒŸ æ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœåˆ†å·æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å‹åˆ¶
        file_name = f"Audiobook_Part_{self.file_index:03d}.mp3"
        save_path = os.path.join(self.output_dir, file_name)
        if os.path.exists(save_path):
            logger.info(f"â­ï¸  æ£€æµ‹åˆ°åˆ†å·å·²å­˜åœ¨ï¼Œè·³è¿‡å‹åˆ¶: {file_name}")
            self.buffer = AudioSegment.empty()
            self.file_index += 1
            return
        
        try:
            final_audio = self.buffer
            
            # 0. æ··å…¥ç¯å¢ƒéŸ³ï¼ˆå¦‚æœæœ‰ï¼‰
            if ambient:
                final_audio = self.mix_ambient(final_audio, ambient)
            
            # 1. ç¡çœ å”¤é†’é˜²æƒŠè·³ï¼šæ·»åŠ Chimeï¼Œå¹¶å¯¹ä¸»å¹²å¼€å¤´åšæ·¡å…¥
            fade_in_ms = min(self.FADE_IN_MS, len(final_audio))
            final_audio = final_audio.fade_in(fade_in_ms)
            if chime and len(chime) > 500:
                final_audio = chime + final_audio
                
            # 2. å°¾éƒ¨æ·¡å‡ºï¼Œé˜²æ­¢çªå…€ç»“æŸ
            fade_out_ms = min(self.FADE_OUT_MS, len(final_audio))
            final_audio = final_audio.fade_out(fade_out_ms)
            
            logger.info(f"ğŸ“¦ æ­£åœ¨å‹åˆ¶: {file_name} ({len(final_audio)/1000/60:.1f}åˆ†é’Ÿ)")
            
            # å¯¼å‡ºä¸ºMP3æ ¼å¼
            final_audio.export(
                save_path, 
                format="mp3", 
                bitrate="128k",
                parameters=["-q:a", "2"]  # VBRè´¨é‡ç­‰çº§
            )
            
            # é‡ç½®ç¼“å†²åŒº
            self.buffer = AudioSegment.empty()
            self.file_index += 1
            
            logger.info(f"âœ… æˆåŠŸå¯¼å‡º: {file_name}")
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
    
    def finalize(self, ambient: Optional[AudioSegment] = None, 
                 chime: Optional[AudioSegment] = None):
        """
        å¤„ç†ä¹¦ç±ç»“å°¾çš„ç¢ç‰‡
        
        Args:
            ambient: ç¯å¢ƒéŸ³èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰
            chime: è¿‡æ¸¡éŸ³æ•ˆï¼ˆå¯é€‰ï¼‰
        """
        remaining_ms = len(self.buffer)
        if remaining_ms == 0:
            logger.info("æ²¡æœ‰å‰©ä½™éŸ³é¢‘éœ€è¦å¤„ç†")
            return
        
        logger.info(f"ğŸ”š å¤„ç†å°¾éƒ¨éŸ³é¢‘: {remaining_ms/1000/60:.1f}åˆ†é’Ÿ")
        
        if remaining_ms < self.min_tail_ms and self.file_index > 1:
            # å°¾éƒ¨ä¸è¶³10åˆ†é’Ÿï¼Œè¿½åŠ åˆ°ä¸Šä¸€ä¸ªæ–‡ä»¶
            self._merge_with_previous(ambient, chime)
        else:
            # ç‹¬ç«‹å¯¼å‡ºä¸ºæ–°çš„ä¸€å·
            self.export_volume(ambient=ambient, chime=chime)
    
    def _merge_with_previous(self, ambient: Optional[AudioSegment] = None,
                             chime: Optional[AudioSegment] = None):
        """
        å°†å°¾éƒ¨éŸ³é¢‘åˆå¹¶åˆ°ä¸Šä¸€ä¸ªæ–‡ä»¶
        
        Args:
            ambient: ç¯å¢ƒéŸ³èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰
            chime: è¿‡æ¸¡éŸ³æ•ˆï¼ˆå¯é€‰ï¼‰
        """
        try:
            prev_index = self.file_index - 1
            prev_file = os.path.join(self.output_dir, f"Audiobook_Part_{prev_index:03d}.mp3")
            
            if not os.path.exists(prev_file):
                logger.warning(f"å‰ä¸€ä¸ªæ–‡ä»¶ä¸å­˜åœ¨: {prev_file}ï¼Œç‹¬ç«‹å¯¼å‡ºå°¾éƒ¨")
                self.export_volume(chime=chime)
                return
            
            logger.info(f"ğŸ”— å°¾éƒ¨åˆå¹¶: {len(self.buffer)/1000/60:.1f}åˆ†é’Ÿè¿½åŠ åˆ° {prev_file}")
            
            # åŠ è½½å‰ä¸€ä¸ªæ–‡ä»¶
            prev_audio = AudioSegment.from_file(prev_file, format="mp3")
            
            # å¤„ç†å°¾éƒ¨éŸ³é¢‘ï¼ˆå¦‚æœ‰ç¯å¢ƒéŸ³åˆ™æ··å…¥ï¼‰
            tail_audio = self.buffer
            if ambient:
                tail_audio = self.mix_ambient(tail_audio, ambient)
            
            # ä½¿ç”¨äº¤å‰æ·¡åŒ–åˆå¹¶ï¼Œé¿å…å‰å· fade_out ä¸å°¾éƒ¨éŸ³é¢‘ä¹‹é—´äº§ç”ŸéŸ³é‡æ–­å±‚
            crossfade_ms = min(2000, len(prev_audio), len(tail_audio))
            merged = prev_audio.append(tail_audio, crossfade=crossfade_ms)
            
            # é‡æ–°å¯¼å‡º
            merged.export(prev_file, format="mp3", bitrate="128k")
            
            # æ¸…ç©ºç¼“å†²åŒº
            self.buffer = AudioSegment.empty()
            
            logger.info("âœ… å°¾éƒ¨åˆå¹¶å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å°¾éƒ¨åˆå¹¶å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä»ç„¶ç‹¬ç«‹å¯¼å‡º
            self.export_volume(chime=chime)
    
    def get_buffer_status(self) -> dict:
        """
        è·å–å½“å‰ç¼“å†²åŒºçŠ¶æ€
        
        Returns:
            dict: åŒ…å«ç¼“å†²åŒºä¿¡æ¯çš„å­—å…¸
        """
        return {
            "buffer_length_ms": len(self.buffer),
            "buffer_length_min": len(self.buffer) / 1000 / 60,
            "current_file_index": self.file_index,
            "target_duration_min": self.target_duration_ms / 1000 / 60,
            "remaining_until_target": (self.target_duration_ms - len(self.buffer)) / 1000 / 60
        }

    def export_audacity(self, output_path: Optional[str] = None) -> Optional[str]:
        """Export a multi-track Audacity project as a ZIP archive.

        The archive contains:
        - One WAV file per speaker (stem), named ``{speaker}.wav``
        - A ``labels.txt`` with tab-separated Audacity label format:
          ``start_seconds\tend_seconds\tspeaker: text``

        This allows professional producers to import into a DAW (Audacity,
        Logic Pro, etc.) for fine-grained per-line editing.

        Args:
            output_path: Path for the ZIP file.  Defaults to
                ``<output_dir>/audacity_export.zip``.

        Returns:
            The path to the created ZIP file, or ``None`` on failure.
        """
        if not self._speaker_tracks and not self._labels:
            logger.warning("No multi-track data collected; call process_from_cache first.")
            return None

        if output_path is None:
            output_path = os.path.join(self.output_dir, "audacity_export.zip")

        try:
            with zipfile.ZipFile(output_path, "w", zipfile.ZIP_DEFLATED) as zf:
                # Write per-speaker stem WAVs
                for speaker, track in self._speaker_tracks.items():
                    safe_name = speaker.replace("/", "_").replace("\\", "_")
                    wav_name = f"{safe_name}.wav"
                    tmp_wav = os.path.join(self.output_dir, f"_tmp_{wav_name}")
                    try:
                        track.export(tmp_wav, format="wav")
                        zf.write(tmp_wav, wav_name)
                    finally:
                        if os.path.exists(tmp_wav):
                            os.unlink(tmp_wav)

                # Write Audacity labels
                label_lines = []
                for lbl in self._labels:
                    start_s = lbl["start_ms"] / 1000.0
                    end_s = lbl["end_ms"] / 1000.0
                    text = f"{lbl['speaker']}: {lbl['text']}"
                    label_lines.append(f"{start_s:.3f}\t{end_s:.3f}\t{text}")
                zf.writestr("labels.txt", "\n".join(label_lines))

            logger.info(f"âœ… Audacity å¤šè½¨å·¥ç¨‹å·²å¯¼å‡º: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"âŒ Audacity å¯¼å‡ºå¤±è´¥: {e}")
            return None

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    packager = CinematicPackager("./test_output")
    
    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
    test_audio = AudioSegment.silent(duration=5000)  # 5ç§’é™éŸ³
    
    # æµ‹è¯•æ·»åŠ éŸ³é¢‘
    print("æµ‹è¯•æ·»åŠ éŸ³é¢‘...")
    packager.add_audio(test_audio)
    
    # æ£€æŸ¥çŠ¶æ€
    status = packager.get_buffer_status()
    print(f"ç¼“å†²åŒºçŠ¶æ€: {status}")
    
    # æµ‹è¯•æœ€ç»ˆåŒ–
    print("æµ‹è¯•æœ€ç»ˆåŒ–...")
    packager.finalize()
    
    print("âœ… æµ‹è¯•å®Œæˆ")