#!/usr/bin/env python3
"""
CineCast MLXåº•å±‚æ¸²æŸ“å¼•æ“
é˜¶æ®µäºŒï¼šçº¯å‡€å¹²éŸ³æ¸²æŸ“ (Dry Voice Rendering)
åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
åŸºäºqwenttsé¡¹ç›®çš„æˆç†Ÿå®ç°

Supports an optional "group-by-voice" rendering strategy: instead of
rendering chunks in script order (which forces frequent voice-embedding
switches), callers can use ``group_indices_by_voice_type`` to cluster all
chunks that share the same voice first, render each cluster in one pass,
and then reassemble in the original order during Stage 3.
"""

import concurrent.futures
import gc
import os
import re
import warnings

# æ‹¦æˆª Tokenizer æ­£åˆ™è­¦å‘Šï¼Œä¿æŒç»ˆç«¯æ—¥å¿—çº¯å‡€
warnings.filterwarnings("ignore", message=".*incorrect regex pattern.*")
# å°è¯•å‘åº•å±‚ç¯å¢ƒå˜é‡æ³¨å…¥ä¿®å¤æ ‡å¿—ï¼ˆéƒ¨åˆ† transformers ç‰ˆæœ¬å…¼å®¹ï¼‰
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["FIX_MISTRAL_REGEX"] = "1"

import numpy as np
import soundfile as sf
import mlx.core as mx
from mlx_audio.tts.utils import load_model
import logging
from typing import List, Dict, Tuple
from collections import defaultdict

logger = logging.getLogger(__name__)


def group_indices_by_voice_type(
    micro_script: List[Dict],
) -> Dict[str, List[int]]:
    """Group script indices by their effective voice type.

    Returns a dict mapping voice-type keys (e.g. ``"narrator"``,
    ``"dialogue:è€æ¸”å¤«"``) to the list of indices in *micro_script* that
    should be rendered with that voice.  This allows the caller to render
    all chunks for a single voice consecutively, minimising MLX
    embedding switches and potentially improving throughput by 2-3Ã—.
    """
    groups: Dict[str, List[int]] = defaultdict(list)
    for idx, item in enumerate(micro_script):
        item_type = item.get("type", "narration")
        speaker = item.get("speaker", "narrator")
        if item_type in ("title", "subtitle", "narration", "recap"):
            key = item_type
        else:
            key = f"dialogue:{speaker}"
        groups[key].append(idx)
    return dict(groups)

class MLXRenderEngine:
    def __init__(self, model_path="./models/Qwen3-TTS-MLX-0.6B", config=None):
        """
        åˆå§‹åŒ–MLXçº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“ (æ”¯æŒ Qwen3-TTS 1.7B Model Pool)
        
        Args:
            model_path: é»˜è®¤æ¨¡å‹è·¯å¾„ (å…¼å®¹æ—§ç‰ˆå•æ¨¡å‹æ¨¡å¼)
            config: å¯é€‰é…ç½®å­—å…¸ï¼Œæ”¯æŒå¤šæ¨¡å‹è·¯å¾„ï¼š
                - model_path_base: 1.7B Base (å…‹éš†ç”¨)
                - model_path_design: 1.7B VoiceDesign (è®¾è®¡ç”¨)
                - model_path_custom: 1.7B CustomVoice (å†…ç½®è§’è‰²ç”¨)
                - model_path_fallback: 0.6B å›é€€è·¯å¾„
        """
        logger.info("ğŸš€ å¯åŠ¨ MLX çº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“...")
        self.config = config or {}
        self.default_voice = self.config.get("default_narrator_voice", "eric")
        self.current_mode = None
        self.model = None
        # åˆ›å»ºä¸“é—¨ç”¨äºç£ç›˜å†™å…¥çš„å•çº¿ç¨‹æ± ï¼Œé¿å…é˜»å¡æ¨ç†
        self.io_executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
        # ä¸¥æ ¼æ˜ å°„æœ¬åœ°æ¨¡å‹ï¼Œé¿å…æ„å¤–é™çº§
        self._model_paths = {
            "preset": self.config.get("model_path_custom", "./models/Qwen3-TTS-12Hz-1.7B-CustomVoice-4bit"),
            "design": self.config.get("model_path_design", "./models/Qwen3-TTS-12Hz-1.7B-VoiceDesign-4bit"),
            "clone": self.config.get("model_path_base", "./models/Qwen3-TTS-12Hz-1.7B-Base-4bit"),
        }
        self._fallback_path = self.config.get(
            "model_path_fallback", model_path
        )
        try:
            # é»˜è®¤åŠ è½½ï¼šå¦‚æœé…ç½®äº† preset è·¯å¾„åˆ™ç”¨ presetï¼Œå¦åˆ™ç”¨ä¼ å…¥çš„ model_path
            default_path = self._model_paths.get("preset") or model_path
            self._do_load(default_path, mode="preset")
            self.sample_rate = 24000  # Qwen3-TTS 1.7B é«˜ä¿çœŸé‡‡æ ·ç‡
            self.max_chars = 150  # ğŸ¯ ä¿®æ”¹ç‚¹ï¼šé€‚é… M4 24G çš„ 1.7B ç”œç‚¹é•¿åº¦
            logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ é¦–é€‰æ¨¡å‹åŠ è½½å¤±è´¥ ({e})ï¼Œå°è¯•å›é€€åˆ° 0.6B...")
            try:
                self._do_load(self._fallback_path, mode="preset")
                self.sample_rate = 22050  # 0.6B æ¨¡å‹ä½¿ç”¨æ—§é‡‡æ ·ç‡
                self.max_chars = 150  # ğŸ¯ ä¿®æ”¹ç‚¹ï¼šå›é€€æ¨¡å¼åŒæ ·æ”¾å®½
                logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–æˆåŠŸ (å›é€€åˆ° 0.6B)")
            except Exception as e2:
                logger.error(f"âŒ MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e2}")
                raise

    def _do_load(self, path, mode="preset"):
        """å®é™…åŠ è½½æ¨¡å‹åˆ°å†…å­˜"""
        if self.model is not None:
            del self.model
            self.model = None
            gc.collect()
            mx.clear_cache()
        self.model = load_model(path)
        self.current_mode = mode
        logger.info(f"âœ… å·²åŠ è½½æ¨¡å‹ [{mode}]: {path}")

    def _load_mode(self, mode):
        """æ ¹æ®ä»»åŠ¡ç±»å‹åˆ‡æ¢æ¨¡å‹ (Model Pool æ¨¡å¼)"""
        if mode == self.current_mode:
            return
        target_path = self._model_paths.get(mode)
        if not target_path:
            # æ²¡æœ‰é…ç½®å¯¹åº”æ¨¡å¼çš„è·¯å¾„ï¼Œä¿æŒå½“å‰æ¨¡å‹
            logger.debug(f"â­ï¸ æœªé…ç½® [{mode}] æ¨¡å‹è·¯å¾„ï¼Œä¿æŒå½“å‰æ¨¡å‹")
            return
        try:
            mx.clear_cache()
            self._do_load(target_path, mode=mode)
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ‡æ¢åˆ° [{mode}] æ¨¡å‹å¤±è´¥ ({e})ï¼Œä¿æŒå½“å‰æ¨¡å‹")

    def warmup(self, modes=None):
        """é¢„çƒ­æŒ‡å®šæ¨¡å¼çš„æ¨¡å‹ï¼ŒéªŒè¯è·¯å¾„å¯ç”¨æ€§

        Args:
            modes: è¦é¢„çƒ­çš„æ¨¡å¼åˆ—è¡¨ï¼Œå¦‚ ["preset", "clone"]ã€‚
                   é»˜è®¤é¢„çƒ­ preset æ¨¡å¼ã€‚
        """
        if modes is None:
            modes = ["preset"]
        for mode in modes:
            path = self._model_paths.get(mode)
            if path:
                logger.info(f"ğŸ”¥ é¢„çƒ­æ¨¡å‹ [{mode}]: {path}")
                try:
                    self._do_load(path, mode=mode)
                except Exception as e:
                    logger.warning(f"âš ï¸ é¢„çƒ­ [{mode}] å¤±è´¥: {e}")

    def _async_write_wav(self, path, data, sr):
        """åå°çº¿ç¨‹å†™å…¥ WAV æ–‡ä»¶ï¼Œé¿å…é˜»å¡æ¨ç†"""
        try:
            sf.write(path, data, sr, format='WAV')
            logger.debug(f"ğŸ’¾ å¼‚æ­¥å†™å…¥å®Œæˆ: {path}")
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å†™å…¥å¤±è´¥: {path}: {e}")

    def destroy(self):
        """æ˜¾å¼æ¸…ç† MLX æ¨¡å‹èµ„æºï¼Œé‡Šæ”¾æ˜¾å­˜"""
        if hasattr(self, 'io_executor') and self.io_executor is not None:
            self.io_executor.shutdown(wait=True)
        if hasattr(self, 'model') and self.model is not None:
            del self.model
            self.model = None
        self.current_mode = None
        mx.clear_cache()
        logger.info("ğŸ§¹ MLX æ¸²æŸ“å¼•æ“èµ„æºå·²æ˜¾å¼é‡Šæ”¾")
    
    # æƒ…æ„ŸæŒ‡ä»¤å­—å…¸ (æ˜ å°„åˆ° VoiceDesign çš„ instruct)
    EMOTION_PROMPTS = {
        "æ„¤æ€’": "Speaking with a harsh, angry, and aggressive tone, slightly louder.",
        "æ‚²ä¼¤": "Speaking slowly with a sad, melancholic, and tearful voice.",
        "æ¿€åŠ¨": "Speaking fast with high pitch, very excited and energetic.",
        "ææƒ§": "Speaking with a trembling, nervous, and scared voice.",
        "å¹³é™": "",  # ä¿æŒåŸºå‡†éŸ³è‰²
    }

    def render_dry_chunk(self, content: str, voice_cfg: dict, save_path: str, emotion: str = "å¹³é™") -> bool:
        """
        åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
        ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
        
        æ”¯æŒä¸‰ç§ voice_cfg æ¨¡å¼ (é€šè¿‡ "mode" å­—æ®µåŒºåˆ†)ï¼š
          - preset (é»˜è®¤): ä¼ ç»Ÿå‚è€ƒéŸ³é¢‘å…‹éš† {"mode": "preset", "audio": "...", "text": "..."}
          - clone: ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘å…‹éš† {"mode": "clone", "ref_audio": "...", "ref_text": "..."}
          - design: æ–‡å­—é©±åŠ¨è®¾è®¡ {"mode": "design", "instruct": "Deep male voice..."}
        
        Args:
            content: è¦æ¸²æŸ“çš„æ–‡æœ¬å†…å®¹
            voice_cfg: éŸ³è‰²é…ç½® (æ”¯æŒ preset/clone/design ä¸‰ç§æ¨¡å¼)
            save_path: ä¿å­˜è·¯å¾„
            emotion: æƒ…æ„Ÿæ ‡ç­¾ï¼Œæ”¯æŒ "å¹³é™"/"æ„¤æ€’"/"æ‚²ä¼¤"/"æ¿€åŠ¨"/"ææƒ§"
        """
        if os.path.exists(save_path):
            logger.debug(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æ¸²æŸ“: {save_path}")
            return True # ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
            
        try:
            render_text = content.strip()
            
            # ğŸŒŸ ç»ˆææš´åŠ›æ¸…æ´—ï¼šæ¶ˆç­ä¸€åˆ‡å¯¼è‡´å¤è¯»çš„ç‰¹æ®Šç¬¦å·
            render_text = re.sub(r'[â€¦]+', 'ã€‚', render_text)       # ä¸­æ–‡çœç•¥å·
            render_text = re.sub(r'\.{2,}', 'ã€‚', render_text)     # è‹±æ–‡çœç•¥å·ï¼ˆå«åŒç‚¹ï¼‰
            render_text = re.sub(r'[â€”]+', 'ï¼Œ', render_text)       # ä¸­æ–‡ç ´æŠ˜å·
            render_text = re.sub(r'[-]{2,}', 'ï¼Œ', render_text)    # è‹±æ–‡ç ´æŠ˜å·
            render_text = re.sub(r'[~ï½]+', 'ã€‚', render_text)     # æ³¢æµªå·
            # æ¸…æ´—æ‰€æœ‰å†…éƒ¨æ¢è¡Œå’Œå¼‚å¸¸ç©ºç™½
            render_text = re.sub(r'\s+', ' ', render_text).strip()
            # æ™ºèƒ½é˜²å¡æ­»æˆªæ–­ï¼šç»ä¸ç”Ÿç¡¬è…°æ–©å•è¯ï¼Œè€Œæ˜¯å¯»æ‰¾æœ€è¿‘çš„æ ‡ç‚¹
            if len(render_text) > self.max_chars:
                safe_text = render_text[:self.max_chars]
                # åŒ¹é…å¸¸è§ä¸­è‹±æ–‡æ–­å¥æ ‡ç‚¹ï¼Œä»åå¾€å‰æ‰¾æœ€åä¸€ä¸ª
                last_match = None
                for match in re.finditer(r'[ã€‚ï¼ï¼Ÿï¼›.,!?;]', safe_text):
                    last_match = match
                if last_match:
                    render_text = safe_text[:last_match.end()]
                else:
                    render_text = safe_text + "ã€‚"
            
            if not re.search(r'[ã€‚ï¼ï¼Ÿï¼›.!?;]$', render_text):
                render_text += "ã€‚"

            # ğŸŒŸ ç»æ€é˜²å¾¡ï¼šæ£€æŸ¥æ¸…ç†åæ˜¯å¦åªå‰©ä¸‹æ ‡ç‚¹ç¬¦å·ï¼ˆæ— å®é™…æ–‡å­—ï¼‰
            pure_text = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿï¼›ã€\u201c\u201d\u2018\u2019ï¼ˆï¼‰ã€Šã€‹,.!?;:\'\"()\s-]', '', render_text)
            if not pure_text:
                # æ ¹æ®æ®‹ç•™çš„æ ‡ç‚¹ç¬¦å·ç±»å‹ï¼ŒåŠ¨æ€å†³å®šé™éŸ³æ—¶é•¿
                original_text = content.strip()
                if "â€¦" in original_text or "..." in original_text:
                    duration = 0.6  # çœç•¥å·é•¿åœé¡¿
                elif "â€”" in original_text or "-" in original_text:
                    duration = 0.3  # ç ´æŠ˜å·ä¸­ç­‰åœé¡¿
                else:
                    duration = 0.15  # é€—å·ç­‰å…¶ä»–æ®‹ç•™çŸ­åœé¡¿

                logger.warning(f"âš ï¸ åˆ‡ç‰‡æ— æœ‰æ•ˆæ–‡å­—ï¼Œç”Ÿæˆ {duration}s åŠ¨æ€ç©ºç™½éŸ³é¢‘: {save_path}")
                audio_data = np.zeros(int(self.sample_rate * duration), dtype=np.float32)
                sf.write(save_path, audio_data, self.sample_rate, format='WAV')
                return True

            logger.debug(f"ğŸµ æ¸²æŸ“å¹²éŸ³: {render_text[:50]}... -> {save_path}")
            
            # ğŸŒŸ æ ¹æ® voice_cfg ä¸­çš„ mode å­—æ®µé€‰æ‹©æ¸²æŸ“ç­–ç•¥
            mode = voice_cfg.get("mode", "preset")

            # ğŸ’¡ æƒ…æ„Ÿæœ—è¯»ï¼šå¦‚æœå¸¦æœ‰éå¹³é™æƒ…æ„Ÿä¸”é…ç½®äº† instructï¼Œå¼ºåˆ¶åŠ«æŒåˆ° design æ¨¡å¼
            if emotion != "å¹³é™" and "instruct" in voice_cfg:
                mode = "design"
                base_instruct = voice_cfg["instruct"]
                emotion_modifier = self.EMOTION_PROMPTS.get(emotion, "")
                generate_kwargs = {
                    "text": render_text,
                    "instruct": f"{base_instruct}. {emotion_modifier}".strip()
                }
                self._load_mode(mode)
                results = list(self.model.generate(**generate_kwargs))
            else:
                self._load_mode(mode)

                if mode == "clone":
                    # å…‹éš†æ¨¡å¼ï¼šé€šå¸¸ä½¿ç”¨ Base æ¨¡å‹
                    generate_kwargs = {
                        "text": render_text,
                        "ref_audio": voice_cfg.get("ref_audio", voice_cfg.get("audio", "")),
                        "ref_text": voice_cfg.get("ref_text", voice_cfg.get("text", ""))
                    }
                    # é˜²å¾¡æ€§è¿½åŠ ï¼šä»¥é˜²é”™è¯¯åœ°ç”¨ CustomVoice æ¨¡å‹è·‘ clone æ¨¡å¼
                    if "speaker" in voice_cfg or "voice" in voice_cfg:
                        generate_kwargs["voice"] = voice_cfg.get("voice", voice_cfg.get("speaker", self.default_voice))
                    
                    results = list(self.model.generate(**generate_kwargs))

                elif mode == "design":
                    # è®¾è®¡æ¨¡å¼ï¼šä½¿ç”¨æ–‡å­—æè¿°é©±åŠ¨éŸ³è‰²
                    results = list(self.model.generate(
                        text=render_text,
                        instruct=voice_cfg["instruct"]
                    ))

                else:
                    # ä¼ ç»Ÿ Preset / CustomVoice æ¨¡å¼
                    generate_kwargs = {
                        "text": render_text,
                    }
                    
                    # ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šå¼ºåˆ¶æå– voice å‚æ•°ï¼Œå…¼å®¹æ—§ç‰ˆ speaker å­—æ®µ
                    # å¦‚æœéƒ½æ²¡æœ‰æä¾›ï¼Œåˆ™ä½¿ç”¨é…ç½®çš„ default_voice ä½œä¸ºå®‰å…¨å…œåº•ï¼Œé˜²æ­¢å¼•æ“å´©æºƒ
                    target_voice = voice_cfg.get("voice", voice_cfg.get("speaker", self.default_voice))
                    generate_kwargs["voice"] = target_voice
                    
                    # å¦‚æœé…ç½®é‡Œå¸¦äº†å‚è€ƒéŸ³é¢‘ï¼ˆåŸºäºåŸºåº•éŸ³è‰²åšå¾®è°ƒå…‹éš†ï¼‰
                    if "audio" in voice_cfg and voice_cfg["audio"]:
                        generate_kwargs["ref_audio"] = voice_cfg["audio"]
                    if "text" in voice_cfg and voice_cfg["text"]:
                        generate_kwargs["ref_text"] = voice_cfg["text"]

                    results = list(self.model.generate(**generate_kwargs))
            
            audio_array = results[0].audio
            mx.eval(audio_array) # å¼ºåˆ¶æ‰§è¡Œ
            audio_data = np.array(audio_array)
            
            # åŒæ­¥å†™å…¥ç£ç›˜ï¼Œç¡®ä¿æµå¼APIèƒ½å¤Ÿç«‹å³è¯»å–
            sf.write(save_path, audio_data, self.sample_rate, format='WAV')
            logger.debug(f"âœ… å¹²éŸ³æ¸²æŸ“å®Œæˆ: {save_path}")
            return True
            
        except Exception as e:
            raise RuntimeError(f"âŒ MLX å¹²éŸ³æ¸²æŸ“å¤±è´¥ [{content[:10]}...]: {e}") from e
            
        finally:
            # æ¸…ç†å†…å­˜
            if 'results' in locals(): del results
            if 'audio_array' in locals(): del audio_array
            if 'audio_data' in locals(): del audio_data
            
            # MLX ç¼“å­˜æ¸…ç†
            mx.clear_cache()
            
            # ğŸŒŸ å¼ºåˆ¶å¬å›ï¼šåœ¨é•¿æ—¶é—´å¾ªç¯ä¸­ï¼Œå¿…é¡»ä¾é å¼ºç¡¬çš„ gc ä»‹å…¥æ¥é˜²å¾¡ç¢ç‰‡åŒ–
            # æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªå¾®å°çš„å¼€é”€ï¼Œå¼ºåˆ¶ Python æ¯å¤„ç†å®Œä¸€ä¸ªåˆ‡ç‰‡å°±å›æ”¶åºŸå¼ƒå¯¹è±¡
            gc.collect()

class CinecastMLXEngine:
    """å¢å¼ºå‹ MLX æ¨ç†å¼•æ“ã€‚

    åœ¨ MLXRenderEngine åŸºç¡€ä¸Šå°è£…é«˜å±‚æ¥å£ï¼Œæ”¯æŒï¼š
    - æŒ‡ä»¤åŒ–éŸ³è‰²è®¾è®¡ (Voice Design)
    - NPZ ç‰¹å¾é©±åŠ¨çš„å…‹éš†æ¨ç† (Voice Clone)
    - å¤šæ¨¡å¼ç»Ÿä¸€å…¥å£ (generate)
    - Mac mini ç»Ÿä¸€å†…å­˜ä¼˜åŒ–

    å¯ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯é…åˆ AudiobookOrchestrator ä½¿ç”¨ã€‚
    """

    def __init__(self, model_path: str, tokenizer_path: str = None, config=None):
        """åˆå§‹åŒ–å¢å¼ºå‹ MLX æ¨ç†å¼•æ“ã€‚

        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆ.safetensors æƒé‡ç›®å½•ï¼‰
            tokenizer_path: åˆ†è¯å™¨è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ model_path ç›¸åŒï¼‰
            config: å¯é€‰é…ç½®å­—å…¸ï¼Œä¸ MLXRenderEngine çš„ config å…¼å®¹
        """
        self.model_path = model_path
        self.tokenizer_path = tokenizer_path or model_path
        self.config = config or {}
        self.cache = {}
        self._render_engine = None
        self.sample_rate = 24000

        logger.info(f"ğŸš€ [CinecastMLXEngine] åˆå§‹åŒ–, æ¨¡å‹è·¯å¾„: {model_path}")

    def _ensure_render_engine(self):
        """å»¶è¿ŸåŠ è½½åº•å±‚æ¸²æŸ“å¼•æ“ã€‚"""
        if self._render_engine is None:
            self._render_engine = MLXRenderEngine(
                self.model_path, config=self.config
            )
            self.sample_rate = self._render_engine.sample_rate
        return self._render_engine

    def generate(self, text: str, mode: str = "base", **kwargs):
        """ç»Ÿä¸€æ¨ç†å…¥å£ã€‚

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            mode: æ¨ç†æ¨¡å¼
                - "design": æŒ‡ä»¤åŒ–éŸ³è‰²è®¾è®¡
                - "clone": NPZ ç‰¹å¾å…‹éš†
                - "custom"/"preset": å†…ç½®é¢„è®¾è§’è‰²
                - "base": åŸºç¡€æ¨¡å¼
            **kwargs: é¢å¤–å‚æ•°
                - instruct: éŸ³è‰²è®¾è®¡æŒ‡ä»¤ï¼ˆdesign æ¨¡å¼ï¼‰
                - prompt_npz: NPZ ç‰¹å¾å­—å…¸ï¼ˆclone æ¨¡å¼ï¼‰
                - language: è¯­è¨€ä»£ç 

        Returns:
            (audio_array, sample_rate) å…ƒç»„
        """
        if mode == "design":
            return self._run_voice_design(text, kwargs.get("instruct", ""))
        elif mode == "clone":
            prompt_npz = kwargs.get("prompt_npz")
            if prompt_npz is not None:
                return self.generate_voice_clone(text, prompt_npz)
            # æ—  NPZ ç‰¹å¾æ—¶å›é€€åˆ°åŸºç¡€æ¨¡å¼
            return self._run_base(text)
        elif mode in ("custom", "preset"):
            return self._run_preset(text, kwargs.get("voice"))
        else:
            return self._run_base(text)

    def generate_voice_design(self, text: str, instruct: str, lang: str = "zh"):
        """æŒ‡ä»¤åŒ–éŸ³è‰²è®¾è®¡ã€‚

        é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆç‹¬ç‰¹çš„è§’è‰²éŸ³è‰²ã€‚

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            instruct: éŸ³è‰²è®¾è®¡æŒ‡ä»¤ï¼ˆå¦‚"å¯Œæœ‰ç£æ€§çš„ä¸­å¹´ç”·æ€§ï¼Œè¯­é€Ÿæ²‰ç¨³"ï¼‰
            lang: è¯­è¨€ä»£ç 

        Returns:
            (audio_array, sample_rate) å…ƒç»„
        """
        return self._run_voice_design(text, instruct)

    def generate_voice_clone(self, text: str, role_feature):
        """åˆ©ç”¨å·²ä¿å­˜çš„ç‰¹å¾è¿›è¡Œå…‹éš†æ¨ç†ã€‚

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            role_feature: ä» .npz åŠ è½½çš„ç‰¹å¾å‘é‡å­—å…¸

        Returns:
            (audio_array, sample_rate) å…ƒç»„
        """
        engine = self._ensure_render_engine()

        # æ„å»ºå…‹éš†æ¨¡å¼çš„ voice_cfg
        voice_cfg = {"mode": "clone"}
        if isinstance(role_feature, dict):
            if "ref_audio" in role_feature:
                voice_cfg["ref_audio"] = str(role_feature["ref_audio"])
            if "ref_text" in role_feature:
                voice_cfg["ref_text"] = str(role_feature["ref_text"])
            if "spk_emb" in role_feature:
                voice_cfg["spk_emb"] = role_feature["spk_emb"]

        # ç›´æ¥åœ¨å†…å­˜ä¸­ç”ŸæˆéŸ³é¢‘ï¼Œé¿å…ç£ç›˜I/O
        try:
            # åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
            engine._load_mode(voice_cfg["mode"])
            results = list(engine.model.generate(text=text, **{k: v for k, v in voice_cfg.items() if k != "mode"}))
            
            if results:
                audio_array = results[0].audio
                mx.eval(audio_array)  # å¼ºåˆ¶æ‰§è¡Œè®¡ç®—
                audio_data = np.array(audio_array)
                return audio_data, self.sample_rate
            else:
                raise RuntimeError("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ— è¾“å‡ºç»“æœ")
                
        except Exception as e:
            logger.error(f"å…‹éš†éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise

    def _run_voice_design(self, text: str, instruct: str):
        """æ‰§è¡ŒéŸ³è‰²è®¾è®¡æ¨ç†ã€‚"""
        engine = self._ensure_render_engine()

        voice_cfg = {
            "mode": "design",
            "instruct": instruct,
        }

        # ç›´æ¥åœ¨å†…å­˜ä¸­ç”ŸæˆéŸ³é¢‘ï¼Œé¿å…ç£ç›˜I/O
        try:
            # åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
            engine._load_mode(voice_cfg["mode"])
            results = list(engine.model.generate(text=text, **{k: v for k, v in voice_cfg.items() if k != "mode"}))
            
            if results:
                audio_array = results[0].audio
                mx.eval(audio_array)  # å¼ºåˆ¶æ‰§è¡Œè®¡ç®—
                audio_data = np.array(audio_array)
                return audio_data, self.sample_rate
            else:
                raise RuntimeError("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ— è¾“å‡ºç»“æœ")
                
        except Exception as e:
            logger.error(f"éŸ³è‰²è®¾è®¡éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise

    def _run_preset(self, text: str, voice: str = None):
        """æ‰§è¡Œé¢„è®¾æ¨¡å¼æ¨ç†ã€‚"""
        engine = self._ensure_render_engine()

        voice_cfg = {"mode": "preset"}
        if voice:
            voice_cfg["voice"] = voice

        # ç›´æ¥åœ¨å†…å­˜ä¸­ç”ŸæˆéŸ³é¢‘ï¼Œé¿å…ç£ç›˜I/O
        try:
            # åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
            engine._load_mode(voice_cfg["mode"])
            results = list(engine.model.generate(text=text, **{k: v for k, v in voice_cfg.items() if k != "mode"}))
            
            if results:
                audio_array = results[0].audio
                mx.eval(audio_array)  # å¼ºåˆ¶æ‰§è¡Œè®¡ç®—
                audio_data = np.array(audio_array)
                return audio_data, self.sample_rate
            else:
                raise RuntimeError("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ— è¾“å‡ºç»“æœ")
                
        except Exception as e:
            logger.error(f"é¢„è®¾éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise

    def _run_base(self, text: str):
        """æ‰§è¡ŒåŸºç¡€æ¨¡å¼æ¨ç†ã€‚"""
        return self._run_preset(text)

    @staticmethod
    def _load_wav(path: str) -> np.ndarray:
        """ä» WAV æ–‡ä»¶åŠ è½½éŸ³é¢‘æ•°æ®ã€‚"""
        if not os.path.exists(path):
            return np.array([], dtype=np.float32)
        data, _ = sf.read(path, dtype="float32")
        return data

    def extract_voice_feature(self, audio_data: np.ndarray, sample_rate: int = 24000, ref_text: str = ""):
        """å¤„ç†å¹¶ä¿å­˜å…‹éš†éŸ³è‰²ç‰¹å¾ï¼ˆé‡‡ç”¨ Zero-Shot å‚è€ƒéŸ³é¢‘æ¨¡å¼ï¼‰"""
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
        if len(audio_data) == 0:
            raise ValueError("éŸ³é¢‘æ•°æ®ä¸ºç©º")
            
        # å½’ä¸€åŒ–éŸ³é¢‘æ•°æ®
        if np.max(np.abs(audio_data)) > 1.0:
            audio_data = audio_data / np.max(np.abs(audio_data))
            
        try:
            import os
            import uuid
            import soundfile as sf
            
            # å»ºç«‹æŒä¹…åŒ–çš„å…‹éš†éŸ³é¢‘æ–‡ä»¶å¤¹ (æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ voices/clones ä¸‹)
            clone_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "voices", "clones")
            os.makedirs(clone_dir, exist_ok=True)
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åå¹¶ä¿å­˜ (ä¸èƒ½ç”¨ tempfileï¼Œå› ä¸ºåç»­æ¨ç†è¿˜éœ€è¦è¯»å–å®ƒ)
            file_name = f"clone_{uuid.uuid4().hex[:8]}.wav"
            save_path = os.path.join(clone_dir, file_name)
            
            # ä¿å­˜ 24kHz çš„æ ‡å‡†åŒ–å‚è€ƒéŸ³é¢‘
            sf.write(save_path, audio_data, sample_rate)
            logger.info(f"âœ… å…‹éš†å‚è€ƒéŸ³é¢‘å·²æ°¸ä¹…ä¿å­˜è‡³: {save_path}ï¼Œå‚è€ƒæ–‡æœ¬ï¼š'{ref_text}'")
            
            # è¿”å›å…ç‰¹å¾æå–çš„ Zero-Shot é…ç½®å­—å…¸
            return {
                "mode": "clone",
                "ref_audio": save_path,
                "ref_text": ref_text  # ğŸš¨ å°†ç©ºç™½æ›¿æ¢ä¸ºé€ä¼ çš„çœŸå®æ–‡æœ¬
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å…‹éš†éŸ³è‰²å¤±è´¥: {e}ï¼Œå›é€€åˆ°é¢„è®¾éŸ³è‰²")
            return {"mode": "preset", "voice": "aiden"}

    def generate_with_feature(self, text: str, feature, language: str = "zh"): 
        """ä½¿ç”¨æŒ‡å®šç‰¹å¾ç”ŸæˆéŸ³é¢‘ï¼ˆç”¨äºæµå¼APIï¼‰

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            feature: éŸ³è‰²ç‰¹å¾
            language: è¯­è¨€ä»£ç 

        Returns:
            éŸ³é¢‘æ•°æ®æ•°ç»„
        """
        engine = self._ensure_render_engine()
        
        # æ„å»ºvoiceé…ç½® - æ ¹æ®featureç±»å‹é€‰æ‹©åˆé€‚çš„æ¨¡å¼
        if isinstance(feature, dict) and feature.get("mode") == "preset":
            # é¢„è®¾éŸ³è‰²æ¨¡å¼
            voice_cfg = {
                "mode": "preset",
                "voice": feature.get("voice", "aiden")
            }
        else:
            # å…‹éš†æ¨¡å¼
            voice_cfg = {"mode": "clone"}
            if isinstance(feature, dict):
                if "spk_emb" in feature:
                    voice_cfg["spk_emb"] = feature["spk_emb"]
                if "ref_audio" in feature:
                    voice_cfg["ref_audio"] = str(feature["ref_audio"])
                if "ref_text" in feature:
                    voice_cfg["ref_text"] = str(feature["ref_text"])
                if "voice" in feature:
                    voice_cfg["voice"] = feature["voice"]
        
        # ç›´æ¥åœ¨å†…å­˜ä¸­ç”ŸæˆéŸ³é¢‘ï¼Œé¿å…ç£ç›˜I/Oé˜»å¡
        try:
            # åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
            engine._load_mode(voice_cfg["mode"])
            results = list(engine.model.generate(text=text, **{k: v for k, v in voice_cfg.items() if k != "mode"}))
            
            if results:
                audio_array = results[0].audio
                mx.eval(audio_array)  # å¼ºåˆ¶æ‰§è¡Œè®¡ç®—
                audio_data = np.array(audio_array)
                return audio_data
            else:
                raise RuntimeError("éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šæ— è¾“å‡ºç»“æœ")
                
        except Exception as e:
            logger.error(f"éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
    
    def unload_model(self):
        """å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾ç»Ÿä¸€å†…å­˜ã€‚

        å»ºè®®åœ¨ç« èŠ‚å¤„ç†é—´éš™è°ƒç”¨ï¼Œé˜²æ­¢ Mac mini å†…å­˜è†¨èƒ€ã€‚
        """
        if self._render_engine is not None:
            self._render_engine.destroy()
            self._render_engine = None
        self.cache.clear()
        gc.collect()
        mx.metal.clear_cache()
        logger.info("ğŸ§¹ [CinecastMLXEngine] æ¨¡å‹å·²å¸è½½ï¼Œå†…å­˜å·²é‡Šæ”¾")

    def destroy(self):
        """é”€æ¯å¼•æ“ï¼Œé‡Šæ”¾æ‰€æœ‰èµ„æºã€‚"""
        self.unload_model()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
    try:
        engine = MLXRenderEngine()
        
        # æµ‹è¯•éŸ³è‰²é…ç½® (ä¼ ç»Ÿ preset æ¨¡å¼)
        test_voice_cfg = {
            "mode": "preset",
            "audio": "reference_for_production.wav",
            "text": "æµ‹è¯•å‚è€ƒæ–‡æœ¬",
            "speed": 1.0
        }
        
        # æµ‹è¯•æ¸²æŸ“ï¼ˆä½¿ç”¨ä¸‰æ®µå¼æ¶æ„çš„ render_dry_chunkï¼‰
        test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯MLXæ¸²æŸ“å¼•æ“æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
        test_save_path = "/tmp/cinecast_test_dry.wav"
        success = engine.render_dry_chunk(test_content, test_voice_cfg, test_save_path)
        
        if success:
            print(f"âœ… æ¸²æŸ“æˆåŠŸï¼Œå¹²éŸ³æ–‡ä»¶å·²å†™å…¥: {test_save_path}")
        else:
            print("âŒ æ¸²æŸ“å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")