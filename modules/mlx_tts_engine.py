#!/usr/bin/env python3
"""
CineCast MLXåº•å±‚æ¸²æŸ“å¼•æ“
é˜¶æ®µäºŒï¼šçº¯å‡€å¹²éŸ³æ¸²æŸ“ (Dry Voice Rendering)
åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
åŸºäºqwenttsé¡¹ç›®çš„æˆç†Ÿå®ç°

Supports an optional "group-by-voice" rendering strategy: instead of
rendering chunks in script order (which forces frequent voice-embedding
switches), callers can use ``group_indices_by_voice_type`` to cluster all
chunks that share the same voice first, render each cluster in one pass,
and then reassemble in the original order during Stage 3.
"""

import concurrent.futures
import gc
import os
import re
import warnings

# æ‹¦æˆª Tokenizer æ­£åˆ™è­¦å‘Šï¼Œä¿æŒç»ˆç«¯æ—¥å¿—çº¯å‡€
warnings.filterwarnings("ignore", message=".*incorrect regex pattern.*")
# å°è¯•å‘åº•å±‚ç¯å¢ƒå˜é‡æ³¨å…¥ä¿®å¤æ ‡å¿—ï¼ˆéƒ¨åˆ† transformers ç‰ˆæœ¬å…¼å®¹ï¼‰
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["FIX_MISTRAL_REGEX"] = "1"

import numpy as np
import soundfile as sf
import mlx.core as mx
from mlx_audio.tts.utils import load_model
import logging
from typing import List, Dict, Tuple
from collections import defaultdict

logger = logging.getLogger(__name__)


def group_indices_by_voice_type(
    micro_script: List[Dict],
) -> Dict[str, List[int]]:
    """Group script indices by their effective voice type.

    Returns a dict mapping voice-type keys (e.g. ``"narrator"``,
    ``"dialogue:è€æ¸”å¤«"``) to the list of indices in *micro_script* that
    should be rendered with that voice.  This allows the caller to render
    all chunks for a single voice consecutively, minimising MLX
    embedding switches and potentially improving throughput by 2-3Ã—.
    """
    groups: Dict[str, List[int]] = defaultdict(list)
    for idx, item in enumerate(micro_script):
        item_type = item.get("type", "narration")
        speaker = item.get("speaker", "narrator")
        if item_type in ("title", "subtitle", "narration", "recap"):
            key = item_type
        else:
            key = f"dialogue:{speaker}"
        groups[key].append(idx)
    return dict(groups)

class MLXRenderEngine:
    def __init__(self, model_path="./models/Qwen3-TTS-MLX-0.6B", config=None):
        """
        åˆå§‹åŒ–MLXçº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“ (æ”¯æŒ Qwen3-TTS 1.7B Model Pool)
        
        Args:
            model_path: é»˜è®¤æ¨¡å‹è·¯å¾„ (å…¼å®¹æ—§ç‰ˆå•æ¨¡å‹æ¨¡å¼)
            config: å¯é€‰é…ç½®å­—å…¸ï¼Œæ”¯æŒå¤šæ¨¡å‹è·¯å¾„ï¼š
                - model_path_base: 1.7B Base (å…‹éš†ç”¨)
                - model_path_design: 1.7B VoiceDesign (è®¾è®¡ç”¨)
                - model_path_custom: 1.7B CustomVoice (å†…ç½®è§’è‰²ç”¨)
                - model_path_fallback: 0.6B å›é€€è·¯å¾„
        """
        logger.info("ğŸš€ å¯åŠ¨ MLX çº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“...")
        self.config = config or {}
        self.current_mode = None
        self.model = None
        # åˆ›å»ºä¸“é—¨ç”¨äºç£ç›˜å†™å…¥çš„å•çº¿ç¨‹æ± ï¼Œé¿å…é˜»å¡æ¨ç†
        self.io_executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
        # ä¸¥æ ¼æ˜ å°„æœ¬åœ°æ¨¡å‹ï¼Œé¿å…æ„å¤–é™çº§
        self._model_paths = {
            "preset": self.config.get("model_path_custom", "./models/Qwen3-TTS-12Hz-1.7B-CustomVoice-4bit"),
            "design": self.config.get("model_path_design", "./models/Qwen3-TTS-12Hz-1.7B-VoiceDesign-4bit"),
            "clone": self.config.get("model_path_base", "./models/Qwen3-TTS-12Hz-1.7B-Base-4bit"),
        }
        self._fallback_path = self.config.get(
            "model_path_fallback", model_path
        )
        try:
            # é»˜è®¤åŠ è½½ï¼šå¦‚æœé…ç½®äº† preset è·¯å¾„åˆ™ç”¨ presetï¼Œå¦åˆ™ç”¨ä¼ å…¥çš„ model_path
            default_path = self._model_paths.get("preset") or model_path
            self._do_load(default_path, mode="preset")
            self.sample_rate = 24000  # Qwen3-TTS 1.7B é«˜ä¿çœŸé‡‡æ ·ç‡
            self.max_chars = 60  # å¾®åˆ‡ç‰‡å®‰å…¨é•¿åº¦ä¸Šé™
            logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ é¦–é€‰æ¨¡å‹åŠ è½½å¤±è´¥ ({e})ï¼Œå°è¯•å›é€€åˆ° 0.6B...")
            try:
                self._do_load(self._fallback_path, mode="preset")
                self.sample_rate = 22050  # 0.6B æ¨¡å‹ä½¿ç”¨æ—§é‡‡æ ·ç‡
                self.max_chars = 60
                logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–æˆåŠŸ (å›é€€åˆ° 0.6B)")
            except Exception as e2:
                logger.error(f"âŒ MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e2}")
                raise

    def _do_load(self, path, mode="preset"):
        """å®é™…åŠ è½½æ¨¡å‹åˆ°å†…å­˜"""
        if self.model is not None:
            del self.model
            self.model = None
            gc.collect()
            mx.clear_cache()
        self.model = load_model(path)
        self.current_mode = mode
        logger.info(f"âœ… å·²åŠ è½½æ¨¡å‹ [{mode}]: {path}")

    def _load_mode(self, mode):
        """æ ¹æ®ä»»åŠ¡ç±»å‹åˆ‡æ¢æ¨¡å‹ (Model Pool æ¨¡å¼)"""
        if mode == self.current_mode:
            return
        target_path = self._model_paths.get(mode)
        if not target_path:
            # æ²¡æœ‰é…ç½®å¯¹åº”æ¨¡å¼çš„è·¯å¾„ï¼Œä¿æŒå½“å‰æ¨¡å‹
            logger.debug(f"â­ï¸ æœªé…ç½® [{mode}] æ¨¡å‹è·¯å¾„ï¼Œä¿æŒå½“å‰æ¨¡å‹")
            return
        try:
            mx.clear_cache()
            self._do_load(target_path, mode=mode)
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ‡æ¢åˆ° [{mode}] æ¨¡å‹å¤±è´¥ ({e})ï¼Œä¿æŒå½“å‰æ¨¡å‹")

    def warmup(self, modes=None):
        """é¢„çƒ­æŒ‡å®šæ¨¡å¼çš„æ¨¡å‹ï¼ŒéªŒè¯è·¯å¾„å¯ç”¨æ€§

        Args:
            modes: è¦é¢„çƒ­çš„æ¨¡å¼åˆ—è¡¨ï¼Œå¦‚ ["preset", "clone"]ã€‚
                   é»˜è®¤é¢„çƒ­ preset æ¨¡å¼ã€‚
        """
        if modes is None:
            modes = ["preset"]
        for mode in modes:
            path = self._model_paths.get(mode)
            if path:
                logger.info(f"ğŸ”¥ é¢„çƒ­æ¨¡å‹ [{mode}]: {path}")
                try:
                    self._do_load(path, mode=mode)
                except Exception as e:
                    logger.warning(f"âš ï¸ é¢„çƒ­ [{mode}] å¤±è´¥: {e}")

    def _async_write_wav(self, path, data, sr):
        """åå°çº¿ç¨‹å†™å…¥ WAV æ–‡ä»¶ï¼Œé¿å…é˜»å¡æ¨ç†"""
        sf.write(path, data, sr, format='WAV')
        logger.debug(f"ğŸ’¾ å¼‚æ­¥å†™å…¥å®Œæˆ: {path}")

    def destroy(self):
        """æ˜¾å¼æ¸…ç† MLX æ¨¡å‹èµ„æºï¼Œé‡Šæ”¾æ˜¾å­˜"""
        if hasattr(self, 'io_executor') and self.io_executor is not None:
            self.io_executor.shutdown(wait=True)
        if hasattr(self, 'model') and self.model is not None:
            del self.model
            self.model = None
        self.current_mode = None
        mx.clear_cache()
        logger.info("ğŸ§¹ MLX æ¸²æŸ“å¼•æ“èµ„æºå·²æ˜¾å¼é‡Šæ”¾")
    
    # æƒ…æ„ŸæŒ‡ä»¤å­—å…¸ (æ˜ å°„åˆ° VoiceDesign çš„ instruct)
    EMOTION_PROMPTS = {
        "æ„¤æ€’": "Speaking with a harsh, angry, and aggressive tone, slightly louder.",
        "æ‚²ä¼¤": "Speaking slowly with a sad, melancholic, and tearful voice.",
        "æ¿€åŠ¨": "Speaking fast with high pitch, very excited and energetic.",
        "ææƒ§": "Speaking with a trembling, nervous, and scared voice.",
        "å¹³é™": "",  # ä¿æŒåŸºå‡†éŸ³è‰²
    }

    def render_dry_chunk(self, content: str, voice_cfg: dict, save_path: str, emotion: str = "å¹³é™") -> bool:
        """
        åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
        ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
        
        æ”¯æŒä¸‰ç§ voice_cfg æ¨¡å¼ (é€šè¿‡ "mode" å­—æ®µåŒºåˆ†)ï¼š
          - preset (é»˜è®¤): ä¼ ç»Ÿå‚è€ƒéŸ³é¢‘å…‹éš† {"mode": "preset", "audio": "...", "text": "..."}
          - clone: ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘å…‹éš† {"mode": "clone", "ref_audio": "...", "ref_text": "..."}
          - design: æ–‡å­—é©±åŠ¨è®¾è®¡ {"mode": "design", "instruct": "Deep male voice..."}
        
        Args:
            content: è¦æ¸²æŸ“çš„æ–‡æœ¬å†…å®¹
            voice_cfg: éŸ³è‰²é…ç½® (æ”¯æŒ preset/clone/design ä¸‰ç§æ¨¡å¼)
            save_path: ä¿å­˜è·¯å¾„
            emotion: æƒ…æ„Ÿæ ‡ç­¾ï¼Œæ”¯æŒ "å¹³é™"/"æ„¤æ€’"/"æ‚²ä¼¤"/"æ¿€åŠ¨"/"ææƒ§"
        """
        if os.path.exists(save_path):
            logger.debug(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æ¸²æŸ“: {save_path}")
            return True # ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
            
        try:
            render_text = content.strip()
            
            # ğŸŒŸ ç»ˆææš´åŠ›æ¸…æ´—ï¼šæ¶ˆç­ä¸€åˆ‡å¯¼è‡´å¤è¯»çš„ç‰¹æ®Šç¬¦å·
            render_text = re.sub(r'[â€¦]+', 'ã€‚', render_text)       # ä¸­æ–‡çœç•¥å·
            render_text = re.sub(r'\.{2,}', 'ã€‚', render_text)     # è‹±æ–‡çœç•¥å·ï¼ˆå«åŒç‚¹ï¼‰
            render_text = re.sub(r'[â€”]+', 'ï¼Œ', render_text)       # ä¸­æ–‡ç ´æŠ˜å·
            render_text = re.sub(r'[-]{2,}', 'ï¼Œ', render_text)    # è‹±æ–‡ç ´æŠ˜å·
            render_text = re.sub(r'[~ï½]+', 'ã€‚', render_text)     # æ³¢æµªå·
            # æ¸…æ´—æ‰€æœ‰å†…éƒ¨æ¢è¡Œå’Œå¼‚å¸¸ç©ºç™½
            render_text = re.sub(r'\s+', ' ', render_text).strip()
            # æ™ºèƒ½é˜²å¡æ­»æˆªæ–­ï¼šç»ä¸ç”Ÿç¡¬è…°æ–©å•è¯ï¼Œè€Œæ˜¯å¯»æ‰¾æœ€è¿‘çš„æ ‡ç‚¹
            if len(render_text) > self.max_chars:
                safe_text = render_text[:self.max_chars]
                # åŒ¹é…å¸¸è§ä¸­è‹±æ–‡æ–­å¥æ ‡ç‚¹ï¼Œä»åå¾€å‰æ‰¾æœ€åä¸€ä¸ª
                match = re.search(r'[ã€‚ï¼ï¼Ÿï¼›.,!?;]', safe_text)
                if match:
                    render_text = safe_text[:match.end()]
                else:
                    render_text = safe_text + "ã€‚"
            
            if not re.search(r'[ã€‚ï¼ï¼Ÿï¼›.!?;]$', render_text):
                render_text += "ã€‚"

            # ğŸŒŸ ç»æ€é˜²å¾¡ï¼šæ£€æŸ¥æ¸…ç†åæ˜¯å¦åªå‰©ä¸‹æ ‡ç‚¹ç¬¦å·ï¼ˆæ— å®é™…æ–‡å­—ï¼‰
            pure_text = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿï¼›ã€\u201c\u201d\u2018\u2019ï¼ˆï¼‰ã€Šã€‹,.!?;:\'\"()\s-]', '', render_text)
            if not pure_text:
                # æ ¹æ®æ®‹ç•™çš„æ ‡ç‚¹ç¬¦å·ç±»å‹ï¼ŒåŠ¨æ€å†³å®šé™éŸ³æ—¶é•¿
                original_text = content.strip()
                if "â€¦" in original_text or "..." in original_text:
                    duration = 0.6  # çœç•¥å·é•¿åœé¡¿
                elif "â€”" in original_text or "-" in original_text:
                    duration = 0.3  # ç ´æŠ˜å·ä¸­ç­‰åœé¡¿
                else:
                    duration = 0.15  # é€—å·ç­‰å…¶ä»–æ®‹ç•™çŸ­åœé¡¿

                logger.warning(f"âš ï¸ åˆ‡ç‰‡æ— æœ‰æ•ˆæ–‡å­—ï¼Œç”Ÿæˆ {duration}s åŠ¨æ€ç©ºç™½éŸ³é¢‘: {save_path}")
                audio_data = np.zeros(int(self.sample_rate * duration), dtype=np.float32)
                sf.write(save_path, audio_data, self.sample_rate, format='WAV')
                return True

            logger.debug(f"ğŸµ æ¸²æŸ“å¹²éŸ³: {render_text[:50]}... -> {save_path}")
            
            # ğŸŒŸ æ ¹æ® voice_cfg ä¸­çš„ mode å­—æ®µé€‰æ‹©æ¸²æŸ“ç­–ç•¥
            mode = voice_cfg.get("mode", "preset")

            # ğŸ’¡ æƒ…æ„Ÿæœ—è¯»ï¼šå¦‚æœå¸¦æœ‰éå¹³é™æƒ…æ„Ÿä¸”é…ç½®äº† instructï¼Œå¼ºåˆ¶åŠ«æŒåˆ° design æ¨¡å¼
            if emotion != "å¹³é™" and "instruct" in voice_cfg:
                mode = "design"
                base_instruct = voice_cfg["instruct"]
                emotion_modifier = self.EMOTION_PROMPTS.get(emotion, "")
                generate_kwargs = {
                    "text": render_text,
                    "instruct": f"{base_instruct}. {emotion_modifier}".strip()
                }
                self._load_mode(mode)
                results = list(self.model.generate(**generate_kwargs))
            else:
                self._load_mode(mode)

                if mode == "clone":
                    # å…‹éš†æ¨¡å¼ï¼šä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
                    results = list(self.model.generate(
                        text=render_text,
                        ref_audio=voice_cfg["ref_audio"],
                        ref_text=voice_cfg.get("ref_text", "")
                    ))
                elif mode == "design":
                    # è®¾è®¡æ¨¡å¼ï¼šä½¿ç”¨æ–‡å­—æè¿°é©±åŠ¨éŸ³è‰²
                    results = list(self.model.generate(
                        text=render_text,
                        instruct=voice_cfg["instruct"]
                    ))
                else:
                    # ä¼ ç»Ÿ Preset æ¨¡å¼ (å…¼å®¹æ—§ç‰ˆ)
                    generate_kwargs = {
                        "text": render_text,
                        "ref_audio": voice_cfg["audio"],
                        "ref_text": voice_cfg["text"],
                    }
                    # å¦‚æœ voice_cfg åŒ…å« speaker å­—æ®µ (CustomVoice å†…ç½®è§’è‰²,
                    # å¦‚ "Male_01", "Female_03" ç­‰ Qwen3-TTS é¢„è®¾è§’è‰² ID)
                    if "speaker" in voice_cfg:
                        generate_kwargs["speaker"] = voice_cfg["speaker"]
                    results = list(self.model.generate(**generate_kwargs))
            
            audio_array = results[0].audio
            mx.eval(audio_array) # å¼ºåˆ¶æ‰§è¡Œ
            audio_data = np.array(audio_array)
            
            # å¼‚æ­¥å†™å…¥ç£ç›˜ï¼Œé¿å…é˜»å¡ä¸‹ä¸€å¥çš„æ¨ç†
            self.io_executor.submit(self._async_write_wav, save_path, audio_data.copy(), self.sample_rate)
            logger.debug(f"âœ… å¹²éŸ³æ¸²æŸ“å®Œæˆ: {save_path}")
            return True
            
        except Exception as e:
            raise RuntimeError(f"âŒ MLX å¹²éŸ³æ¸²æŸ“å¤±è´¥ [{content[:10]}...]: {e}") from e
            
        finally:
            # æ¸…ç†å†…å­˜
            if 'results' in locals(): del results
            if 'audio_array' in locals(): del audio_array
            if 'audio_data' in locals(): del audio_data
            
            # MLX ç¼“å­˜æ¸…ç†
            mx.clear_cache()
            
            # ğŸŒŸ å¼ºåˆ¶å¬å›ï¼šåœ¨é•¿æ—¶é—´å¾ªç¯ä¸­ï¼Œå¿…é¡»ä¾é å¼ºç¡¬çš„ gc ä»‹å…¥æ¥é˜²å¾¡ç¢ç‰‡åŒ–
            # æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªå¾®å°çš„å¼€é”€ï¼Œå¼ºåˆ¶ Python æ¯å¤„ç†å®Œä¸€ä¸ªåˆ‡ç‰‡å°±å›æ”¶åºŸå¼ƒå¯¹è±¡
            gc.collect()

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
    try:
        engine = MLXRenderEngine()
        
        # æµ‹è¯•éŸ³è‰²é…ç½® (ä¼ ç»Ÿ preset æ¨¡å¼)
        test_voice_cfg = {
            "mode": "preset",
            "audio": "reference_for_production.wav",
            "text": "æµ‹è¯•å‚è€ƒæ–‡æœ¬",
            "speed": 1.0
        }
        
        # æµ‹è¯•æ¸²æŸ“ï¼ˆä½¿ç”¨ä¸‰æ®µå¼æ¶æ„çš„ render_dry_chunkï¼‰
        test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯MLXæ¸²æŸ“å¼•æ“æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
        test_save_path = "/tmp/cinecast_test_dry.wav"
        success = engine.render_dry_chunk(test_content, test_voice_cfg, test_save_path)
        
        if success:
            print(f"âœ… æ¸²æŸ“æˆåŠŸï¼Œå¹²éŸ³æ–‡ä»¶å·²å†™å…¥: {test_save_path}")
        else:
            print("âŒ æ¸²æŸ“å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")