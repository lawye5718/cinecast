#!/usr/bin/env python3
"""
CineCast MLXåº•å±‚æ¸²æŸ“å¼•æ“
é˜¶æ®µäºŒï¼šçº¯å‡€å¹²éŸ³æ¸²æŸ“ (Dry Voice Rendering)
åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
åŸºäºqwenttsé¡¹ç›®çš„æˆç†Ÿå®ç°
"""

import gc
import io
import os
import re
import numpy as np
import soundfile as sf
import mlx.core as mx
from mlx_audio.tts.utils import load_model
from pydub import AudioSegment
import logging
from typing import Dict

logger = logging.getLogger(__name__)

class MLXRenderEngine:
    def __init__(self, model_path="./models/Qwen3-TTS-MLX-0.6B"):
        """
        åˆå§‹åŒ–MLXçº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“
        
        Args:
            model_path: Qwen3-TTS-MLXæ¨¡å‹è·¯å¾„
        """
        logger.info("ğŸš€ å¯åŠ¨ MLX çº¯å‡€å¹²éŸ³æ¸²æŸ“å¼•æ“...")
        try:
            self.model = load_model(model_path)
            self.sample_rate = 22050
            self.max_chars = 60  # å¾®åˆ‡ç‰‡å®‰å…¨é•¿åº¦ä¸Šé™
            logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def render_dry_chunk(self, content: str, voice_cfg: dict, save_path: str) -> bool:
        """
        åªè´Ÿè´£å°†æ–‡æœ¬å˜æˆ WAV æ–‡ä»¶ï¼Œç»ä¸ç»´æŠ¤çŠ¶æ€
        ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
        """
        if os.path.exists(save_path):
            logger.debug(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æ¸²æŸ“: {save_path}")
            return True # ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼šå·²å­˜åœ¨åˆ™ç›´æ¥è·³è¿‡ï¼
            
        try:
            logger.debug(f"ğŸµ æ¸²æŸ“å¹²éŸ³: {content[:50]}... -> {save_path}")
            
            # MLX æé€Ÿæ¨ç†
            results = list(self.model.generate(
                text=content,
                ref_audio=voice_cfg["audio"],
                ref_text=voice_cfg["text"]
            ))
            
            audio_array = results[0].audio
            mx.eval(audio_array) # å¼ºåˆ¶æ‰§è¡Œ
            audio_data = np.array(audio_array)
            
            # ç›´æ¥å†™å…¥ç£ç›˜ï¼Œç»ä¸åœ¨å†…å­˜ä¸­ç§¯å‹
            sf.write(save_path, audio_data, self.sample_rate, format='WAV')
            logger.debug(f"âœ… å¹²éŸ³æ¸²æŸ“å®Œæˆ: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¹²éŸ³æ¸²æŸ“å¤±è´¥ [{content[:10]}...]: {e}")
            return False
            
        finally:
            # æ¸…ç†å†…å­˜
            if 'results' in locals(): del results
            if 'audio_array' in locals(): del audio_array
            if 'audio_data' in locals(): del audio_data
            mx.metal.clear_cache()
            gc.collect()
    
    def render_unit(self, content: str, voice_cfg: Dict) -> AudioSegment:
        """
        æ¸²æŸ“å•ä¸ªå‰§æœ¬å•å…ƒä¸ºAudioSegmentï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        ä¸ render_dry_chunk çš„åŒºåˆ«:
        - render_dry_chunk: ä¸‰æ®µå¼æ¶æ„æ¨èæ–¹æ³•ï¼Œç›´æ¥å†™å…¥ç£ç›˜WAVæ–‡ä»¶ï¼Œ
          æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå†…å­˜å ç”¨æ›´ä½
        - render_unit: æ—§æ¥å£ï¼Œè¿”å›å†…å­˜ä¸­çš„AudioSegmentå¯¹è±¡ï¼Œ
          é€‚ç”¨äºéœ€è¦ç›´æ¥æ“ä½œéŸ³é¢‘æ•°æ®çš„åœºæ™¯

        Args:
            content: è¦æ¸²æŸ“çš„æ–‡æœ¬å†…å®¹
            voice_cfg: éŸ³è‰²é…ç½®å­—å…¸ï¼ŒåŒ…å« audio, text, speed ç­‰å­—æ®µ

        Returns:
            AudioSegment: æ¸²æŸ“åçš„éŸ³é¢‘ç‰‡æ®µï¼Œå¤±è´¥æ—¶è¿”å›ç©ºAudioSegment
        """
        logger.warning("âš ï¸  ä½¿ç”¨æ—§æ¥å£render_unitï¼Œå»ºè®®è¿ç§»åˆ°render_dry_chunk")
        try:
            chunks = self._micro_chunk(content)
            unit_audio = AudioSegment.empty()

            for chunk in chunks:
                if not chunk.strip():
                    continue

                results = list(self.model.generate(
                    text=chunk,
                    ref_audio=voice_cfg["audio"],
                    ref_text=voice_cfg["text"]
                ))

                audio_array = results[0].audio
                mx.eval(audio_array)
                audio_data = np.array(audio_array)

                buffer = io.BytesIO()
                sf.write(buffer, audio_data, self.sample_rate, format='WAV')
                buffer.seek(0)
                segment = AudioSegment.from_file(buffer, format="wav")

                speed_factor = voice_cfg.get("speed", 1.0)
                if speed_factor != 1.0:
                    new_frame_rate = int(segment.frame_rate * speed_factor)
                    segment = segment._spawn(segment.raw_data, overrides={
                        "frame_rate": new_frame_rate
                    }).set_frame_rate(self.sample_rate)

                unit_audio += segment

                del results, audio_array, audio_data
                mx.metal.clear_cache()
                gc.collect()

            return unit_audio
        except Exception as e:
            logger.error(f"âŒ render_unitå¤±è´¥: {e}")
            return AudioSegment.empty()
    
    def _micro_chunk(self, text: str) -> list:
        """
        å¤šçº§å¾®åˆ‡ç‰‡ç®—æ³•
        ç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½ä¸è¶…è¿‡å®‰å…¨é•¿åº¦é™åˆ¶
        """
        if not text.strip():
            return []
        
        # ç¬¬ä¸€çº§ï¼šæŒ‰å¥å·/æ¢è¡Œç¬¦ç²—åˆ‡åˆ†
        raw_sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›\n])', text)
        sub_chunks = []
        
        # æ‹¼æ¥æ ‡ç‚¹ä¸å¥å­
        temp_sentence = ""
        for part in raw_sentences:
            if not part.strip():
                continue
            if re.match(r'^[ã€‚ï¼ï¼Ÿï¼›\n]$', part.strip()):
                temp_sentence += part
                sub_chunks.append(temp_sentence)
                temp_sentence = ""
            else:
                if temp_sentence:
                    sub_chunks.append(temp_sentence)
                temp_sentence = part
        if temp_sentence:
            sub_chunks.append(temp_sentence)
        
        # ç¬¬äºŒçº§ï¼šå¼ºåˆ¶ç»†åˆ†è¶…é•¿å¥
        fine_chunks = []
        for sentence in sub_chunks:
            if len(sentence) > self.max_chars:
                # æŒ‰é€—å·æˆ–é¡¿å·è¿›ä¸€æ­¥è‚¢è§£
                comma_parts = re.split(r'([ï¼Œã€ï¼š])', sentence)
                temp_comma = ""
                for cp in comma_parts:
                    if re.match(r'^[ï¼Œã€ï¼š]$', cp.strip()):
                        temp_comma += cp
                        fine_chunks.append(temp_comma)
                        temp_comma = ""
                    else:
                        temp_comma += cp
                        if len(temp_comma) >= self.max_chars:
                            fine_chunks.append(temp_comma)
                            temp_comma = ""
                if temp_comma:
                    fine_chunks.append(temp_comma)
            else:
                fine_chunks.append(sentence)
        
        # ç¬¬ä¸‰çº§ï¼šæ™ºèƒ½å›å¡«åˆå¹¶è¿‡çŸ­ç‰‡æ®µ
        final_chunks = []
        current_chunk = ""
        for fc in fine_chunks:
            fc = fc.strip()
            if not fc:
                continue
            if len(current_chunk) + len(fc) <= self.max_chars:
                current_chunk += " " + fc if current_chunk else fc
            else:
                if current_chunk:
                    final_chunks.append(current_chunk.strip())
                current_chunk = fc
        if current_chunk:
            final_chunks.append(current_chunk.strip())
        
        return [chunk for chunk in final_chunks if chunk.strip()]

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
    try:
        engine = MLXRenderEngine()
        
        # æµ‹è¯•éŸ³è‰²é…ç½®
        test_voice_cfg = {
            "audio": "reference_for_production.wav",
            "text": "æµ‹è¯•å‚è€ƒæ–‡æœ¬",
            "speed": 1.0
        }
        
        # æµ‹è¯•æ¸²æŸ“
        test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯MLXæ¸²æŸ“å¼•æ“æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
        audio_result = engine.render_unit(test_content, test_voice_cfg)
        
        print(f"âœ… æ¸²æŸ“æˆåŠŸï¼ŒéŸ³é¢‘æ—¶é•¿: {len(audio_result)/1000:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")