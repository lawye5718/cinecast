#!/usr/bin/env python3
"""
CineCast ä¸»æ§ç¨‹åº
ä¸‰æ®µå¼ç‰©ç†éš”ç¦»æ¶æ„ (Three-Stage Isolated Pipeline)
å®ç°100%é˜²å†…å­˜æº¢å‡ºå’Œæ–­ç‚¹ç»­ä¼ 
"""

import argparse
import gc
import os
import re
import sys
import json
import logging
import time
import requests
from bs4 import BeautifulSoup
import ebooklib
from ebooklib import epub
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from modules.asset_manager import AssetManager
from modules.llm_director import LLMScriptDirector, atomic_json_write
from modules.mlx_tts_engine import MLXRenderEngine, group_indices_by_voice_type
from modules.cinematic_packager import CinematicPackager
from logging.handlers import RotatingFileHandler

# é…ç½®æ—¥å¿— - ä½¿ç”¨è½®è½¬å¤„ç†å™¨é˜²æ­¢æ—¥å¿—æ–‡ä»¶æ— é™å¢é•¿
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# æ§åˆ¶å°å¤„ç†å™¨
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)

# æ–‡ä»¶è½®è½¬å¤„ç†å™¨ - æ¯ä¸ªæ–‡ä»¶æœ€å¤§ 10MBï¼Œä¿ç•™ 5 ä¸ªå¤‡ä»½æ–‡ä»¶
file_handler = RotatingFileHandler(
    'cinecast.log',
    encoding='utf-8',
    maxBytes=10 * 1024 * 1024,  # 10MB
    backupCount=5
)
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(file_formatter)

# æ·»åŠ å¤„ç†å™¨
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# æ¸²æŸ“è¶…æ—¶é˜ˆå€¼ï¼ˆç§’ï¼‰ã€‚
# å†·å¯åŠ¨é˜ˆå€¼ï¼šå¼•æ“åˆšåˆå§‹åŒ–æ—¶ï¼ŒMLX éœ€è¦ JIT ç¼–è¯‘ Metal ç€è‰²å™¨ï¼Œé¦–æ¬¡æ¨ç†è€—æ—¶è¾ƒé•¿ã€‚
ENGINE_COLD_START_THRESHOLD_SECONDS = 120.0
# çƒ­è¿è¡Œé˜ˆå€¼ï¼šå¼•æ“çƒ­èº«å®Œæˆåï¼Œæ­£å¸¸æ¸²æŸ“è¶…è¿‡æ­¤å€¼è§†ä¸ºå¤§æ¨¡å‹å¹»è§‰/å†…å­˜ç¢ç‰‡åŒ–ï¼Œè§¦å‘å¼•æ“çƒ­é‡å¯ã€‚
ENGINE_WARM_THRESHOLD_SECONDS = 45.0

class CineCastProducer:
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–CineCastä¸‰æ®µå¼ç”Ÿäº§çº¿
        
        Args:
            config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config or self._get_default_config()
        self.assets = AssetManager(self.config["assets_dir"])
        self.script_dir = os.path.join(self.config["output_dir"], "scripts")
        self.cache_dir = os.path.join(self.config["output_dir"], "temp_wav_cache")
        os.makedirs(self.script_dir, exist_ok=True)
        os.makedirs(self.cache_dir, exist_ok=True)

    def _create_tts_engine(self):
        """åˆ›å»º MLX TTS å¼•æ“ï¼Œæ”¯æŒ 1.7B Model Pool é…ç½®
        
        Returns:
            MLXRenderEngine: é…ç½®å¥½çš„ TTS å¼•æ“å®ä¾‹
        """
        engine_config = {}
        for key in ("model_path_base", "model_path_design",
                    "model_path_custom", "model_path_fallback",
                    "default_narrator_voice"):
            val = self.config.get(key)
            if val:
                engine_config[key] = val
        return MLXRenderEngine(self.config["model_path"], config=engine_config)

    def _get_default_config(self):
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "assets_dir": "./assets",
            "output_dir": "./output/Audiobooks",
            "model_path": "../qwentts/models/Qwen3-TTS-MLX-0.6B",  # ç›¸å¯¹äºcinecastç›®å½•
            "model_path_base": None,     # 1.7B Base (å…‹éš†ç”¨)
            "model_path_design": None,   # 1.7B VoiceDesign (è®¾è®¡ç”¨)
            "model_path_custom": None,   # 1.7B CustomVoice (å†…ç½®è§’è‰²ç”¨)
            "model_path_fallback": None, # 0.6B å›é€€è·¯å¾„
            "ambient_theme": "iceland_wind",  # ç¯å¢ƒéŸ³ä¸»é¢˜
            "target_duration_min": 30,  # ç›®æ ‡æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            "min_tail_min": 10,  # æœ€å°å°¾éƒ¨æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            "use_local_llm": True,  # æ˜¯å¦ä½¿ç”¨æœ¬åœ°LLM
            "enable_recap": True,  # ğŸŒŸ å‰æƒ…æè¦æ€»å¼€å…³
            "pure_narrator_mode": False,  # ğŸŒŸ çº¯å‡€æ—ç™½æ¨¡å¼å¼€å…³
            "user_recaps": None,  # ğŸŒŸ ç”¨æˆ·æä¾›çš„å‰æƒ…æè¦æ–‡æœ¬ï¼ˆè·³è¿‡LLMç”Ÿæˆï¼‰
            "global_cast": {},  # ğŸŒŸ å¤–è„‘å…¨å±€è§’è‰²è®¾å®šé›†ï¼ˆCharacter Bibleï¼‰
            "custom_recaps": {},  # ğŸŒŸ å¤–è„‘å‰æƒ…æè¦å­—å…¸ {Chapter_NNN: recap_text}
            "enable_auto_recap": True,  # ğŸŒŸ æ˜¯å¦å¯ç”¨æœ¬åœ°LLMè‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
            "default_narrator_voice": "aiden",  # ğŸŒŸ é»˜è®¤æ—ç™½åŸºåº•éŸ³è‰² (Qwen3-TTS Preset)
        }
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ä¸ªç»„ä»¶"""
        logger.info("ğŸ¬ åˆå§‹åŒ–CineCastç”µå½±çº§æœ‰å£°ä¹¦ç”Ÿäº§çº¿...")
        
        try:
            # 1. åˆå§‹åŒ–èµ„äº§ç®¡ç†ç³»ç»Ÿ
            self.assets = AssetManager(self.config["assets_dir"])
            logger.info("âœ… èµ„äº§ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # 2. åˆå§‹åŒ–LLMå‰§æœ¬å¯¼æ¼”
            self.director = LLMScriptDirector()
            logger.info("âœ… LLMå‰§æœ¬å¯¼æ¼”åˆå§‹åŒ–å®Œæˆ")
            
            # 3. åˆå§‹åŒ–MLXæ¸²æŸ“å¼•æ“
            model_path = self.config["model_path"]
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not os.path.isabs(model_path):
                model_path = os.path.join(project_root.parent, model_path)
            
            # æ„å»ºå¼•æ“é…ç½®ï¼ˆæ”¯æŒ 1.7B Model Poolï¼‰
            _path_keys = {"model_path_base", "model_path_design",
                          "model_path_custom", "model_path_fallback"}
            engine_config = {}
            for key in (*_path_keys, "default_narrator_voice"):
                val = self.config.get(key)
                if val and key in _path_keys and not os.path.isabs(val):
                    val = os.path.join(project_root.parent, val)
                if val:
                    engine_config[key] = val

            self.engine = MLXRenderEngine(model_path, config=engine_config)
            logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
            # 4. åˆå§‹åŒ–æ··éŸ³æ‰“åŒ…å™¨
            target_min = self.config.get("target_duration_min", 30)
            self.packager = CinematicPackager(self.config["output_dir"], target_duration_min=target_min)
            logger.info("âœ… æ··éŸ³æ‰“åŒ…å™¨åˆå§‹åŒ–å®Œæˆ")
            
            logger.info("ğŸ‰ æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    @staticmethod
    def _cn_to_int(cn_str: str) -> int:
        """è¾…åŠ©æ–¹æ³•ï¼šå°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—ã€‚

        æ”¯æŒï¼šé›¶-ä¹ã€åã€ç™¾ã€åƒã€ä¸¤ï¼ˆå¦‚ ä¸‰ç™¾å››åäº” -> 345ï¼Œä¸¤ç™¾ -> 200ï¼‰ã€‚
        çº¯é˜¿æ‹‰ä¼¯æ•°å­—å­—ç¬¦ä¸²ç›´æ¥è½¬æ¢ï¼ˆå¦‚ "123" -> 123ï¼‰ã€‚
        ä¸åœ¨æ˜ å°„è¡¨ä¸­çš„å­—ç¬¦ä¼šè¢«é™é»˜å¿½ç•¥ã€‚
        """
        cn_num = {'é›¶': 0, 'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9,
                  'å': 10, 'ç™¾': 100, 'åƒ': 1000, 'ä¸¤': 2}
        if cn_str.isdigit():
            return int(cn_str)
        result, temp = 0, 0
        for char in cn_str:
            if char in cn_num:
                val = cn_num[char]
                if val >= 10:
                    if temp == 0: temp = 1
                    result += temp * val
                    temp = 0
                else:
                    temp = val
        return result + temp

    @staticmethod
    def parse_user_recaps(raw_text: str) -> dict:
        """å¢å¼ºç‰ˆè§£æï¼šæ”¯æŒ'ç« 'ã€'å›'ï¼Œæ”¯æŒä¸­æ–‡æ•°å­—ï¼ˆå¦‚ç¬¬ä¸€ç™¾äºŒåå›ï¼‰

        æ”¯æŒçš„æ ¼å¼ï¼ˆæ¯ç« ä¹‹é—´ç”¨ç©ºè¡Œæˆ–ç« èŠ‚æ ‡è®°åˆ†éš”ï¼‰ï¼š
            ç¬¬1ç« ï¼šæ‘˜è¦å†…å®¹...
            ç¬¬2ç« ï¼šæ‘˜è¦å†…å®¹...
            ç¬¬ä¸€ç™¾äºŒåå›ï¼šæ‘˜è¦å†…å®¹...
        æˆ–ï¼š
            Chapter 1: recap text...
            Chapter 2: recap text...
        æˆ–ç®€å•çš„æŒ‰è¡Œåˆ†éš”ï¼ˆæ¯è¡Œå¯¹åº”ä¸€ç« çš„å‰æƒ…æè¦ï¼Œç¬¬1è¡Œç”¨äºç¬¬2ç« ï¼Œç¬¬2è¡Œç”¨äºç¬¬3ç« ï¼Œä»¥æ­¤ç±»æ¨ï¼‰ï¼š
            ç¬¬ä¸€ç« çš„æ‘˜è¦å†…å®¹ï¼ˆå°†ä½œä¸ºç¬¬2ç« çš„å‰æƒ…æè¦ï¼‰
            ç¬¬äºŒç« çš„æ‘˜è¦å†…å®¹ï¼ˆå°†ä½œä¸ºç¬¬3ç« çš„å‰æƒ…æè¦ï¼‰
        """
        if not raw_text or not raw_text.strip():
            return {}

        recaps = {}
        # å…¼å®¹: ç¬¬1ç« , ç¬¬ä¸€ç« , ç¬¬120å›, ç¬¬ä¸€ç™¾äºŒåå›, Chapter 1
        pattern = re.compile(
            r'(?:ç¬¬\s*([0-9é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸¤]+)\s*[ç« å›]|Chapter[_ ]?(\d+))\s*[ï¼š:]\s*(.+?)(?=\n\s*(?:ç¬¬\s*[0-9é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸¤]+\s*[ç« å›]|Chapter[_ ]?\d+)|$)',
            re.DOTALL | re.IGNORECASE
        )
        matches = pattern.findall(raw_text)

        if matches:
            for m in matches:
                # m[0] æ˜¯ä¸­æ–‡/é˜¿æ‹‰ä¼¯æ•°å­—(ç« /å›), m[1] æ˜¯ Chapter æ ¼å¼çš„æ•°å­—
                num_str = m[0] or m[1]
                chapter_num = CineCastProducer._cn_to_int(num_str)
                recap_text = m[2].strip()
                if recap_text and chapter_num > 0:
                    recaps[chapter_num] = recap_text
        else:
            # å›é€€ï¼šæŒ‰éç©ºè¡Œåˆ†å‰²ï¼Œç¬¬ N è¡Œå¯¹åº”ç¬¬ N+1 ç« ï¼ˆå› ä¸ºç¬¬1ç« æ²¡æœ‰å‰æƒ…æè¦ï¼‰
            lines = [line.strip() for line in raw_text.strip().split('\n') if line.strip()]
            for idx, line in enumerate(lines):
                recaps[idx + 2] = line  # ä»ç¬¬2ç« å¼€å§‹

        return recaps

    def _extract_epub_chapters(self, epub_path: str) -> dict:
        """ğŸŒŸ ä» EPUB æå–å¹²å‡€çš„ç« èŠ‚æ–‡æœ¬å­—å…¸ {ç« èŠ‚å: æ–‡æœ¬å†…å®¹}"""
        logger.info(f"ğŸ“– æ­£åœ¨è§£æ EPUB æ–‡ä»¶: {epub_path}")
        book = epub.read_epub(epub_path)
        chapters = {}
        for idx, item in enumerate(book.get_items_of_type(ebooklib.ITEM_DOCUMENT)):
            soup = BeautifulSoup(item.get_content(), 'html.parser')
            text = soup.get_text(separator='\n')
            clean_text = '\n'.join([line.strip() for line in text.split('\n') if line.strip()])
            if len(clean_text) > 20: # è¿‡æ»¤æçŸ­åºŸé¡µï¼ˆé™ä½é˜ˆå€¼ä»¥ä¿ç•™ç®€çŸ­ç« èŠ‚ï¼‰
                title = f"Chapter_{idx:03d}"
                chapters[title] = clean_text
        return chapters
    
    def check_api_connectivity(self):
        """å‰ç½®æ£€æŸ¥ï¼šéªŒè¯äº‘ç«¯ API è¿é€šæ€§ (DashScope Qwen-Flash)"""
        api_key = os.environ.get("DASHSCOPE_API_KEY", "")
        if not api_key:
            logger.error("âŒ æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œæ— æ³•ä½¿ç”¨ Qwen APIã€‚")
            return False
        try:
            response = requests.post(
                "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_key}",
                },
                json={
                    "model": "qwen-flash",
                    "messages": [{"role": "user", "content": "ping"}],
                    "max_tokens": 8,
                },
                timeout=10,
            )
            if response.status_code == 200:
                logger.info("âœ… Qwen API æœåŠ¡å‰ç½®æ£€æŸ¥é€šè¿‡")
                return True
            else:
                logger.error(f"âŒ Qwen API æœåŠ¡å“åº”å¼‚å¸¸ (HTTP {response.status_code})")
                return False
        except Exception as e:
            logger.error(f"âŒ Qwen API æœåŠ¡ä¸å¯è¾¾: {e}")
            return False

    # ==========================================
    # ğŸŒŸ å°è¯´é›†æ•…äº‹è¾¹ç•Œæ£€æµ‹ (Novella Collection Boundary Detection)
    # ==========================================
    @staticmethod
    def _is_new_story_start(chapter_name: str, content: str, prev_chapter_name: str = None) -> bool:
        """æ£€æµ‹å½“å‰ç« èŠ‚æ˜¯å¦æ˜¯å°è¯´é›†ä¸­æ–°æ•…äº‹çš„èµ·å§‹ã€‚

        é€šè¿‡ç« èŠ‚æ ‡é¢˜æ¨¡å¼åŒ¹é…åˆ¤æ–­ï¼šå¦‚æœç« èŠ‚åæš—ç¤º"ç¬¬ä¸€ç« "æˆ–"åºè¨€"ï¼Œ
        ä¸”ä¸æ˜¯å…¨ä¹¦çš„é¦–ä¸ªç« èŠ‚ï¼Œåˆ™è§†ä¸ºæ–°æ•…äº‹çš„å¼€å§‹ã€‚

        Args:
            chapter_name: å½“å‰ç« èŠ‚åç§°
            content: å½“å‰ç« èŠ‚å†…å®¹
            prev_chapter_name: ä¸Šä¸€ç« èŠ‚åç§°ï¼ˆNone è¡¨ç¤ºè¿™æ˜¯ç¬¬ä¸€ä¸ªç« èŠ‚ï¼‰

        Returns:
            True è¡¨ç¤ºæ£€æµ‹åˆ°æ–°æ•…äº‹çš„å¼€å§‹
        """
        if prev_chapter_name is None:
            return False

        # æ£€æµ‹"ç¬¬ä¸€ç« "ã€"ç¬¬1ç« "ã€"Chapter 1"ã€"åºç« "ã€"åºè¨€"ã€"æ¥”å­"ç­‰æ–°æ•…äº‹æ ‡å¿—
        new_story_patterns = [
            r'ç¬¬[ä¸€1]ç« ',
            r'åº[ç« è¨€]',
            r'æ¥”å­',
            r'(?i)chapter[_ ]?0*1\b',
            r'(?i)prologue',
        ]
        for pattern in new_story_patterns:
            if re.search(pattern, chapter_name):
                return True
            # ä¹Ÿæ£€æµ‹å†…å®¹å‰100å­—
            if re.search(pattern, content[:100]):
                return True

        return False

    @staticmethod
    def _find_recap_insert_index(micro_script: list) -> int:
        """Find the insertion index for recap entries.

        Scans the script for the first ``narration`` or ``dialogue`` entry and
        returns its index so that title / subtitle entries at the chapter
        beginning are preserved intact.  Falls back to index 0 when the script
        is empty or contains only header-type entries.
        """
        for i, entry in enumerate(micro_script):
            if entry.get("type") in ("narration", "dialogue"):
                return i
        return 0

    # ==========================================
    # ğŸ¬ é˜¶æ®µä¸€ï¼šå‰§æœ¬åŒ–ä¸å¾®åˆ‡ç‰‡ (Script & Micro-chunking)
    # ==========================================
    def phase_1_generate_scripts(self, input_source, max_chapters=None, is_preview=False):
        """é˜¶æ®µä¸€ï¼šç¼–å‰§æœŸ (Qwen API) - ç”ŸæˆåŒ…å«chunk_idå’Œåœé¡¿æ—¶é—´çš„å¾®åˆ‡ç‰‡å‰§æœ¬

        Args:
            input_source: EPUBæ–‡ä»¶è·¯å¾„æˆ–TXTç›®å½•è·¯å¾„
            max_chapters: æœ€å¤šå¤„ç†çš„ç« èŠ‚æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼Œè¯•å¬æ¨¡å¼ä¼ 1ï¼‰
            is_preview: æ˜¯å¦ä¸ºè¯•å¬æ¨¡å¼ï¼ˆå¼ºåˆ¶æ³¨å…¥æ‘˜è¦ã€æˆªæ–­å‰10å¥ï¼‰
        """
        logger.info("\n" + "="*50 + "\nğŸ¬ [é˜¶æ®µä¸€] ç¼–å‰§æœŸ (Qwen API)\n" + "="*50)
        
        pure_mode = self.config.get("pure_narrator_mode", False)

        # ğŸŒŸ å‰ç½®æ£€æŸ¥ï¼šçº¯å‡€æ¨¡å¼ä¸‹ä¸éœ€è¦ Qwen API æœåŠ¡
        if not pure_mode and not self.check_api_connectivity():
            logger.error("âŒ Qwen API æœåŠ¡ä¸å¯ç”¨ï¼Œé˜¶æ®µä¸€ä¸­æ­¢ã€‚è¯·æ£€æŸ¥ DASHSCOPE_API_KEY æ˜¯å¦å·²é…ç½®ã€‚")
            return False

        # æ”¯æŒEPUBå’ŒTXTä¸¤ç§è¾“å…¥æ ¼å¼
        if input_source.endswith('.epub'):
            chapters = self._extract_epub_chapters(input_source)
            if not chapters:
                logger.error("âŒ EPUB è§£æå¤±è´¥æˆ–æ— æœ‰æ•ˆæ–‡æœ¬ï¼")
                return False

        # ğŸŒŸ ä¿®å¤ï¼šæ–°å¢æ”¯æŒ WebUI ä¸Šä¼ å•æ–‡ä»¶ TXT æ¨¡å¼
        elif os.path.isfile(input_source) and input_source.endswith(('.txt', '.md')):
            try:
                with open(input_source, 'r', encoding='utf-8') as f:
                    chapters = {os.path.splitext(os.path.basename(input_source))[0]: f.read()}
            except UnicodeDecodeError:
                logger.error("âŒ æ–‡æœ¬è¯»å–å¤±è´¥ï¼šè¯·ç¡®ä¿ä½ çš„ TXT æ–‡ä»¶æ˜¯æ ‡å‡†çš„ UTF-8 ç¼–ç ï¼")
                return False
            except OSError as e:
                logger.error(f"âŒ æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                return False

        else:
            # å¤„ç†TXTç›®å½•
            text_files = sorted([f for f in os.listdir(input_source) if f.endswith(('.txt', '.md'))])
            if not text_files:
                logger.error(f"âŒ ç›®å½• {input_source} ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå‰§æœ¬ï¼")
                return False
            chapters = {}
            for file_name in text_files:
                with open(os.path.join(input_source, file_name), 'r', encoding='utf-8') as f:
                    chapters[os.path.splitext(file_name)[0]] = f.read()

        # ğŸŒŸ è¯•å¬æ¨¡å¼ä¼˜åŒ–ï¼šåªå¤„ç†å‰ max_chapters ä¸ªç« èŠ‚ï¼Œé¿å…å…¨ä¹¦è§£æ
        if max_chapters is not None:
            chapter_items = list(chapters.items())[:max_chapters]
            chapters = dict(chapter_items)
            logger.info(f"ğŸ§ è¯•å¬æ¨¡å¼ï¼šä»…å¤„ç†å‰ {max_chapters} ä¸ªç« èŠ‚")
        
        # ğŸŒŸ è¯•å¬æ¨¡å¼æ ¸å¿ƒæ‹¦æˆªï¼šåªå–ç¬¬ä¸€ç« ï¼Œä¸”åªä¿ç•™å‰1000å­—
        if is_preview:
            first_chap_key = list(chapters.keys())[0]
            first_chap_content = chapters[first_chap_key][:1000]
            chapters = {first_chap_key: first_chap_content}
            logger.info(f"ğŸ§ è¯•å¬é˜²å¡æ­»ï¼šå·²åˆ‡æ–­å…¨ä¹¦éå†ï¼Œä»…å¤„ç†é¦–ç« å‰1000å­—")

        # ğŸŒŸ é¡¹ç›®çº§è§’è‰²åº“ç‰©ç†éš”ç¦»ï¼šæ ¹æ®è¾“å…¥æ–‡ä»¶ååŠ¨æ€ç”Ÿæˆ cast_db_path
        project_name = os.path.splitext(os.path.basename(input_source))[0]
        cast_db_path = os.path.join("workspace", f"{project_name}_cast.json")

        director = LLMScriptDirector(
            global_cast=self.config.get("global_cast", {}),
            cast_db_path=cast_db_path,
        )
        prev_chapter_content = None  # ç”¨äºå­˜å‚¨ä¸Šä¸€ç« å†…å®¹
        failed_chapters = []

        # ğŸŒŸ è§£æç”¨æˆ·æä¾›çš„å‰æƒ…æè¦ï¼ˆå¦‚æœæœ‰ï¼‰
        user_recaps = {}
        user_recap_text = self.config.get("user_recaps")
        if user_recap_text:
            user_recaps = self.parse_user_recaps(user_recap_text)
            if user_recaps:
                logger.info(f"ğŸ“‹ æ£€æµ‹åˆ°ç”¨æˆ·æä¾›çš„å‰æƒ…æè¦ï¼Œå…± {len(user_recaps)} ç« ")

        # ğŸŒŸ è·å–å¤–è„‘æä¾›çš„å‰æƒ…æè¦å­—å…¸ (æŒ‰ç« èŠ‚åç´¢å¼•, å¦‚ "Chapter_002")
        custom_recaps = self.config.get("custom_recaps", {})

        story_chapter_index = 0  # ğŸŒŸ æ­£æ–‡ç« èŠ‚è®¡æ•°å™¨ï¼Œåªå¯¹æ­£æ–‡ç´¯åŠ ï¼Œç¡®ä¿ä¸ç”¨æˆ·æä¾›çš„ç¬¬Nç« ç²¾ç¡®å¯¹é½
        prev_chapter_name = None  # ğŸŒŸ ç”¨äºå°è¯´é›†è¾¹ç•Œæ£€æµ‹
        for chapter_name, content in chapters.items():

            # ğŸŒŸ å…ˆåˆ¤å®šæ˜¯å¦ä¸ºæ­£æ–‡ï¼ˆç”¨äºæ­£æ–‡è®¡æ•°å™¨ç´¯åŠ ï¼‰
            is_main_text = True
            non_main_keywords = ["ç‰ˆæƒ", "ç›®å½•", "å‡ºç‰ˆ", "ISBN", "åºè¨€", "è‡´è°¢", "å‰è¨€", "å¼•è¨€", "æ¥”å­", "Project Gutenberg"]
            if len(content) < 500 or any(keyword in content[:200] for keyword in non_main_keywords):
                is_main_text = False

            # è¾…åŠ©é˜²å¾¡ï¼šå¦‚æœç‰©ç†æ–‡ä»¶åæ˜¯ 000 æˆ– 001ï¼Œä¸”å¼€å¤´æ²¡æœ‰æ˜ç¡®çš„"ç¬¬ä¸€ç« "æ ‡å¿—ï¼Œå¼ºåˆ¶è§†ä¸ºéæ­£æ–‡
            if re.search(r'(?i)chapter_00[01]\b', chapter_name) and not re.search(r'ç¬¬[ä¸€1]ç« ', content[:100]):
                is_main_text = False

            # ğŸŒŸ åªæœ‰æ­£æ–‡æ‰ç´¯åŠ è®¡æ•°å™¨ï¼Œç¡®ä¿ä¸å¤–éƒ¨ä¼ å…¥çš„ç¬¬Nç« ç²¾ç¡®å¯¹é½ï¼
            if is_main_text:
                story_chapter_index += 1

            # ğŸŒŸ å°è¯´é›† (Novella Collection) æ•…äº‹è¾¹ç•Œæ£€æµ‹ä¸ä¸Šä¸‹æ–‡é‡ç½®
            if self._is_new_story_start(chapter_name, content, prev_chapter_name):
                director.reset_context()
                prev_chapter_content = None  # é‡ç½®å‰æƒ…æè¦ä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢è·¨ä¹¦æ‘˜è¦æ±¡æŸ“

            prev_chapter_name = chapter_name
            script_path = os.path.join(self.script_dir, f"{chapter_name}_micro.json")
            if os.path.exists(script_path) and not is_preview:
                logger.info(f"â­ï¸ å¾®åˆ‡ç‰‡å‰§æœ¬å·²å­˜åœ¨ï¼Œè·³è¿‡: {chapter_name}")
                # ä¿ç•™å·²æœ‰ç« èŠ‚çš„æ–‡æœ¬ç»™ä¸‹ä¸€ç« ç”¨
                prev_chapter_content = content
                continue
                
            logger.info(f"âœï¸ æ­£åœ¨è°ƒç”¨ Qwen-Flash è§£æå‰§æœ¬: {chapter_name} (å­—æ•°: {len(content)})")
            try:
                # ğŸŒŸ æ ¸å¿ƒåŒè½¨åˆ¶åˆ†æµï¼šçº¯å‡€æ¨¡å¼ æˆ– éæ­£æ–‡å†…å®¹ï¼Œç›´æ¥èµ°çº¯å‡€æ—ç™½æ¨¡å¼ï¼ˆå… LLMï¼‰
                if pure_mode or not is_main_text:
                    logger.info(f"âš¡ {'çº¯å‡€æ—ç™½æ¨¡å¼' if pure_mode else 'æ£€æµ‹åˆ°é™„å±æ–‡æœ¬(åºè¨€/ç‰ˆæƒ)'}ï¼Œå¯ç”¨å…LLMè§„åˆ™è§£æ: {chapter_name}")
                    micro_script = director.generate_pure_narrator_script(content, chapter_prefix=chapter_name)
                else:
                    # ğŸŒŸ Qwen-Flash æ•´ç« ç›´å‡ºï¼Œè®¾ä¸º 10000 æ—¢é«˜æ•ˆåˆç»å¯¹é˜²æ­¢ 32K è¾“å‡ºæº¢å‡º
                    micro_script = director.parse_and_micro_chunk(
                        content, chapter_prefix=chapter_name,
                        max_length=10000  # ğŸŒŸ è§£é™¤ 4000 å°å°ï¼Œå¯¹é½åº•å±‚å¼•æ“çš„æœ€ä½³ç”œç‚¹ä½
                    )
                
                # éªŒè¯ç”Ÿæˆçš„å‰§æœ¬æ•°æ®ç»“æ„
                if not micro_script:
                    logger.error(f"âŒ {chapter_name} ç”Ÿæˆçš„å¾®åˆ‡ç‰‡å‰§æœ¬ä¸ºç©ºï¼Œè·³è¿‡è¯¥ç« èŠ‚")
                    failed_chapters.append(chapter_name)
                    continue
                
                # ğŸŒŸ æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½å‰æƒ…æè¦åˆ¤æ–­ï¼ˆçº¯å‡€æ¨¡å¼ä¸‹è·³è¿‡ï¼‰
                recap_injected = False
                if not pure_mode:
                    recap_text = None

                    # ğŸŒŸ 1. å¼ºåˆ¶æœ€é«˜ä¼˜å…ˆçº§ï¼šåªè¦ç”¨æˆ·/å¤–è„‘æä¾›äº†å‰æƒ…æè¦ï¼Œæ— è§†ç« èŠ‚é•¿åº¦ï¼Œç›´æ¥ä½¿ç”¨ï¼
                    if chapter_name in custom_recaps:
                        recap_text = custom_recaps[chapter_name]
                        logger.info(f"ğŸ“‹ å¼ºåˆ¶ä½¿ç”¨å¤–è„‘æä¾›çš„å‰æƒ…æè¦: {chapter_name}")
                    elif story_chapter_index in user_recaps:
                        recap_text = user_recaps[story_chapter_index]
                        logger.info(f"ğŸ“‹ å¼ºåˆ¶ä½¿ç”¨ç”¨æˆ·æä¾›çš„å‰æƒ…æè¦ (åŒ¹é…æ­£æ–‡ç¬¬ {story_chapter_index} ç« ): {chapter_name}")
                    
                    # ğŸŒŸ 2. å¦‚æœç”¨æˆ·æ²¡æä¾›ï¼Œå†å»åˆ¤æ–­æ˜¯å¦æ˜¯æ­£æ–‡ï¼Œä»¥åŠæ˜¯å¦éœ€è¦å¤§æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆ
                    elif self.config.get("enable_recap", True):
                        if not is_main_text:
                            logger.info(f"â­ï¸ åˆ¤å®š {chapter_name} ä¸ºéæ­£æ–‡/çŸ­ç« èŠ‚ï¼Œè·³è¿‡ç”Ÿæˆå‰æƒ…æ‘˜è¦ã€‚")

                        if is_main_text and self.config.get("enable_auto_recap", True) and prev_chapter_content is not None:
                            if len(prev_chapter_content) >= 800:
                                logger.info(f"ğŸ”„ æ­£åœ¨ä¸º {chapter_name} ç”Ÿæˆå‰æƒ…æ‘˜è¦ (Map-Reduce å¼•æ“)...")
                                recap_text = director.generate_chapter_recap(prev_chapter_content)

                    # ğŸŒŸ 3. æ‰§è¡Œæè¦æ³¨å…¥
                    if recap_text:
                        intro_unit = {
                            "chunk_id": f"{chapter_name}_recap_intro",
                            "type": "recap",
                            "speaker": "talkover",
                            "content": "å‰æƒ…æè¦ï¼š",
                            "pause_ms": 500
                        }
                        recap_unit = {
                            "chunk_id": f"{chapter_name}_recap_body",
                            "type": "recap",
                            "speaker": "talkover",
                            "content": recap_text,
                            "pause_ms": 1500
                        }
                        # å®‰å…¨æ’å…¥æ³•ï¼šæ‰«æç¬¬ä¸€ä¸ª narration/dialogue ä½ç½®ï¼Œä¿æŒæ ‡é¢˜ç»“æ„å®Œæ•´
                        insert_idx = self._find_recap_insert_index(micro_script)
                        micro_script.insert(insert_idx, intro_unit)
                        micro_script.insert(insert_idx + 1, recap_unit)
                        recap_injected = True

                # ğŸŒŸ è¯•å¬å¼ºåˆ¶æ³¨å…¥é€»è¾‘ï¼ˆæ ¸å¿ƒï¼‰
                # å¦‚æœæ˜¯è¯•å¬æ¨¡å¼ï¼Œä¸”åŸæœ¬è¿™ç« æ²¡æ‘˜è¦ï¼ˆæ¯”å¦‚ç¬¬ä¸€ç« ï¼‰ï¼Œä½†ç”¨æˆ·ä¼ äº†å¤–è„‘å­—å…¸ï¼Œæˆ‘ä»¬å°±å¼ºè¡Œå€Ÿç”¨ä¸€æ¡æ¥è¯•å¬ï¼
                if is_preview and not recap_injected and custom_recaps:
                    borrowed_recap = next(iter(custom_recaps.values()))
                    logger.info(f"ğŸ§ è¯•å¬è¿é€šæ€§æµ‹è¯•ï¼šå¼ºåˆ¶å€Ÿç”¨ä¸€æ¡å‰æƒ…æè¦è¿›è¡Œ Talkover éŸ³è‰²éªŒè¯ï¼")
                    intro_unit = {
                        "chunk_id": f"{chapter_name}_recap_intro",
                        "type": "recap",
                        "speaker": "talkover",
                        "content": "å‰æƒ…æè¦ï¼š",
                        "pause_ms": 500
                    }
                    recap_unit = {
                        "chunk_id": f"{chapter_name}_recap_body",
                        "type": "recap",
                        "speaker": "talkover",
                        "content": borrowed_recap,
                        "pause_ms": 1500
                    }
                    # ğŸŒŸ å®‰å…¨æ’å…¥æ³•ï¼šæ‰«æç¬¬ä¸€ä¸ª narration/dialogue ä½ç½®ï¼Œä¿æŒæ ‡é¢˜ç»“æ„å®Œæ•´
                    insert_idx = self._find_recap_insert_index(micro_script)
                    micro_script.insert(insert_idx, intro_unit)
                    micro_script.insert(insert_idx + 1, recap_unit)
                
                # ä¿å­˜å½“å‰ç« çš„åŸå§‹æ–‡æœ¬ï¼Œä¾›ä¸‹ä¸€ç« ä½¿ç”¨
                prev_chapter_content = content
                
                # ğŸŒŸ è¯•å¬æ¨¡å¼æé€Ÿæˆªæ–­ï¼šåªä¿ç•™å‰ 10 å¥è¯ï¼ˆåŒ…å«åˆšæ³¨å…¥çš„æè¦ï¼‰
                if is_preview:
                    micro_script = micro_script[:10]
                
                # éªŒè¯æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å¿…éœ€çš„å­—æ®µ
                valid = True
                for i, item in enumerate(micro_script):
                    required_fields = ['chunk_id', 'type', 'speaker', 'content']
                    missing_fields = [field for field in required_fields if field not in item]
                    if missing_fields:
                        logger.error(f"âŒ {chapter_name} ç¬¬{i+1}ä¸ªç‰‡æ®µç¼ºå°‘å­—æ®µ: {missing_fields}")
                        logger.error(f"   ç‰‡æ®µå†…å®¹: {item}")
                        valid = False
                        break

                if not valid:
                    logger.error(f"âŒ ç« èŠ‚ {chapter_name} æ•°æ®æ ¡éªŒå¤±è´¥ï¼Œè·³è¿‡è¯¥ç« ")
                    failed_chapters.append(chapter_name)
                    continue
                
                # ğŸŒŸ åŸå­åŒ–å†™å…¥ï¼šé˜²æ­¢ä¸­æ–­å¯¼è‡´ JSON æŸå
                atomic_json_write(script_path, micro_script)
                logger.info(f"âœ… ç”Ÿæˆå¾®åˆ‡ç‰‡å‰§æœ¬: {script_path} ({len(micro_script)}ä¸ªç‰‡æ®µ)")
            except Exception as e:
                logger.error(f"âŒ ç« èŠ‚ {chapter_name} è§£æä¸¥é‡å¤±è´¥ï¼Œè·³è¿‡è¯¥ç« : {e}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                failed_chapters.append(chapter_name)
                continue
                
        # é˜¶æ®µä¸€å®Œæˆï¼ˆQwen API æ— éœ€é‡Šæ”¾æœ¬åœ°å†…å­˜ï¼‰

        if failed_chapters:
            logger.warning(f"âš ï¸ ä»¥ä¸‹ç« èŠ‚å¤„ç†å¤±è´¥: {', '.join(failed_chapters)}")

        logger.info("âœ… é˜¶æ®µä¸€å®Œæˆï¼Œå‰§æœ¬ç”Ÿæˆå·²å®Œæ¯•ï¼")
        return True
    
    # ==========================================
    # ğŸ§ è¯•å¬æ¨¡å¼ï¼šæé€Ÿé€šé“ï¼Œåªå¤„ç†å‰ 10 å¥è¯
    # ==========================================
    def run_preview_mode(self, input_source: str, preview_text: str = None) -> str:
        """ğŸŒŸ ä¸“å±çš„è¯•å¬æ¨¡å¼ï¼šæé€Ÿé€šé“ï¼Œæµ‹è¯•å¤–è„‘è¿é€šæ€§ï¼Œåªå¤„ç†å‰ 10 å¥è¯

        å½“ preview_text éç©ºæ—¶ï¼Œè·³è¿‡é˜¶æ®µä¸€ï¼ˆLLM åˆ‡ç‰‡ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ç”¨æˆ·åœ¨ç½‘é¡µ
        ä¸Šç¼–è¾‘çš„è¯•å¬æ–‡æœ¬æ„å»ºå¾®åˆ‡ç‰‡å‰§æœ¬ã€‚

        æµç¨‹ï¼šå…ˆå®Œæˆç¬¬ä¸€é˜¶æ®µå¾®åˆ‡ç‰‡ï¼Œå†ä»ç¬¬ä¸€ç« å‰§æœ¬ä¸­æˆªå–å‰ 10 å¥ï¼Œ
        å†™å…¥ç‹¬ç«‹çš„ä¸´æ—¶å‰§æœ¬æ–‡ä»¶ï¼ˆä¸è¦†ç›–åŸå§‹å‰§æœ¬ï¼‰ï¼Œç›´æ¥æ¸²æŸ“å¹¶å‹åˆ¶ã€‚
        """
        logger.info("ğŸ§ å¯åŠ¨æé€Ÿè¯•å¬é€šé“...")

        # ğŸŒŸ è¿é€šæ€§æ¢é’ˆï¼šæ£€æŸ¥å¤–è„‘æ•°æ®æ˜¯å¦æˆåŠŸç©¿é€ WebUI åˆ°è¾¾åº•å±‚
        global_cast = self.config.get("global_cast", {})
        custom_recaps = self.config.get("custom_recaps", {})

        if global_cast:
            logger.info(f"âœ… è¯•å¬è¿é€šæ€§æµ‹è¯•: æˆåŠŸæ¥æ”¶å¤–è„‘ã€è§’è‰²è®¾å®šé›†ã€‘ ({len(global_cast)} ä¸ªè§’è‰²)")
        else:
            logger.info(f"â„¹ï¸ è¯•å¬è¿é€šæ€§æµ‹è¯•: æœªæ£€æµ‹åˆ°å¤–è„‘è§’è‰²è®¾å®šï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ†é…ç­–ç•¥")

        if custom_recaps:
            logger.info(f"âœ… è¯•å¬è¿é€šæ€§æµ‹è¯•: æˆåŠŸæ¥æ”¶å¤–è„‘ã€å‰æƒ…æ‘˜è¦åº“ã€‘ ({len(custom_recaps)} ç« )")
        else:
            logger.info(f"â„¹ï¸ è¯•å¬è¿é€šæ€§æµ‹è¯•: æœªæ£€æµ‹åˆ°å¤–éƒ¨å‰æƒ…æ‘˜è¦")

        # ä¸´æ—¶å¼ºåˆ¶è®¾ä¸ºæçŸ­æ—¶é•¿ï¼Œè¿«ä½¿ CinematicPackager æå‰è§¦å‘å¯¼å‡º
        original_duration = self.config["target_duration_min"]
        self.config["target_duration_min"] = 0.5  # 30ç§’å°±å‘ç‰ˆ
        preview_script_path = os.path.join(self.script_dir, "_preview_temp_micro.json")

        try:
            # ğŸŒŸ å¦‚æœç”¨æˆ·æä¾›äº†ç¼–è¾‘åçš„è¯•å¬æ–‡æœ¬ï¼Œç›´æ¥æ„å»ºå¾®åˆ‡ç‰‡ï¼Œè·³è¿‡ LLM
            if preview_text and preview_text.strip():
                sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ!?])', preview_text)
                expanded = []
                for s in sentences:
                    expanded.extend(s.split('\n'))
                sentences = [s.strip() for s in expanded if s.strip()]
                preview_script = []
                for i, sent in enumerate(sentences[:10]):
                    preview_script.append({
                        "chunk_id": f"preview_{i:03d}",
                        "type": "narration",
                        "speaker": "narrator",
                        "gender": "unknown",
                        "emotion": "å¹³é™",
                        "content": sent,
                        "pause_ms": 300,
                    })
                logger.info(f"ğŸ§ ä½¿ç”¨ç”¨æˆ·ç¼–è¾‘çš„è¯•å¬æ–‡æœ¬ï¼ˆ{len(preview_script)} å¥ï¼‰")
            else:
                # â”€â”€ ç¬¬ä¸€é˜¶æ®µï¼šå¾®åˆ‡ç‰‡ï¼ˆä»…å¤„ç†ç¬¬ä¸€ç« ï¼Œä¼ å…¥ is_preview æ ‡è¯†ï¼‰â”€â”€
                self.phase_1_generate_scripts(input_source, is_preview=True)

                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”Ÿæˆçš„å‰§æœ¬
                script_files = sorted([f for f in os.listdir(self.script_dir) if f.endswith('_micro.json')])
                if not script_files:
                    raise Exception(f"æœªæ‰¾åˆ°å‰§æœ¬ï¼Œè¯·æ£€æŸ¥é˜¶æ®µä¸€æ˜¯å¦æˆåŠŸ (script_dir={self.script_dir})")

                first_script_path = os.path.join(self.script_dir, script_files[0])
                with open(first_script_path, 'r', encoding='utf-8') as f:
                    micro_script = json.load(f)

                # ğŸŒŸ æ ¸å¿ƒæˆªæ–­ï¼šåªå–å‰ 10 å¥ï¼
                preview_script = micro_script[:10]

            # ğŸŒŸ å†™å…¥ç‹¬ç«‹çš„ä¸´æ—¶é¢„è§ˆå‰§æœ¬ï¼Œä¸è¦†ç›–åŸå§‹å‰§æœ¬ï¼ˆä¿æŠ¤å…¨æœ¬å‹åˆ¶çš„æ–­ç‚¹ç»­ä¼ ï¼‰
            with open(preview_script_path, 'w', encoding='utf-8') as f:
                json.dump(preview_script, f, ensure_ascii=False)

            # â”€â”€ ç¬¬äºŒé˜¶æ®µï¼šä»…æ¸²æŸ“é¢„è§ˆç‰‡æ®µçš„å¹²éŸ³ â”€â”€
            self._render_script_chunks(preview_script)

            # â”€â”€ ç¬¬ä¸‰é˜¶æ®µï¼šä»…æ··éŸ³é¢„è§ˆç‰‡æ®µ â”€â”€
            self._mix_script_chunks(preview_script)

            # æ‰¾åˆ°å‹åˆ¶å‡ºçš„ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿”å›ç»™ç½‘é¡µ
            preview_files = [f for f in os.listdir(self.config["output_dir"]) if f.endswith('.mp3')]
            if preview_files:
                return os.path.join(self.config["output_dir"], sorted(preview_files)[0])
            return None

        finally:
            # æ¢å¤é…ç½®ä»¥å…æ±¡æŸ“æ­£å¼çš„å…¨æœ¬å‹åˆ¶
            self.config["target_duration_min"] = original_duration
            # æ¸…ç†ä¸´æ—¶é¢„è§ˆå‰§æœ¬ï¼ˆæ— è®ºæˆåŠŸ/å¤±è´¥éƒ½è¦æ¸…ç†ï¼‰
            if os.path.exists(preview_script_path):
                os.remove(preview_script_path)

    def _render_script_chunks(self, micro_script: list):
        """æ¸²æŸ“æŒ‡å®šçš„å¾®åˆ‡ç‰‡åˆ—è¡¨ä¸ºå¹²éŸ³ WAV æ–‡ä»¶ï¼ˆä¾›è¯•å¬æ¨¡å¼ç›´æ¥è°ƒç”¨ï¼‰"""
        from modules.mlx_tts_engine import MLXRenderEngine, group_indices_by_voice_type

        # æ„å»ºå¼•æ“é…ç½®ï¼ˆæ”¯æŒ 1.7B Model Poolï¼‰
        engine_config = {}
        for key in ("model_path_base", "model_path_design",
                    "model_path_custom", "model_path_fallback"):
            val = self.config.get(key)
            if val:
                engine_config[key] = val

        engine = self._create_tts_engine()

        voice_groups = group_indices_by_voice_type(micro_script)
        for voice_key, indices in voice_groups.items():
            first_item = micro_script[indices[0]]
            group_voice_cfg = self.assets.get_voice_for_role(
                first_item["type"],
                first_item.get("speaker"),
                first_item.get("gender")
            )
            for idx in indices:
                item = micro_script[idx]
                save_path = os.path.join(self.cache_dir, f"{item['chunk_id']}.wav")
                engine.render_dry_chunk(item["content"], group_voice_cfg, save_path)

        if hasattr(engine, 'destroy'):
            engine.destroy()
        del engine

    def _mix_script_chunks(self, micro_script: list):
        """å°†æŒ‡å®šçš„å¾®åˆ‡ç‰‡åˆ—è¡¨æ··éŸ³å‹åˆ¶ä¸º MP3ï¼ˆä¾›è¯•å¬æ¨¡å¼ç›´æ¥è°ƒç”¨ï¼‰"""
        target_min = self.config.get("target_duration_min", 30)
        packager = CinematicPackager(self.config["output_dir"], target_duration_min=target_min)

        if self.config.get("pure_narrator_mode", False):
            ambient_bgm = None
            chime_sound = None
        else:
            ambient_bgm = self.assets.get_ambient_sound(self.config["ambient_theme"])
            chime_sound = self.assets.get_transition_chime()

        packager.process_from_cache(micro_script, self.cache_dir, self.assets, ambient_bgm, chime_sound)

    # ==========================================
    # ğŸ™ï¸ é˜¶æ®µäºŒï¼šçº¯å‡€å¹²éŸ³æ¸²æŸ“ (Dry Voice Rendering)
    # ==========================================
    def phase_2_render_dry_audio(self):
        """é˜¶æ®µäºŒï¼šå½•éŸ³æœŸ (MLX TTS) - çº¯å‡€å¹²éŸ³æ¸²æŸ“ï¼Œåªäº§ç”ŸWAVæ–‡ä»¶
        
        Uses a "group-by-voice" strategy: chunks sharing the same voice type
        are rendered consecutively to minimise MLX embedding switches.
        """
        logger.info("\n" + "="*50 + "\nğŸ™ï¸ [é˜¶æ®µäºŒ] å½•éŸ³æœŸ (MLX TTS)\n" + "="*50)

        # æ„å»ºå¼•æ“é…ç½®ï¼ˆæ”¯æŒ 1.7B Model Poolï¼‰
        engine_config = {}
        for key in ("model_path_base", "model_path_design",
                    "model_path_custom", "model_path_fallback"):
            val = self.config.get(key)
            if val:
                engine_config[key] = val

        engine = self._create_tts_engine()

        # ğŸ”¥ é¢„çƒ­ï¼šåœ¨æ¸²æŸ“å¼€å§‹å‰é¢„åŠ è½½æ¨¡å‹ï¼Œåˆ©ç”¨ M4 ç»Ÿä¸€å†…å­˜å¸¦å®½ä¼˜åŠ¿
        warmup_modes = ["preset"]
        if engine_config.get("model_path_base"):
            warmup_modes.append("clone")
        engine.warmup(warmup_modes)
        
        # å…¨å±€å†·å¯åŠ¨æ ‡è®°ï¼Œå¼•æ“åˆšåˆå§‹åŒ–æ—¶å¿…å®šæ˜¯å†·å¯åŠ¨
        is_cold_start = True
        
        script_files = sorted([f for f in os.listdir(self.script_dir)
                               if f.endswith('_micro.json') and not f.startswith('_preview_')])
        total_chunks = 0
        rendered_chunks = 0
        
        for file in script_files:
            with open(os.path.join(self.script_dir, file), 'r', encoding='utf-8') as f:
                micro_script = json.load(f)
            total_chunks += len(micro_script)
            
            logger.info(f"ğŸ™ï¸ æ­£åœ¨æ¸²æŸ“å¹²éŸ³: {file} ({len(micro_script)}ä¸ªç‰‡æ®µ)")
            
            # ğŸŒŸ Group-by-voice ä¼˜åŒ–ï¼šæŒ‰è§’è‰²åˆ†ç»„æ‰¹é‡æ¸²æŸ“ï¼Œå‡å°‘ MLX éŸ³è‰²åˆ‡æ¢å¼€é”€
            voice_groups = group_indices_by_voice_type(micro_script)
            for voice_key, indices in voice_groups.items():
                logger.info(f"   ğŸ¤ æ¸²æŸ“éŸ³è‰²ç»„: {voice_key} ({len(indices)}ä¸ªç‰‡æ®µ)")
                # ğŸŒŸ ä¿®å¤ï¼šæ¯ä¸ªéŸ³è‰²ç»„åªè§£æä¸€æ¬¡ voice_cfgï¼Œç¡®ä¿ç»„å†…æ‰€æœ‰å¾®åˆ‡ç‰‡
                # ä½¿ç”¨å®Œå…¨ç›¸åŒçš„éŸ³è‰²é…ç½®ï¼Œæœç»éŸ³è‰²åœ¨å¾®åˆ‡ç‰‡ä¹‹é—´åˆ‡æ¢
                first_item = micro_script[indices[0]]
                group_voice_cfg = self.assets.get_voice_for_role(
                    first_item["type"],
                    first_item.get("speaker"),
                    first_item.get("gender")
                )
                for idx in indices:
                    item = micro_script[idx]
                    save_path = os.path.join(self.cache_dir, f"{item['chunk_id']}.wav")
                    
                    # æ–­ç‚¹ç»­ä¼ ï¼šç¼“å­˜å‘½ä¸­ç›´æ¥è·³è¿‡ï¼Œä¸å‚ä¸çœ‹é—¨ç‹—è®¡æ—¶
                    if os.path.exists(save_path):
                        rendered_chunks += 1
                        if rendered_chunks > 0 and rendered_chunks % 50 == 0:
                            logger.info(f"   ğŸµ è¿›åº¦: {rendered_chunks}/{total_chunks} ç‰‡æ®µå·²æ¸²æŸ“(è·³è¿‡)")
                        continue

                    start_time = time.time()

                    try:
                        success = engine.render_dry_chunk(item["content"], group_voice_cfg, save_path)
                        if not success:
                            logger.error(
                                f"ğŸ”‡ æ¸²æŸ“è¿”å›å¤±è´¥: chunk_id={item.get('chunk_id')}, "
                                f"speaker={item.get('speaker')}, "
                                f"content='{item['content'][:50]}...'"
                            )
                    except Exception as e:
                        import traceback
                        logger.error(
                            f"âŒ æ¸²æŸ“å¼‚å¸¸: chunk_id={item.get('chunk_id')}, "
                            f"speaker={item.get('speaker')}, "
                            f"content='{item['content'][:50]}...', "
                            f"error={e}"
                        )
                        logger.error(f"ğŸ“‹ å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
                        success = False

                    elapsed_time = time.time() - start_time
                    rendered_chunks += 1

                    # åŠ¨æ€çœ‹é—¨ç‹—é˜ˆå€¼ï¼ˆå†·å¯åŠ¨120ç§’ï¼Œçƒ­è¿è¡Œ45ç§’ï¼‰
                    timeout_threshold = ENGINE_COLD_START_THRESHOLD_SECONDS if is_cold_start else ENGINE_WARM_THRESHOLD_SECONDS

                    if elapsed_time > timeout_threshold:
                        logger.warning(
                            f"ğŸš¨ ä¸¥é‡è­¦å‘Š: åˆ‡ç‰‡ {item.get('chunk_id')} æ¸²æŸ“è€—æ—¶ "
                            f"{elapsed_time:.1f} ç§’ï¼(å½“å‰é˜ˆå€¼: {timeout_threshold}s)"
                        )
                        # ğŸ”¥ é”€æ¯è¶…æ—¶äº§ç”Ÿçš„è„éŸ³é¢‘ï¼Œé˜²æ­¢æ±¡æŸ“æ··éŸ³
                        if os.path.exists(save_path):
                            os.remove(save_path)
                            logger.info(f"ğŸ—‘ï¸ å·²é”€æ¯è¶…æ—¶äº§ç”Ÿçš„è„éŸ³é¢‘: {save_path}")
                        logger.info("ğŸ”„ æ­£åœ¨è§¦å‘å¼•æ“è‡ªæ„ˆé‡ç½®åè®®...")
                        if hasattr(engine, 'destroy'):
                            engine.destroy()
                        del engine
                        gc.collect()
                        logger.info("âœ¨ å†…å­˜å·²æ¸…ç©ºï¼Œæ­£åœ¨é‡æ–°åŠ è½½ MLX TTS å¼•æ“...")
                        engine = self._create_tts_engine()
                        logger.info("âœ… å¼•æ“çƒ­é‡å¯å®Œæˆï¼Œæ¢å¤ç”Ÿäº§ï¼")
                        # é‡å¯åçš„ä¸‹ä¸€ä¸ªç‰‡æ®µåˆå°†é¢ä¸´ JIT ç¼–è¯‘ï¼Œé‡ç½®ä¸ºå†·å¯åŠ¨çŠ¶æ€
                        is_cold_start = True
                        # è·³è¿‡å½“å‰å¤±è´¥ç‰‡æ®µçš„è¿›åº¦è®¡æ•°ï¼Œé‡æ–°æ¸²æŸ“
                        rendered_chunks -= 1
                        continue
                    else:
                        # æ¸²æŸ“åœ¨é˜ˆå€¼å†…å¹³ç¨³åº¦è¿‡ï¼Œå¼•æ“çƒ­èº«å®Œæ¯•ï¼Œåˆ‡æ¢ä¸ºä¸¥è‹›çŠ¶æ€
                        is_cold_start = False
                    
                    if rendered_chunks > 0 and rendered_chunks % 50 == 0:
                        logger.info(f"   ğŸµ è¿›åº¦: {rendered_chunks}/{total_chunks} ç‰‡æ®µå·²æ¸²æŸ“")
        
        # é‡Šæ”¾ MLX æ¨¡å‹æ˜¾å­˜
        if hasattr(engine, 'destroy'):
            engine.destroy()
        del engine
        logger.info(f"âœ… é˜¶æ®µäºŒå®Œæˆ ({rendered_chunks}/{total_chunks} ç‰‡æ®µ)ï¼ŒMLX å·²ä»å†…å­˜ä¸­å®‰å…¨æ’¤ç¦»ï¼")
        
    # ==========================================
    # ğŸ›ï¸ é˜¶æ®µä¸‰ï¼šç”µå½±çº§æ··éŸ³å‘ç‰ˆ (Cinematic Post-Processing)
    # ==========================================
    def phase_3_cinematic_mix(self):
        """é˜¶æ®µä¸‰ï¼šæ··éŸ³å‘ç‰ˆæœŸ (Pydub) - ä»å¹²éŸ³ç¼“å­˜ç»„è£…æˆç”µå½±çº§æœ‰å£°ä¹¦"""
        logger.info("\n" + "="*50 + "\nğŸ›ï¸ [é˜¶æ®µä¸‰] æ··éŸ³å‘ç‰ˆæœŸ (Pydub)\n" + "="*50)

        # ğŸŒŸ å‰ç½®æ£€æŸ¥ï¼šç¡®è®¤ç¼“å­˜ç›®å½•å­˜åœ¨æœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µ
        if os.path.isdir(self.cache_dir):
            wav_files = [f for f in os.listdir(self.cache_dir) if f.endswith('.wav')]
        else:
            wav_files = []
        if not wav_files:
            logger.warning("âš ï¸ æœªå‘ç°æœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µï¼Œè¯·æ£€æŸ¥å‰§æœ¬è§£æé˜¶æ®µï¼ˆé˜¶æ®µä¸€ï¼‰å’Œå¹²éŸ³æ¸²æŸ“é˜¶æ®µï¼ˆé˜¶æ®µäºŒï¼‰æ˜¯å¦æˆåŠŸã€‚è·³è¿‡æ··éŸ³ã€‚")
            return

        # ğŸŒŸ å…¨é‡è·³è¿‡ï¼šå¦‚æœåˆ†å·å·²å…¨éƒ¨å­˜åœ¨ä¸”å‰§æœ¬æ— æ›´æ–°ï¼Œç›´æ¥è·³è¿‡æ•´ä¸ªæ··éŸ³é˜¶æ®µ
        output_dir = self.config["output_dir"]
        existing_volumes = sorted([f for f in os.listdir(output_dir)
                                   if f.startswith("Audiobook_Part_") and f.endswith(".mp3")])
        script_files = sorted([f for f in os.listdir(self.script_dir)
                               if f.endswith('_micro.json') and not f.startswith('_preview_')])
        if existing_volumes and script_files:
            latest_volume_mtime = max(
                os.path.getmtime(os.path.join(output_dir, f)) for f in existing_volumes
            )
            latest_script_mtime = max(
                os.path.getmtime(os.path.join(self.script_dir, f)) for f in script_files
            )
            if latest_volume_mtime >= latest_script_mtime:
                logger.info(f"â­ï¸ æ£€æµ‹åˆ° {len(existing_volumes)} ä¸ªåˆ†å·å·²å­˜åœ¨ä¸”å‰§æœ¬æ— æ›´æ–°ï¼Œè·³è¿‡æ•´ä¸ªæ··éŸ³é˜¶æ®µ")
                return

        target_min = self.config.get("target_duration_min", 30)
        packager = CinematicPackager(self.config["output_dir"], target_duration_min=target_min)

        # ğŸŒŸ æ ¸å¿ƒæ‹¦æˆªï¼šçº¯å‡€æ¨¡å¼ä¸‹ï¼Œå¼ºè¡Œå°†éŸ³æ•ˆè®¾ä¸º None
        if self.config.get("pure_narrator_mode", False):
            logger.info("ğŸ”‡ çº¯å‡€æ¨¡å¼å·²å¼€å¯ï¼šå…³é—­ç¯å¢ƒèƒŒæ™¯éŸ³ä¸ç« èŠ‚è¿‡æ¸¡éŸ³æ•ˆ")
            ambient_bgm = None
            chime_sound = None
        else:
            ambient_bgm = self.assets.get_ambient_sound(self.config["ambient_theme"])
            chime_sound = self.assets.get_transition_chime()
        
        for file in script_files:
            with open(os.path.join(self.script_dir, file), 'r', encoding='utf-8') as f:
                micro_script = json.load(f)
            # ğŸŒŸ Pydub å¼€å§‹ç»„è£…ï¼Œæ­¤æ—¶å·²ç»æ²¡æœ‰å¤§æ¨¡å‹åœ¨æŠ¢å å†…å­˜äº†
            packager.process_from_cache(micro_script, self.cache_dir, self.assets, ambient_bgm, chime_sound)
        
        logger.info("ğŸ‰ ä¸‰æ®µå¼æ¶æ„å…¨æµç¨‹å®Œæˆï¼å…¨ä¹¦å‹åˆ¶å®Œæ¯•ï¼Œè¯·å‰å¾€ output ç›®å½•æŸ¥æ”¶ã€‚")

    def phase_4_quality_control(self, target_dir=None):
        """é˜¶æ®µå››ï¼šè´¨æ£€æœŸ (Audio Shield) - è‡ªåŠ¨æ‰«æå¹¶å¤„ç†çˆ†éŸ³

        Args:
            target_dir: è¦æ‰«æçš„ç›®å½•ã€‚é»˜è®¤ä¸º output_dirã€‚
        """
        logger.info("\n" + "="*50 + "\nğŸ” [é˜¶æ®µå››] è´¨æ£€æœŸ (Audio Shield)\n" + "="*50)

        # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
        output_dir = target_dir or self.config["output_dir"]
        if not os.path.exists(output_dir):
            logger.error("âŒ æœªå‘ç°è¾“å‡ºç›®å½•ï¼Œè´¨æ£€ä¸­æ­¢ã€‚")
            return

        # è‡ªåŠ¨æ‹‰èµ· GUIï¼Œå¹¶ç›´æ¥è¿›å…¥æ‰«ææ¨¡å¼
        from audio_shield.gui import launch_gui_with_context
        logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨è´¨æ£€å·¥ä½œå°...")

        # é€šè¿‡å°è£…åçš„å‡½æ•°å¯åŠ¨ï¼Œè‡ªåŠ¨è½½å…¥å½“å‰é¡¹ç›®çš„ output ç›®å½•
        launch_gui_with_context(output_dir, sensitivity=0.4)
    
def main():
    """ä¸»å‡½æ•° - å¼•å…¥å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="CineCast ç”µå½±çº§æœ‰å£°ä¹¦ç”Ÿäº§çº¿")
    parser.add_argument("input", nargs="?", default="./input_chapters", help="è¾“å…¥æ–‡ä»¶(EPUB)æˆ–ç›®å½•(TXT)")
    parser.add_argument("--pure-narrator", action="store_true", help="å¯ç”¨çº¯å‡€æ—ç™½æ¨¡å¼(å•éŸ³è‰²/æ— èƒŒæ™¯éŸ³/æ— æ‘˜è¦/å…LLM)")
    args = parser.parse_args()

    producer = CineCastProducer()
    producer.config["pure_narrator_mode"] = args.pure_narrator  # ğŸŒŸ å°†å‘½ä»¤è¡Œå‚æ•°å†™å…¥å…¨å±€é…ç½®
    input_source = args.input
    
    if input_source.endswith('.epub') and os.path.exists(input_source):
        logger.info(f"ğŸ“š æ£€æµ‹åˆ°EPUBæ–‡ä»¶: {input_source}")
    elif os.path.isfile(input_source) and input_source.endswith(('.txt', '.md')):
        logger.info(f"ğŸ“ æ£€æµ‹åˆ°å•æ–‡ä»¶TXTæ¨¡å¼: {input_source}")
    elif os.path.isdir(input_source):
        if not os.listdir(input_source):
            logger.warning(f"âš ï¸ è¯·å…ˆåœ¨ {input_source} æ–‡ä»¶å¤¹ä¸­æ”¾å…¥æµ‹è¯•ç”¨çš„ .txt ç« èŠ‚ï¼")
            with open(os.path.join(input_source, "ç¬¬ä¸€ç« _æµ‹è¯•.txt"), 'w', encoding='utf-8') as f:
                f.write("ç¬¬ä¸€ç«  é£é›ª\n1976å¹´\nå¤œå¹•é™ä¸´æ¸¯å£ã€‚\"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ\"è€æ¸”å¤«é—®ã€‚\n\"æˆ‘ä¸ä¿¡ã€‚\"å¹´è½»äººå›ç­”ã€‚")
        logger.info(f"ğŸ“ ä½¿ç”¨TXTç›®å½•æ¨¡å¼: {input_source}")
    else:
        # å›é€€åˆ°é»˜è®¤TXTç›®å½•æ¨¡å¼
        input_source = "./input_chapters"
        os.makedirs(input_source, exist_ok=True)
        if not os.listdir(input_source):
            logger.warning(f"âš ï¸ è¯·å…ˆåœ¨ {input_source} æ–‡ä»¶å¤¹ä¸­æ”¾å…¥æµ‹è¯•ç”¨çš„ .txt ç« èŠ‚ï¼")
            with open(os.path.join(input_source, "ç¬¬ä¸€ç« _æµ‹è¯•.txt"), 'w', encoding='utf-8') as f:
                f.write("ç¬¬ä¸€ç«  é£é›ª\n1976å¹´\nå¤œå¹•é™ä¸´æ¸¯å£ã€‚\"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ\"è€æ¸”å¤«é—®ã€‚\n\"æˆ‘ä¸ä¿¡ã€‚\"å¹´è½»äººå›ç­”ã€‚")
        logger.info(f"ğŸ“ ä½¿ç”¨TXTç›®å½•æ¨¡å¼: {input_source}")
    
    try:
        # ä¸¥æ ¼çš„ä¸‰æ®µå¼ä¸²è¡Œå¤„ç†ï¼Œå½»åº•åˆ‡æ–­å†…å­˜é‡å 
        if producer.phase_1_generate_scripts(input_source):
            producer.phase_2_render_dry_audio()

            # ğŸ›¡ï¸ æ–°å¢ï¼šé˜¶æ®µäºŒåè´¨æ£€ï¼ˆå¹²éŸ³è´¨æ£€ï¼‰
            logger.info("ğŸ›¡ï¸ è¿›å…¥å¹²éŸ³ç¼“å­˜è´¨æ£€é˜¶æ®µ...")
            producer.phase_4_quality_control(target_dir=producer.cache_dir)

            producer.phase_3_cinematic_mix()

            # ğŸ›¡ï¸ æ–°å¢ï¼šé˜¶æ®µä¸‰åè´¨æ£€ï¼ˆæˆå“å‘å¸ƒè´¨æ£€ï¼‰
            logger.info("ğŸ›¡ï¸ è¿›å…¥æˆå“å‘å¸ƒè´¨æ£€é˜¶æ®µ...")
            producer.phase_4_quality_control(target_dir=producer.config["output_dir"])
    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸‰æ®µå¼æ¶æ„æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()