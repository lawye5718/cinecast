#!/usr/bin/env python3
"""
CineCast ä¸»æ§ç¨‹åº
ä¸‰æ®µå¼ç‰©ç†éš”ç¦»æ¶æ„ (Three-Stage Isolated Pipeline)
å®ç°100%é˜²å†…å­˜æº¢å‡ºå’Œæ–­ç‚¹ç»­ä¼ 
"""

import argparse
import os
import sys
import json
import logging
import requests
from bs4 import BeautifulSoup
import ebooklib
from ebooklib import epub
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from modules.asset_manager import AssetManager
from modules.llm_director import LLMScriptDirector, atomic_json_write
from modules.mlx_tts_engine import MLXRenderEngine, group_indices_by_voice_type
from modules.cinematic_packager import CinematicPackager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cinecast.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class CineCastProducer:
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–CineCastä¸‰æ®µå¼ç”Ÿäº§çº¿
        
        Args:
            config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config or self._get_default_config()
        self.assets = AssetManager(self.config["assets_dir"])
        self.script_dir = os.path.join(self.config["output_dir"], "scripts")
        self.cache_dir = os.path.join(self.config["output_dir"], "temp_wav_cache")
        os.makedirs(self.script_dir, exist_ok=True)
        os.makedirs(self.cache_dir, exist_ok=True)
    
    def _get_default_config(self):
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "assets_dir": "./assets",
            "output_dir": "./output/Audiobooks",
            "model_path": "../qwentts/models/Qwen3-TTS-MLX-0.6B",  # ç›¸å¯¹äºcinecastç›®å½•
            "ambient_theme": "iceland_wind",  # ç¯å¢ƒéŸ³ä¸»é¢˜
            "target_duration_min": 30,  # ç›®æ ‡æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            "min_tail_min": 10,  # æœ€å°å°¾éƒ¨æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            "use_local_llm": True,  # æ˜¯å¦ä½¿ç”¨æœ¬åœ°LLM
            "enable_recap": True,  # ğŸŒŸ å‰æƒ…æè¦æ€»å¼€å…³
            "pure_narrator_mode": False  # ğŸŒŸ çº¯å‡€æ—ç™½æ¨¡å¼å¼€å…³
        }
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ä¸ªç»„ä»¶"""
        logger.info("ğŸ¬ åˆå§‹åŒ–CineCastç”µå½±çº§æœ‰å£°ä¹¦ç”Ÿäº§çº¿...")
        
        try:
            # 1. åˆå§‹åŒ–èµ„äº§ç®¡ç†ç³»ç»Ÿ
            self.assets = AssetManager(self.config["assets_dir"])
            logger.info("âœ… èµ„äº§ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # 2. åˆå§‹åŒ–LLMå‰§æœ¬å¯¼æ¼”
            self.director = LLMScriptDirector(
                use_local_mlx_lm=self.config["use_local_llm"]
            )
            logger.info("âœ… LLMå‰§æœ¬å¯¼æ¼”åˆå§‹åŒ–å®Œæˆ")
            
            # 3. åˆå§‹åŒ–MLXæ¸²æŸ“å¼•æ“
            model_path = self.config["model_path"]
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not os.path.isabs(model_path):
                model_path = os.path.join(project_root.parent, model_path)
            
            self.engine = MLXRenderEngine(model_path)
            logger.info("âœ… MLXæ¸²æŸ“å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
            # 4. åˆå§‹åŒ–æ··éŸ³æ‰“åŒ…å™¨
            self.packager = CinematicPackager(self.config["output_dir"])
            logger.info("âœ… æ··éŸ³æ‰“åŒ…å™¨åˆå§‹åŒ–å®Œæˆ")
            
            logger.info("ğŸ‰ æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _extract_epub_chapters(self, epub_path: str) -> dict:
        """ğŸŒŸ ä» EPUB æå–å¹²å‡€çš„ç« èŠ‚æ–‡æœ¬å­—å…¸ {ç« èŠ‚å: æ–‡æœ¬å†…å®¹}"""
        logger.info(f"ğŸ“– æ­£åœ¨è§£æ EPUB æ–‡ä»¶: {epub_path}")
        book = epub.read_epub(epub_path)
        chapters = {}
        for idx, item in enumerate(book.get_items_of_type(ebooklib.ITEM_DOCUMENT)):
            soup = BeautifulSoup(item.get_content(), 'html.parser')
            text = soup.get_text(separator='\n')
            clean_text = '\n'.join([line.strip() for line in text.split('\n') if line.strip()])
            if len(clean_text) > 100: # è¿‡æ»¤æçŸ­åºŸé¡µ
                title = f"Chapter_{idx:03d}"
                chapters[title] = clean_text
        return chapters
    
    def _eject_ollama_memory(self):
        """ğŸŒŸ æ ¸å¿ƒç»æ‹›ï¼šå¼ºè¡Œå¼¹å°„ Ollama æ¨¡å‹ï¼Œæ¸…ç©º M4 æ˜¾å­˜"""
        logger.info("ğŸ§¹ æ­£åœ¨å¸è½½ Ollama æ¨¡å‹é‡Šæ”¾æ˜¾å­˜...")
        try:
            requests.post(
                "http://127.0.0.1:11434/api/generate",
                json={"model": "qwen14b-pro", "prompt": "bye", "keep_alive": 0},
                timeout=10
            )
            logger.info("âœ… 14B å¤§æ¨¡å‹å·²æˆåŠŸä»ç»Ÿä¸€å†…å­˜ä¸­å¼¹å°„ï¼")
        except Exception as e:
            logger.warning(f"âš ï¸ å¼¹å°„ Ollama å¤±è´¥ï¼Œå¯èƒ½å·²è‡ªåŠ¨é‡Šæ”¾: {e}")
    
    def check_ollama_alive(self):
        """å‰ç½®æ£€æŸ¥ï¼šéªŒè¯ Ollama æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(
                "http://127.0.0.1:11434/api/tags", timeout=10
            )
            if response.status_code == 200:
                logger.info("âœ… Ollama æœåŠ¡å‰ç½®æ£€æŸ¥é€šè¿‡")
                return True
            else:
                logger.error(f"âŒ Ollama æœåŠ¡å“åº”å¼‚å¸¸ (HTTP {response.status_code})")
                return False
        except Exception as e:
            logger.error(f"âŒ Ollama æœåŠ¡ä¸å¯è¾¾: {e}")
            return False

    # ==========================================
    # ğŸ¬ é˜¶æ®µä¸€ï¼šå‰§æœ¬åŒ–ä¸å¾®åˆ‡ç‰‡ (Script & Micro-chunking)
    # ==========================================
    def phase_1_generate_scripts(self, input_source):
        """é˜¶æ®µä¸€ï¼šç¼–å‰§æœŸ (Ollama) - ç”ŸæˆåŒ…å«chunk_idå’Œåœé¡¿æ—¶é—´çš„å¾®åˆ‡ç‰‡å‰§æœ¬"""
        logger.info("\n" + "="*50 + "\nğŸ¬ [é˜¶æ®µä¸€] ç¼–å‰§æœŸ (Ollama)\n" + "="*50)
        
        pure_mode = self.config.get("pure_narrator_mode", False)

        # ğŸŒŸ å‰ç½®æ£€æŸ¥ï¼šçº¯å‡€æ¨¡å¼ä¸‹ä¸éœ€è¦ Ollama æœåŠ¡
        if not pure_mode and not self.check_ollama_alive():
            logger.error("âŒ Ollama æœåŠ¡ä¸å¯ç”¨ï¼Œé˜¶æ®µä¸€ä¸­æ­¢ã€‚è¯·æ£€æŸ¥ Ollama æ˜¯å¦å·²å¯åŠ¨ã€‚")
            return False

        # æ”¯æŒEPUBå’ŒTXTä¸¤ç§è¾“å…¥æ ¼å¼
        if input_source.endswith('.epub'):
            chapters = self._extract_epub_chapters(input_source)
            if not chapters:
                logger.error("âŒ EPUB è§£æå¤±è´¥æˆ–æ— æœ‰æ•ˆæ–‡æœ¬ï¼")
                return False
        else:
            # å¤„ç†TXTç›®å½•
            text_files = sorted([f for f in os.listdir(input_source) if f.endswith(('.txt', '.md'))])
            if not text_files:
                logger.error(f"âŒ ç›®å½• {input_source} ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå‰§æœ¬ï¼")
                return False
            chapters = {}
            for file_name in text_files:
                with open(os.path.join(input_source, file_name), 'r', encoding='utf-8') as f:
                    chapters[os.path.splitext(file_name)[0]] = f.read()
        
        director = LLMScriptDirector()
        prev_chapter_content = None  # ç”¨äºå­˜å‚¨ä¸Šä¸€ç« å†…å®¹
        failed_chapters = []
        
        for chapter_name, content in chapters.items():
            script_path = os.path.join(self.script_dir, f"{chapter_name}_micro.json")
            if os.path.exists(script_path):
                logger.info(f"â­ï¸ å¾®åˆ‡ç‰‡å‰§æœ¬å·²å­˜åœ¨ï¼Œè·³è¿‡: {chapter_name}")
                # ä¿ç•™å·²æœ‰ç« èŠ‚çš„æ–‡æœ¬ç»™ä¸‹ä¸€ç« ç”¨
                prev_chapter_content = content
                continue
                
            logger.info(f"âœï¸ æ­£åœ¨ç”Ÿæˆå¾®åˆ‡ç‰‡å‰§æœ¬: {chapter_name} (å­—æ•°: {len(content)})")
            try:
                # ğŸŒŸ æ ¸å¿ƒæ‹¦æˆªåˆ†æ”¯ï¼šçº¯å‡€æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„ç”Ÿæˆå™¨
                if pure_mode:
                    logger.info(f"âš¡ å¯ç”¨çº¯å‡€æ—ç™½æ¨¡å¼è§£æ: {chapter_name}")
                    micro_script = director.generate_pure_narrator_script(content, chapter_prefix=chapter_name)
                else:
                    # ğŸŒŸ ä¿®å¤ï¼šä¼ å…¥ chapter_name ä½œä¸º ID å‰ç¼€ï¼Œé¿å…æ–‡ä»¶åå†²çª
                    micro_script = director.parse_and_micro_chunk(content, chapter_prefix=chapter_name)
                
                # éªŒè¯ç”Ÿæˆçš„å‰§æœ¬æ•°æ®ç»“æ„
                if not micro_script:
                    logger.error(f"âŒ {chapter_name} ç”Ÿæˆçš„å¾®åˆ‡ç‰‡å‰§æœ¬ä¸ºç©ºï¼Œè·³è¿‡è¯¥ç« èŠ‚")
                    failed_chapters.append(chapter_name)
                    continue
                
                # ğŸŒŸ æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½å‰æƒ…æè¦åˆ¤æ–­ï¼ˆçº¯å‡€æ¨¡å¼ä¸‹è·³è¿‡ï¼‰
                # åˆ¤å®šæ¡ä»¶ï¼šéçº¯å‡€æ¨¡å¼ + å¼€å…³æ‰“å¼€ + ä¸æ˜¯ç¬¬ä¸€ç«  + ä¸Šä¸€ç« æœ‰è¶³å¤Ÿå†…å®¹ + å½“å‰ç« çœ‹èµ·æ¥åƒæ­£æ–‡
                if not pure_mode:
                    is_main_text = True
                    # è¿‡æ»¤ç‰ˆæƒé¡µã€ç›®å½•ã€è‡´è°¢ç­‰éæ­£æ–‡ç« èŠ‚ (é€šè¿‡é•¿åº¦å’Œç‰¹å¾è¯è¯†åˆ«)
                    if len(content) < 500 or any(keyword in content[:200] for keyword in ["ç‰ˆæƒ", "ç›®å½•", "å‡ºç‰ˆ", "ISBN", "åºè¨€", "è‡´è°¢"]):
                        is_main_text = False
                        logger.info(f"â­ï¸ åˆ¤å®š {chapter_name} ä¸ºéæ­£æ–‡/çŸ­ç« èŠ‚ï¼Œè·³è¿‡ç”Ÿæˆå‰æƒ…æ‘˜è¦ã€‚")

                    if self.config.get("enable_recap", True) and prev_chapter_content is not None and is_main_text:
                        # åªæœ‰ä¸Šä¸€ç« ä¹Ÿæ˜¯æ­£æ–‡ï¼Œæ‰å€¼å¾—å›é¡¾
                        if len(prev_chapter_content) >= 800:
                            logger.info(f"ğŸ”„ æ­£åœ¨ä¸º {chapter_name} ç”Ÿæˆå‰æƒ…æ‘˜è¦ (Map-Reduce å¼•æ“)...")
                            recap_text = director.generate_chapter_recap(prev_chapter_content)
                        
                            if recap_text:
                                # æ„å»ºä¸€ä¸ªæ ‡å‡†çš„å‰æƒ…æè¦å¼•å­å•å…ƒ
                                intro_unit = {
                                    "chunk_id": f"{chapter_name}_recap_intro",
                                    "type": "recap",
                                    "speaker": "talkover",
                                    "content": "å‰æƒ…æè¦ï¼š",
                                    "pause_ms": 500
                                }
                                # æ„å»ºæ‘˜è¦ä¸»ä½“å•å…ƒ
                                recap_unit = {
                                    "chunk_id": f"{chapter_name}_recap_body",
                                    "type": "recap",
                                    "speaker": "talkover",
                                    "content": recap_text,
                                    "pause_ms": 1500
                                }
                                # å°†æè¦æ’å…¥åˆ°æœ¬ç« å‰§æœ¬çš„æœ€å¼€å¤´ï¼ˆåœ¨æ ‡é¢˜ä¹‹åï¼Œæ­£æ–‡ä¹‹å‰ï¼‰
                                micro_script.insert(1, intro_unit)
                                micro_script.insert(2, recap_unit)
                
                # ä¿å­˜å½“å‰ç« çš„åŸå§‹æ–‡æœ¬ï¼Œä¾›ä¸‹ä¸€ç« ä½¿ç”¨
                prev_chapter_content = content
                
                # éªŒè¯æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å¿…éœ€çš„å­—æ®µ
                valid = True
                for i, item in enumerate(micro_script):
                    required_fields = ['chunk_id', 'type', 'speaker', 'content']
                    missing_fields = [field for field in required_fields if field not in item]
                    if missing_fields:
                        logger.error(f"âŒ {chapter_name} ç¬¬{i+1}ä¸ªç‰‡æ®µç¼ºå°‘å­—æ®µ: {missing_fields}")
                        logger.error(f"   ç‰‡æ®µå†…å®¹: {item}")
                        valid = False
                        break

                if not valid:
                    logger.error(f"âŒ ç« èŠ‚ {chapter_name} æ•°æ®æ ¡éªŒå¤±è´¥ï¼Œè·³è¿‡è¯¥ç« ")
                    failed_chapters.append(chapter_name)
                    continue
                
                # ğŸŒŸ åŸå­åŒ–å†™å…¥ï¼šé˜²æ­¢ä¸­æ–­å¯¼è‡´ JSON æŸå
                atomic_json_write(script_path, micro_script)
                logger.info(f"âœ… ç”Ÿæˆå¾®åˆ‡ç‰‡å‰§æœ¬: {script_path} ({len(micro_script)}ä¸ªç‰‡æ®µ)")
            except Exception as e:
                logger.error(f"âŒ ç« èŠ‚ {chapter_name} è§£æä¸¥é‡å¤±è´¥ï¼Œè·³è¿‡è¯¥ç« : {e}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                failed_chapters.append(chapter_name)
                continue
                
        # å¼ºåˆ¶å¼¹å°„Ollamaå†…å­˜ï¼ˆçº¯å‡€æ¨¡å¼ä¸‹æ— éœ€å¼¹å°„ï¼‰
        if not pure_mode:
            self._eject_ollama_memory()

        if failed_chapters:
            logger.warning(f"âš ï¸ ä»¥ä¸‹ç« èŠ‚å¤„ç†å¤±è´¥: {', '.join(failed_chapters)}")

        logger.info("âœ… é˜¶æ®µä¸€å®Œæˆï¼ŒOllamaå·²ä»å†…å­˜ä¸­å®‰å…¨æ’¤ç¦»ï¼")
        return True
    
    # ==========================================
    # ğŸ§ è¯•å¬æ¨¡å¼ï¼šæé€Ÿé€šé“ï¼Œåªå¤„ç†å‰ 10 å¥è¯
    # ==========================================
    def run_preview_mode(self, input_source: str) -> str:
        """ğŸŒŸ ä¸“å±çš„è¯•å¬æ¨¡å¼ï¼šæé€Ÿé€šé“ï¼Œåªå¤„ç†å‰ 10 å¥è¯

        æµç¨‹ï¼šå…ˆå®Œæˆç¬¬ä¸€é˜¶æ®µå¾®åˆ‡ç‰‡ï¼Œå†ä»ç¬¬ä¸€ç« å‰§æœ¬ä¸­æˆªå–å‰ 10 å¥ï¼Œ
        å†™å…¥ç‹¬ç«‹çš„ä¸´æ—¶å‰§æœ¬æ–‡ä»¶ï¼ˆä¸è¦†ç›–åŸå§‹å‰§æœ¬ï¼‰ï¼Œç›´æ¥æ¸²æŸ“å¹¶å‹åˆ¶ã€‚
        """
        logger.info("ğŸ§ å¯åŠ¨è¯•å¬é€šé“...")

        # ä¸´æ—¶å¼ºåˆ¶è®¾ä¸ºæçŸ­æ—¶é•¿ï¼Œè¿«ä½¿ CinematicPackager æå‰è§¦å‘å¯¼å‡º
        original_duration = self.config["target_duration_min"]
        self.config["target_duration_min"] = 0.5  # 30ç§’å°±å‘ç‰ˆ

        try:
            # â”€â”€ ç¬¬ä¸€é˜¶æ®µï¼šå¾®åˆ‡ç‰‡ï¼ˆå¿…é¡»å…ˆå®Œæˆï¼ï¼‰â”€â”€
            self.phase_1_generate_scripts(input_source)

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”Ÿæˆçš„å‰§æœ¬
            script_files = sorted([f for f in os.listdir(self.script_dir) if f.endswith('_micro.json')])
            if not script_files:
                raise Exception(f"æœªæ‰¾åˆ°å‰§æœ¬ï¼Œè¯·æ£€æŸ¥é˜¶æ®µä¸€æ˜¯å¦æˆåŠŸ (script_dir={self.script_dir})")

            first_script_path = os.path.join(self.script_dir, script_files[0])
            with open(first_script_path, 'r', encoding='utf-8') as f:
                micro_script = json.load(f)

            # ğŸŒŸ æ ¸å¿ƒæˆªæ–­ï¼šåªå–å‰ 10 å¥ï¼
            preview_script = micro_script[:10]

            # ğŸŒŸ å†™å…¥ç‹¬ç«‹çš„ä¸´æ—¶é¢„è§ˆå‰§æœ¬ï¼Œä¸è¦†ç›–åŸå§‹å‰§æœ¬ï¼ˆä¿æŠ¤å…¨æœ¬å‹åˆ¶çš„æ–­ç‚¹ç»­ä¼ ï¼‰
            preview_script_path = os.path.join(self.script_dir, "_preview_temp_micro.json")
            with open(preview_script_path, 'w', encoding='utf-8') as f:
                json.dump(preview_script, f, ensure_ascii=False)

            # â”€â”€ ç¬¬äºŒé˜¶æ®µï¼šä»…æ¸²æŸ“é¢„è§ˆç‰‡æ®µçš„å¹²éŸ³ â”€â”€
            self._render_script_chunks(preview_script)

            # â”€â”€ ç¬¬ä¸‰é˜¶æ®µï¼šä»…æ··éŸ³é¢„è§ˆç‰‡æ®µ â”€â”€
            self._mix_script_chunks(preview_script)

            # æ‰¾åˆ°å‹åˆ¶å‡ºçš„ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿”å›ç»™ç½‘é¡µ
            preview_files = [f for f in os.listdir(self.config["output_dir"]) if f.endswith('.mp3')]
            if preview_files:
                return os.path.join(self.config["output_dir"], sorted(preview_files)[0])
            return None

        finally:
            # æ¢å¤é…ç½®ä»¥å…æ±¡æŸ“æ­£å¼çš„å…¨æœ¬å‹åˆ¶
            self.config["target_duration_min"] = original_duration
            # æ¸…ç†ä¸´æ—¶é¢„è§ˆå‰§æœ¬ï¼ˆæ— è®ºæˆåŠŸ/å¤±è´¥éƒ½è¦æ¸…ç†ï¼‰
            preview_script_path = os.path.join(self.script_dir, "_preview_temp_micro.json")
            if os.path.exists(preview_script_path):
                os.remove(preview_script_path)

    def _render_script_chunks(self, micro_script: list):
        """æ¸²æŸ“æŒ‡å®šçš„å¾®åˆ‡ç‰‡åˆ—è¡¨ä¸ºå¹²éŸ³ WAV æ–‡ä»¶ï¼ˆä¾›è¯•å¬æ¨¡å¼ç›´æ¥è°ƒç”¨ï¼‰"""
        from modules.mlx_tts_engine import MLXRenderEngine, group_indices_by_voice_type
        engine = MLXRenderEngine(self.config["model_path"])

        voice_groups = group_indices_by_voice_type(micro_script)
        for voice_key, indices in voice_groups.items():
            first_item = micro_script[indices[0]]
            group_voice_cfg = self.assets.get_voice_for_role(
                first_item["type"],
                first_item.get("speaker"),
                first_item.get("gender")
            )
            for idx in indices:
                item = micro_script[idx]
                save_path = os.path.join(self.cache_dir, f"{item['chunk_id']}.wav")
                engine.render_dry_chunk(item["content"], group_voice_cfg, save_path)

        del engine
        try:
            import mlx.core as mx
            mx.clear_cache()
        except ImportError:
            pass

    def _mix_script_chunks(self, micro_script: list):
        """å°†æŒ‡å®šçš„å¾®åˆ‡ç‰‡åˆ—è¡¨æ··éŸ³å‹åˆ¶ä¸º MP3ï¼ˆä¾›è¯•å¬æ¨¡å¼ç›´æ¥è°ƒç”¨ï¼‰"""
        packager = CinematicPackager(self.config["output_dir"])

        if self.config.get("pure_narrator_mode", False):
            ambient_bgm = None
            chime_sound = None
        else:
            ambient_bgm = self.assets.get_ambient_sound(self.config["ambient_theme"])
            chime_sound = self.assets.get_transition_chime()

        packager.process_from_cache(micro_script, self.cache_dir, self.assets, ambient_bgm, chime_sound)

    # ==========================================
    # ğŸ™ï¸ é˜¶æ®µäºŒï¼šçº¯å‡€å¹²éŸ³æ¸²æŸ“ (Dry Voice Rendering)
    # ==========================================
    def phase_2_render_dry_audio(self):
        """é˜¶æ®µäºŒï¼šå½•éŸ³æœŸ (MLX TTS) - çº¯å‡€å¹²éŸ³æ¸²æŸ“ï¼Œåªäº§ç”ŸWAVæ–‡ä»¶
        
        Uses a "group-by-voice" strategy: chunks sharing the same voice type
        are rendered consecutively to minimise MLX embedding switches.
        """
        logger.info("\n" + "="*50 + "\nğŸ™ï¸ [é˜¶æ®µäºŒ] å½•éŸ³æœŸ (MLX TTS)\n" + "="*50)
        engine = MLXRenderEngine(self.config["model_path"])
        
        script_files = sorted([f for f in os.listdir(self.script_dir)
                               if f.endswith('_micro.json') and not f.startswith('_preview_')])
        total_chunks = 0
        rendered_chunks = 0
        
        for file in script_files:
            with open(os.path.join(self.script_dir, file), 'r', encoding='utf-8') as f:
                micro_script = json.load(f)
            total_chunks += len(micro_script)
            
            logger.info(f"ğŸ™ï¸ æ­£åœ¨æ¸²æŸ“å¹²éŸ³: {file} ({len(micro_script)}ä¸ªç‰‡æ®µ)")
            
            # ğŸŒŸ Group-by-voice ä¼˜åŒ–ï¼šæŒ‰è§’è‰²åˆ†ç»„æ‰¹é‡æ¸²æŸ“ï¼Œå‡å°‘ MLX éŸ³è‰²åˆ‡æ¢å¼€é”€
            voice_groups = group_indices_by_voice_type(micro_script)
            for voice_key, indices in voice_groups.items():
                logger.info(f"   ğŸ¤ æ¸²æŸ“éŸ³è‰²ç»„: {voice_key} ({len(indices)}ä¸ªç‰‡æ®µ)")
                # ğŸŒŸ ä¿®å¤ï¼šæ¯ä¸ªéŸ³è‰²ç»„åªè§£æä¸€æ¬¡ voice_cfgï¼Œç¡®ä¿ç»„å†…æ‰€æœ‰å¾®åˆ‡ç‰‡
                # ä½¿ç”¨å®Œå…¨ç›¸åŒçš„éŸ³è‰²é…ç½®ï¼Œæœç»éŸ³è‰²åœ¨å¾®åˆ‡ç‰‡ä¹‹é—´åˆ‡æ¢
                first_item = micro_script[indices[0]]
                group_voice_cfg = self.assets.get_voice_for_role(
                    first_item["type"],
                    first_item.get("speaker"),
                    first_item.get("gender")
                )
                for idx in indices:
                    item = micro_script[idx]
                    save_path = os.path.join(self.cache_dir, f"{item['chunk_id']}.wav")
                    if engine.render_dry_chunk(item["content"], group_voice_cfg, save_path):
                        rendered_chunks += 1
                    
                    if rendered_chunks > 0 and rendered_chunks % 50 == 0:
                        logger.info(f"   ğŸµ è¿›åº¦: {rendered_chunks}/{total_chunks} ç‰‡æ®µå·²æ¸²æŸ“")
        
        # é‡Šæ”¾ MLX æ¨¡å‹æ˜¾å­˜
        del engine
        try:
            import mlx.core as mx
            mx.clear_cache()
        except ImportError:
            pass
        logger.info(f"âœ… é˜¶æ®µäºŒå®Œæˆ ({rendered_chunks}/{total_chunks} ç‰‡æ®µ)ï¼ŒMLX å·²ä»å†…å­˜ä¸­å®‰å…¨æ’¤ç¦»ï¼")
        
    # ==========================================
    # ğŸ›ï¸ é˜¶æ®µä¸‰ï¼šç”µå½±çº§æ··éŸ³å‘ç‰ˆ (Cinematic Post-Processing)
    # ==========================================
    def phase_3_cinematic_mix(self):
        """é˜¶æ®µä¸‰ï¼šæ··éŸ³å‘ç‰ˆæœŸ (Pydub) - ä»å¹²éŸ³ç¼“å­˜ç»„è£…æˆç”µå½±çº§æœ‰å£°ä¹¦"""
        logger.info("\n" + "="*50 + "\nğŸ›ï¸ [é˜¶æ®µä¸‰] æ··éŸ³å‘ç‰ˆæœŸ (Pydub)\n" + "="*50)

        # ğŸŒŸ å‰ç½®æ£€æŸ¥ï¼šç¡®è®¤ç¼“å­˜ç›®å½•å­˜åœ¨æœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µ
        if os.path.isdir(self.cache_dir):
            wav_files = [f for f in os.listdir(self.cache_dir) if f.endswith('.wav')]
        else:
            wav_files = []
        if not wav_files:
            logger.warning("âš ï¸ æœªå‘ç°æœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µï¼Œè¯·æ£€æŸ¥å‰§æœ¬è§£æé˜¶æ®µï¼ˆé˜¶æ®µä¸€ï¼‰å’Œå¹²éŸ³æ¸²æŸ“é˜¶æ®µï¼ˆé˜¶æ®µäºŒï¼‰æ˜¯å¦æˆåŠŸã€‚è·³è¿‡æ··éŸ³ã€‚")
            return

        packager = CinematicPackager(self.config["output_dir"])

        # ğŸŒŸ æ ¸å¿ƒæ‹¦æˆªï¼šçº¯å‡€æ¨¡å¼ä¸‹ï¼Œå¼ºè¡Œå°†éŸ³æ•ˆè®¾ä¸º None
        if self.config.get("pure_narrator_mode", False):
            logger.info("ğŸ”‡ çº¯å‡€æ¨¡å¼å·²å¼€å¯ï¼šå…³é—­ç¯å¢ƒèƒŒæ™¯éŸ³ä¸ç« èŠ‚è¿‡æ¸¡éŸ³æ•ˆ")
            ambient_bgm = None
            chime_sound = None
        else:
            ambient_bgm = self.assets.get_ambient_sound(self.config["ambient_theme"])
            chime_sound = self.assets.get_transition_chime()
        
        script_files = sorted([f for f in os.listdir(self.script_dir)
                               if f.endswith('_micro.json') and not f.startswith('_preview_')])
        for file in script_files:
            with open(os.path.join(self.script_dir, file), 'r', encoding='utf-8') as f:
                micro_script = json.load(f)
            # ğŸŒŸ Pydub å¼€å§‹ç»„è£…ï¼Œæ­¤æ—¶å·²ç»æ²¡æœ‰å¤§æ¨¡å‹åœ¨æŠ¢å å†…å­˜äº†
            packager.process_from_cache(micro_script, self.cache_dir, self.assets, ambient_bgm, chime_sound)
        
        logger.info("ğŸ‰ ä¸‰æ®µå¼æ¶æ„å…¨æµç¨‹å®Œæˆï¼å…¨ä¹¦å‹åˆ¶å®Œæ¯•ï¼Œè¯·å‰å¾€ output ç›®å½•æŸ¥æ”¶ã€‚")
    
def main():
    """ä¸»å‡½æ•° - å¼•å…¥å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="CineCast ç”µå½±çº§æœ‰å£°ä¹¦ç”Ÿäº§çº¿")
    parser.add_argument("input", nargs="?", default="./input_chapters", help="è¾“å…¥æ–‡ä»¶(EPUB)æˆ–ç›®å½•(TXT)")
    parser.add_argument("--pure-narrator", action="store_true", help="å¯ç”¨çº¯å‡€æ—ç™½æ¨¡å¼(å•éŸ³è‰²/æ— èƒŒæ™¯éŸ³/æ— æ‘˜è¦/å…LLM)")
    args = parser.parse_args()

    producer = CineCastProducer()
    producer.config["pure_narrator_mode"] = args.pure_narrator  # ğŸŒŸ å°†å‘½ä»¤è¡Œå‚æ•°å†™å…¥å…¨å±€é…ç½®
    input_source = args.input
    
    if input_source.endswith('.epub') and os.path.exists(input_source):
        logger.info(f"ğŸ“š æ£€æµ‹åˆ°EPUBæ–‡ä»¶: {input_source}")
    elif os.path.isdir(input_source):
        if not os.listdir(input_source):
            logger.warning(f"âš ï¸ è¯·å…ˆåœ¨ {input_source} æ–‡ä»¶å¤¹ä¸­æ”¾å…¥æµ‹è¯•ç”¨çš„ .txt ç« èŠ‚ï¼")
            with open(os.path.join(input_source, "ç¬¬ä¸€ç« _æµ‹è¯•.txt"), 'w', encoding='utf-8') as f:
                f.write("ç¬¬ä¸€ç«  é£é›ª\n1976å¹´\nå¤œå¹•é™ä¸´æ¸¯å£ã€‚\"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ\"è€æ¸”å¤«é—®ã€‚\n\"æˆ‘ä¸ä¿¡ã€‚\"å¹´è½»äººå›ç­”ã€‚")
        logger.info(f"ğŸ“ ä½¿ç”¨TXTç›®å½•æ¨¡å¼: {input_source}")
    else:
        # å›é€€åˆ°é»˜è®¤TXTç›®å½•æ¨¡å¼
        input_source = "./input_chapters"
        os.makedirs(input_source, exist_ok=True)
        if not os.listdir(input_source):
            logger.warning(f"âš ï¸ è¯·å…ˆåœ¨ {input_source} æ–‡ä»¶å¤¹ä¸­æ”¾å…¥æµ‹è¯•ç”¨çš„ .txt ç« èŠ‚ï¼")
            with open(os.path.join(input_source, "ç¬¬ä¸€ç« _æµ‹è¯•.txt"), 'w', encoding='utf-8') as f:
                f.write("ç¬¬ä¸€ç«  é£é›ª\n1976å¹´\nå¤œå¹•é™ä¸´æ¸¯å£ã€‚\"ä½ ç›¸ä¿¡å‘½è¿å—ï¼Ÿ\"è€æ¸”å¤«é—®ã€‚\n\"æˆ‘ä¸ä¿¡ã€‚\"å¹´è½»äººå›ç­”ã€‚")
        logger.info(f"ğŸ“ ä½¿ç”¨TXTç›®å½•æ¨¡å¼: {input_source}")
    
    try:
        # ä¸¥æ ¼çš„ä¸‰æ®µå¼ä¸²è¡Œå¤„ç†ï¼Œå½»åº•åˆ‡æ–­å†…å­˜é‡å 
        if producer.phase_1_generate_scripts(input_source):
            producer.phase_2_render_dry_audio()
            producer.phase_3_cinematic_mix()
    except Exception as e:
        logger.error(f"ğŸ’¥ ä¸‰æ®µå¼æ¶æ„æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()