#!/usr/bin/env python3
"""
CineCast æµå¼API - æœ€ç»ˆæˆåŠŸç‰ˆæœ¬
åŸºäºå·²éªŒè¯çš„å·¥ä½œæ–¹æ³•å®ç°
"""

import sys
import os
from pathlib import Path

# ä½¿ç”¨ç›¸å¯¹è·¯å¾„é¿å…ç¡¬ç¼–ç 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import mlx.core as mx
import numpy as np
import soundfile as sf
import io
import logging
import time
import re
import warnings   # ğŸš¨ å¼•å…¥è­¦å‘Šæ§åˆ¶

# å±è”½ Tokenizer æ— æ„ä¹‰çš„æ­£åˆ™è¡¨è¾¾å¼è­¦å‘Š
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", module="tiktoken")

from pydub import AudioSegment

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from modules.mlx_tts_engine import CinecastMLXEngine as MLXTTSEngine
from modules.asset_manager import AssetManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="CineCast Streaming TTS API - Production Ready")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI TTS å…¼å®¹è¯·æ±‚æ¨¡å‹
class OpenAITTSRequest(BaseModel):
    model: str = "qwen3-tts"
    input: str
    voice: str = "aiden"
    response_format: str = "mp3"
    speed: float = 1.0

# å…¨å±€çŠ¶æ€
class VoiceContext:
    def __init__(self):
        # é»˜è®¤ä½¿ç”¨åŸç”Ÿé…ç½®æ–‡ä»¶ä¸­çš„æ—ç™½è®¾å®šï¼Œæˆ– aiden
        self.current_voice = "aiden" 
        self.engine = None
        self.asset_manager = None
        self.is_ready = False
    
    async def initialize(self):
        """åˆå§‹åŒ–å¼•æ“"""
        if not self.is_ready:
            try:
                self.asset_manager = AssetManager()
                # ä½¿ç”¨å·²éªŒè¯å¯ä»¥å·¥ä½œçš„æ¨¡å‹è·¯å¾„
                self.engine = MLXTTSEngine(
                    model_path="./models/Qwen3-TTS-12Hz-1.7B-CustomVoice-4bit"
                )
                self.is_ready = True
                logger.info("âœ… æµå¼APIå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                pass
    
    def get_voice_feature(self, voice_name: str):
        """ğŸŒŸ æ¶æ„å›å½’ï¼šåˆ©ç”¨åŸç”Ÿçš„ AssetManager è§£æç‰¹å¾ï¼Œå®Œç¾æ”¯æŒå…‹éš†"""
        if not self.is_ready:
            return {"mode": "preset", "voice": "aiden"}
            
        try:
            # AssetManager åŸæœ¬å°±èƒ½è¯†åˆ« .cinecast_role_voices.json é‡Œçš„å…‹éš†è®°å½•
            return self.asset_manager.load_role(voice_name)
        except Exception as e:
            logger.warning(f"éŸ³è‰² {voice_name} æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°ï¼Œå›é€€åˆ°é»˜è®¤: {e}")
            return {"mode": "preset", "voice": "aiden"}
            logger.error(f"âŒ å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

# å…¨å±€ä¸Šä¸‹æ–‡
voice_context = VoiceContext()

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨åˆå§‹åŒ–"""
    await voice_context.initialize()

@app.get("/")
async def root():
    return {
        "message": "CineCast Streaming TTS API - Production Ready",
        "status": "running",
        "ready": voice_context.is_ready
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "ready": voice_context.is_ready,
        "current_voice": voice_context.current_voice
    }

@app.get("/voices")
async def list_voices():
    """åˆ—å‡ºå¯ç”¨éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    preset_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
    return {
        "preset_voices": preset_voices,
        "current_voice": voice_context.current_voice
    }

@app.post("/set_voice")
async def set_voice(voice_name: str = Form(...)):
    """è®¾ç½®å½“å‰éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    try:
        # éªŒè¯éŸ³è‰²åç§°
        valid_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
        if voice_name.lower() not in valid_voices:
            return {"error": f"Invalid voice name. Valid options: {valid_voices}"}
        
        voice_context.current_voice = voice_name.lower()
        logger.info(f"âœ… éŸ³è‰²å·²è®¾ç½®ä¸º: {voice_context.current_voice}")
        
        return {
            "status": "success",
            "voice_name": voice_context.current_voice
        }
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®éŸ³è‰²å¤±è´¥: {e}")
        return {"error": str(e)}

def generate_mp3_chunks(text: str, voice_name: str):
    """ç”ŸæˆMP3éŸ³é¢‘å—çš„ç”Ÿæˆå™¨å‡½æ•°ï¼ˆåŠ é”é˜²å´©æºƒ + æ”¯æŒå…‹éš†ï¼‰"""
    if not voice_context.is_ready:
        raise RuntimeError("Service not ready")
    
    try:
        # ğŸš¨ æ¶æ„å›å½’ï¼šè·å–å®Œæ•´çš„éŸ³è‰²ç‰¹å¾ï¼ˆå¯èƒ½æ˜¯é¢„è®¾ï¼Œä¹Ÿå¯èƒ½æ˜¯æœ¬åœ°çš„å…‹éš†é…ç½®ï¼‰
        feature = voice_context.get_voice_feature(voice_name)
        
        # æ–‡æœ¬é¢„å¤„ç† - æš´åŠ›æ¸…æ´— (ä¿ç•™ä½ ä¹‹å‰çš„ä¿®å¤)
        safe_text = re.sub(r'[â€¦]+', 'ã€‚', text)
        safe_text = re.sub(r'\.{2,}', 'ã€‚', safe_text)
        safe_text = re.sub(r'[â€”]+', 'ï¼Œ', safe_text)
        safe_text = re.sub(r'[-]{2,}', 'ï¼Œ', safe_text)
        safe_text = re.sub(r'[~ï½]+', 'ã€‚', safe_text)
        safe_text = re.sub(r'\s+', ' ', safe_text).strip()
        
        # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·å®‰å…¨åˆ†å‰²
        sentences = [s.strip() for s in re.split(r'([ã€‚ï¼ï¼Ÿ!?])', safe_text) if s.strip()]
        
        # å°†å¥å­å’Œæ ‡ç‚¹é‡æ–°åˆå¹¶ï¼Œé¿å…æ ‡ç‚¹å•ç‹¬æˆå¥
        merged_sentences = []
        for i in range(0, len(sentences)-1, 2):
            merged_sentences.append(sentences[i] + sentences[i+1])
        if len(sentences) % 2 != 0:
            merged_sentences.append(sentences[-1])
            
        logger.info(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {len(merged_sentences)} ä¸ªå¥å­, ä½¿ç”¨éŸ³è‰²ç‰¹å¾: {feature['mode']}")
        
        for i, sentence in enumerate(merged_sentences):
            # é˜²æ­¢çº¯æ ‡ç‚¹
            pure_text = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿï¼›ã€,.!?;:\'"()\s-]', '', sentence)
            if not pure_text:
                continue
                
            logger.info(f"ğŸµ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{len(merged_sentences)} å¥: {sentence[:20]}...")
            
            # ğŸŒŸ æ¶æ„å›å½’ï¼šè°ƒç”¨åŸæœ¬å°è£…å¥½çš„ generate_with_featureï¼Œå®ƒåŸç”Ÿæ”¯æŒå…‹éš†å’Œé¢„è®¾ï¼
            # ğŸš¨ æ³¨æ„ï¼šå¼•æ“å†…éƒ¨å·²æœ‰é”ä¿æŠ¤ï¼Œæ­¤å¤„æ— éœ€å†åŠ é”
            try:
                audio_data = voice_context.engine.generate_with_feature(
                    sentence, 
                    feature, 
                    language="zh"
                )
                
                if audio_data is not None and audio_data.size > 0:
                    # ğŸš¨ æ–°å¢é˜²å¾¡ï¼šæˆªæ–­ä¸€åˆ‡å¼‚å¸¸å°–å³°ï¼Œé˜²æ­¢ int16 æº¢å‡ºå¯¼è‡´çš„åˆºè€³çˆ†éŸ³
                    audio_data = np.clip(audio_data, -1.0, 1.0)
                    
                    # å°†PCMè½¬æ¢ä¸ºMP3å¸§
                    audio_segment = AudioSegment(
                        (audio_data * 32767).astype(np.int16).tobytes(),
                        frame_rate=24000, sample_width=2, channels=1
                    )
                    
                    mp3_buf = io.BytesIO()
                    audio_segment.export(mp3_buf, format="mp3", parameters=["-write_xing", "0"])
                    mp3_bytes = mp3_buf.getvalue()
                    
                    logger.info(f"âœ… ç¬¬ {i+1} å¥MP3ç”Ÿæˆå®Œæˆ ({len(mp3_bytes)} bytes)")
                    yield mp3_bytes
                else:
                    logger.warning(f"âš ï¸ ç”ŸæˆéŸ³é¢‘ä¸ºç©ºï¼Œè·³è¿‡ç¬¬ {i+1} å¥")
                    
            except Exception as ex:
                logger.error(f"âŒ å½“å‰å¥å­ç”Ÿæˆå¼‚å¸¸: {ex}")
                continue
            
            # åœ¨é”å¤–é‡Šæ”¾ CPU èµ„æºç‰‡åˆ»ï¼Œé˜²æ­¢é˜»å¡å…¶ä»–çº¿ç¨‹æŠ¢é”
            import gc
            gc.collect()
            time.sleep(0.01) 
                    
    except Exception as e:
        logger.error(f"âŒ æ•´ä½“éŸ³é¢‘ç”Ÿæˆæµå¤±è´¥: {e}")
        raise

@app.post("/v1/audio/speech")
async def openai_compatible_tts(request: OpenAITTSRequest):
    """ç¬¦åˆOpenAIæ ‡å‡†çš„æµå¼TTSæ¥å£"""
    if not request.input.strip():
        raise HTTPException(status_code=400, detail="Input text is required")
    
    logger.info(f"ğŸ§ OpenAIå…¼å®¹TTSè¯·æ±‚: {request.input[:50]}... ä½¿ç”¨éŸ³è‰²: {request.voice}")
    
    return StreamingResponse(
        generate_mp3_chunks(request.input, request.voice),
        media_type="audio/mpeg",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

@app.get("/read_stream")
async def read_stream(text: str, voice: str = "aiden"):
    """æµå¼æœ—è¯»APIï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    if len(text) > 1000:  # é™åˆ¶é•¿åº¦
        return {"error": "Text too long (max 1000 characters)"}
    
    # ä½¿ç”¨å½“å‰è®¾ç½®çš„éŸ³è‰²æˆ–æŒ‡å®šéŸ³è‰²
    voice_name = voice_context.current_voice if voice == "aiden" else voice
    
    logger.info(f"ğŸ“– å¼€å§‹æµå¼æœ—è¯»: {text[:50]}... ä½¿ç”¨éŸ³è‰²: {voice_name}")
    
    return StreamingResponse(
        generate_mp3_chunks(text, voice_name),
        media_type="audio/mpeg",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

@app.post("/generate_batch")
async def generate_batch(request: dict):
    """æ‰¹é‡ç”ŸæˆAPIï¼ˆéæµå¼ï¼‰"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    text = request.get("text", "")
    voice_name = request.get("voice", voice_context.current_voice)
    
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    try:
        # ç›´æ¥ç”Ÿæˆå®Œæ•´éŸ³é¢‘
        render_engine = voice_context.engine._ensure_render_engine()
        render_engine._load_mode("preset")
        results = list(render_engine.model.generate(text=text, voice=voice_name))
        
        if results:
            audio_array = results[0].audio
            mx.eval(audio_array)
            audio_data = np.array(audio_array)
            
            # è½¬æ¢ä¸ºå­—èŠ‚æµ
            audio_buffer = io.BytesIO()
            sf.write(audio_buffer, audio_data, 24000, format='WAV')
            audio_bytes = audio_buffer.getvalue()
            
            return StreamingResponse(
                io.BytesIO(audio_bytes),
                media_type="audio/wav",
                headers={"Content-Disposition": "attachment; filename=tts_output.wav"}
            )
        else:
            return {"error": "Failed to generate audio"}
            
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ CineCast æµå¼ TTS API (ç”Ÿäº§å°±ç»ªç‰ˆ)...")
    print("ğŸ“ æœåŠ¡åœ°å€: http://localhost:8888")
    print("ğŸ“Š APIæ–‡æ¡£: http://localhost:8888/docs")
    print("ğŸ¥ å¥åº·æ£€æŸ¥: http://localhost:8888/health")
    print("ğŸ¤ éŸ³è‰²åˆ—è¡¨: http://localhost:8888/voices")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 50)
    
    uvicorn.run(
        "stream_api_production:app",
        host="0.0.0.0",
        port=8888,
        reload=False,
        log_level="info"
    )