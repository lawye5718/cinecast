#!/usr/bin/env python3
"""
CineCast æµå¼API - æœ€ç»ˆæˆåŠŸç‰ˆæœ¬
åŸºäºå·²éªŒè¯çš„å·¥ä½œæ–¹æ³•å®ç°
"""

import sys
import os
from pathlib import Path

# ä½¿ç”¨ç›¸å¯¹è·¯å¾„é¿å…ç¡¬ç¼–ç 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import mlx.core as mx
import numpy as np
import soundfile as sf
import io
import logging
import time
from pydub import AudioSegment

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from modules.mlx_tts_engine import CinecastMLXEngine as MLXTTSEngine
from modules.asset_manager import AssetManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="CineCast Streaming TTS API - Production Ready")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI TTS å…¼å®¹è¯·æ±‚æ¨¡å‹
class OpenAITTSRequest(BaseModel):
    model: str = "qwen3-tts"
    input: str
    voice: str = "aiden"
    response_format: str = "mp3"
    speed: float = 1.0

# å…¨å±€çŠ¶æ€
class VoiceContext:
    def __init__(self):
        self.current_voice = "aiden"
        self.engine = None
        self.asset_manager = None
        self.is_ready = False
    
    async def initialize(self):
        """åˆå§‹åŒ–å¼•æ“"""
        if not self.is_ready:
            try:
                self.asset_manager = AssetManager()
                # ä½¿ç”¨å·²éªŒè¯å¯ä»¥å·¥ä½œçš„æ¨¡å‹è·¯å¾„
                self.engine = MLXTTSEngine(
                    model_path="./models/Qwen3-TTS-12Hz-1.7B-CustomVoice-4bit"
                )
                self.is_ready = True
                logger.info("âœ… æµå¼APIå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                raise

# å…¨å±€ä¸Šä¸‹æ–‡
voice_context = VoiceContext()

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨åˆå§‹åŒ–"""
    await voice_context.initialize()

@app.get("/")
async def root():
    return {
        "message": "CineCast Streaming TTS API - Production Ready",
        "status": "running",
        "ready": voice_context.is_ready
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "ready": voice_context.is_ready,
        "current_voice": voice_context.current_voice
    }

@app.get("/voices")
async def list_voices():
    """åˆ—å‡ºå¯ç”¨éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    preset_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
    return {
        "preset_voices": preset_voices,
        "current_voice": voice_context.current_voice
    }

@app.post("/set_voice")
async def set_voice(voice_name: str = Form(...)):
    """è®¾ç½®å½“å‰éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    try:
        # éªŒè¯éŸ³è‰²åç§°
        valid_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
        if voice_name.lower() not in valid_voices:
            return {"error": f"Invalid voice name. Valid options: {valid_voices}"}
        
        voice_context.current_voice = voice_name.lower()
        logger.info(f"âœ… éŸ³è‰²å·²è®¾ç½®ä¸º: {voice_context.current_voice}")
        
        return {
            "status": "success",
            "voice_name": voice_context.current_voice
        }
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®éŸ³è‰²å¤±è´¥: {e}")
        return {"error": str(e)}

def generate_mp3_chunks(text: str, voice_name: str):
    """ç”ŸæˆMP3éŸ³é¢‘å—çš„ç”Ÿæˆå™¨å‡½æ•°ï¼ˆè§£å†³WAVå¤´éƒ¨å†—ä½™é—®é¢˜ï¼‰"""
    if not voice_context.is_ready:
        raise RuntimeError("Service not ready")
    
    try:
        # ç›´æ¥ä½¿ç”¨å·²éªŒè¯çš„å·¥ä½œæ–¹æ³•
        render_engine = voice_context.engine._ensure_render_engine()
        
        # å‡†å¤‡voiceé…ç½®
        voice_cfg = {
            "mode": "preset",
            "voice": voice_name
        }
        
        # æ–‡æœ¬é¢„å¤„ç† - ç®€å•æŒ‰å¥å·åˆ†å‰²
        sentences = [s.strip() for s in text.split('ã€‚') if s.strip()]
        if not sentences[-1].endswith(('ã€‚', '.', '!', '?', 'ï¼', 'ï¼Ÿ')):
            sentences[-1] += 'ã€‚'
        
        logger.info(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {len(sentences)} ä¸ªå¥å­")
        
        for i, sentence in enumerate(sentences):
            if not sentence.strip():
                continue
                
            logger.info(f"ğŸµ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{len(sentences)} å¥: {sentence[:20]}...")
            
            # ç›´æ¥è°ƒç”¨æ¨¡å‹ç”Ÿæˆ
            render_engine._load_mode("preset")
            results = list(render_engine.model.generate(text=sentence, voice=voice_name))
            
            if results:
                # å¤„ç†éŸ³é¢‘æ•°æ®
                audio_array = results[0].audio
                mx.eval(audio_array)
                audio_data = np.array(audio_array)
                
                # å°†PCMè½¬æ¢ä¸ºMP3å¸§ï¼ˆè§£å†³WAVå¤´éƒ¨å†—ä½™é—®é¢˜ï¼‰
                audio_segment = AudioSegment(
                    (audio_data * 32767).astype(np.int16).tobytes(),
                    frame_rate=24000, sample_width=2, channels=1
                )
                
                # å¯¼å‡ºä¸ºMP3å­—èŠ‚ï¼Œä¸å¸¦ID3æ ‡ç­¾ä»¥å‡å°‘å¼€é”€
                mp3_buf = io.BytesIO()
                audio_segment.export(mp3_buf, format="mp3", parameters=["-write_xing", "0"])
                mp3_bytes = mp3_buf.getvalue()
                
                logger.info(f"âœ… ç¬¬ {i+1} å¥MP3ç”Ÿæˆå®Œæˆ ({len(mp3_bytes)} bytes)")
                yield mp3_bytes
                
                # æ¸…ç†æ˜¾å­˜
                mx.metal.clear_cache()
                    
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        raise

@app.post("/v1/audio/speech")
async def openai_compatible_tts(request: OpenAITTSRequest):
    """ç¬¦åˆOpenAIæ ‡å‡†çš„æµå¼TTSæ¥å£"""
    if not request.input.strip():
        raise HTTPException(status_code=400, detail="Input text is required")
    
    logger.info(f"ğŸ§ OpenAIå…¼å®¹TTSè¯·æ±‚: {request.input[:50]}... ä½¿ç”¨éŸ³è‰²: {request.voice}")
    
    return StreamingResponse(
        generate_mp3_chunks(request.input, request.voice),
        media_type="audio/mpeg",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

@app.get("/read_stream")
async def read_stream(text: str, voice: str = "aiden"):
    """æµå¼æœ—è¯»APIï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    if len(text) > 1000:  # é™åˆ¶é•¿åº¦
        return {"error": "Text too long (max 1000 characters)"}
    
    # ä½¿ç”¨å½“å‰è®¾ç½®çš„éŸ³è‰²æˆ–æŒ‡å®šéŸ³è‰²
    voice_name = voice_context.current_voice if voice == "aiden" else voice
    
    logger.info(f"ğŸ“– å¼€å§‹æµå¼æœ—è¯»: {text[:50]}... ä½¿ç”¨éŸ³è‰²: {voice_name}")
    
    return StreamingResponse(
        generate_mp3_chunks(text, voice_name),
        media_type="audio/mpeg",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

@app.post("/generate_batch")
async def generate_batch(request: dict):
    """æ‰¹é‡ç”ŸæˆAPIï¼ˆéæµå¼ï¼‰"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    text = request.get("text", "")
    voice_name = request.get("voice", voice_context.current_voice)
    
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    try:
        # ç›´æ¥ç”Ÿæˆå®Œæ•´éŸ³é¢‘
        render_engine = voice_context.engine._ensure_render_engine()
        render_engine._load_mode("preset")
        results = list(render_engine.model.generate(text=text, voice=voice_name))
        
        if results:
            audio_array = results[0].audio
            mx.eval(audio_array)
            audio_data = np.array(audio_array)
            
            # è½¬æ¢ä¸ºå­—èŠ‚æµ
            audio_buffer = io.BytesIO()
            sf.write(audio_buffer, audio_data, 24000, format='WAV')
            audio_bytes = audio_buffer.getvalue()
            
            return StreamingResponse(
                io.BytesIO(audio_bytes),
                media_type="audio/wav",
                headers={"Content-Disposition": "attachment; filename=tts_output.wav"}
            )
        else:
            return {"error": "Failed to generate audio"}
            
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ CineCast æµå¼ TTS API (ç”Ÿäº§å°±ç»ªç‰ˆ)...")
    print("ğŸ“ æœåŠ¡åœ°å€: http://localhost:8000")
    print("ğŸ“Š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ¥ å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print("ğŸ¤ éŸ³è‰²åˆ—è¡¨: http://localhost:8000/voices")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 50)
    
    uvicorn.run(
        "stream_api_production:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )