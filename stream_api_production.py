#!/usr/bin/env python3
"""
CineCast æµå¼API - æœ€ç»ˆæˆåŠŸç‰ˆæœ¬
åŸºäºå·²éªŒè¯çš„å·¥ä½œæ–¹æ³•å®ç°
"""

import sys
import os
from pathlib import Path

# ä½¿ç”¨ç›¸å¯¹è·¯å¾„é¿å…ç¡¬ç¼–ç 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import mlx.core as mx
import numpy as np
import soundfile as sf
import io
import logging
import time
import re
import asyncio  # ğŸš¨ æ–°å¢ï¼šç”¨äºå¼‚æ­¥çº¿ç¨‹ç®¡æ§
import warnings

warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", module="tiktoken")

from pydub import AudioSegment
import numpy as np
import mlx.core as mx

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import Response  # ğŸš¨ æ›¿æ¢ StreamingResponse

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from modules.mlx_tts_engine import CinecastMLXEngine as MLXTTSEngine
from modules.asset_manager import AssetManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="CineCast Streaming TTS API - Production Ready")

# =====================================================================
# ğŸŒŸ ä¿®å¤ä¸€ï¼šæ— ç¼é›†æˆåŸæœ‰ Gradio WebUIï¼Œå…±ç”¨æ¨¡å‹ä¸æ˜¾å­˜
# =====================================================================
try:
    import gradio as gr
    import traceback  # ğŸš¨ æ–°å¢å¯¼å…¥ç”¨äºæ‰“å°è¯¦ç»†é”™è¯¯
    
    # æ‹¦æˆªæ—§ç‰ˆç½‘é¡µä¸­çš„ launch é˜²æ­¢é˜»å¡
    _original_launch = gr.Blocks.launch
    gr.Blocks.launch = lambda self, *args, **kwargs: None
    
    logger.info("æ­£åœ¨å°è¯•å¯¼å…¥æ—§ç‰ˆ webui...")
    import webui  # ğŸš¨ å¦‚æœ webui.py é‡Œé¢è¿˜æœ‰è¯­æ³•é”™è¯¯ï¼Œè¿™é‡Œå°±ä¼šæŠ›å‡ºå¼‚å¸¸
    logger.info(f"webuiæ¨¡å—å¯¼å…¥æˆåŠŸï¼Œå¯ç”¨å±æ€§: {[attr for attr in dir(webui) if not attr.startswith('_')][:10]}")
    
    gr.Blocks.launch = _original_launch # æ¢å¤åŸæ–¹æ³•
    
    # åŠ¨æ€å¯»æ‰¾å®ä¾‹åç§°ï¼ˆå…¼å®¹ demo, app, interface ç­‰å¸¸è§å‘½åï¼‰
    gradio_app_instance = None
    logger.info("å¼€å§‹æœç´¢Gradioå®ä¾‹...")
    if hasattr(webui, 'demo'):
        gradio_app_instance = webui.demo
        logger.info("æ‰¾åˆ°demoå®ä¾‹")
    elif hasattr(webui, 'app') and isinstance(webui.app, gr.Blocks):
        gradio_app_instance = webui.app
        logger.info("æ‰¾åˆ°appå®ä¾‹")
    elif hasattr(webui, 'interface'):
        gradio_app_instance = webui.interface
        logger.info("æ‰¾åˆ°interfaceå®ä¾‹")
    elif hasattr(webui, 'ui') and isinstance(webui.ui, gr.Blocks):
        gradio_app_instance = webui.ui
        logger.info("æ‰¾åˆ°uiå®ä¾‹")
    elif hasattr(webui, 'stream_ui') and isinstance(webui.stream_ui, gr.Blocks):
        gradio_app_instance = webui.stream_ui
        logger.info("æ‰¾åˆ°stream_uiå®ä¾‹")
    else:
        logger.warning("æœªæ‰¾åˆ°ä»»ä½•Gradioå®ä¾‹")
        logger.info(f"webuiæ¨¡å—ä¸­çš„Blockså¯¹è±¡: {[attr for attr in dir(webui) if isinstance(getattr(webui, attr, None), gr.Blocks)]}")
        
    if gradio_app_instance:
        app = gr.mount_gradio_app(app, gradio_app_instance, path="/webui")
        logger.info("âœ… åŸæœ‰ Cinecast ç½‘é¡µç«¯å·²æˆåŠŸæŒ‚è½½ï¼è¯·è®¿é—® http://localhost:8888/webui/ (æ³¨æ„æœ«å°¾çš„æ–œæ )")
    else:
        logger.warning("âš ï¸ æˆåŠŸå¯¼å…¥ webui.pyï¼Œä½†åœ¨é‡Œé¢æ²¡æœ‰æ‰¾åˆ°åä¸º demo / app çš„ Gradio å®ä¾‹ã€‚")
        
except Exception as e:
    logger.error(f"âŒ æŒ‚è½½åŸæœ‰ç½‘é¡µç«¯å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
    # ğŸš¨ æ‰“å°å®Œæ•´çš„æŠ¥é”™å †æ ˆï¼Œå¸®æˆ‘ä»¬å‡†ç¡®å®šä½ webui.py é‡Œé¢è¿˜å‰©å“ªä¸ªæ¯’ç˜¤ï¼
    logger.error(traceback.format_exc())

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI TTS å…¼å®¹è¯·æ±‚æ¨¡å‹
class OpenAITTSRequest(BaseModel):
    model: str = "qwen3-tts"
    input: str
    voice: str = "aiden"
    response_format: str = "mp3"
    speed: float = 1.0

# å…¨å±€çŠ¶æ€
class VoiceContext:
    def __init__(self):
        # é»˜è®¤ä½¿ç”¨åŸç”Ÿé…ç½®æ–‡ä»¶ä¸­çš„æ—ç™½è®¾å®šï¼Œæˆ– aiden
        self.current_voice = "aiden" 
        self.engine = None
        self.asset_manager = None
        self.is_ready = False
    
    async def initialize(self):
        """åˆå§‹åŒ–å¼•æ“"""
        if not self.is_ready:
            try:
                self.asset_manager = AssetManager()
                # ä½¿ç”¨å·²éªŒè¯å¯ä»¥å·¥ä½œçš„æ¨¡å‹è·¯å¾„
                self.engine = MLXTTSEngine(
                    model_path="./models/Qwen3-TTS-12Hz-1.7B-CustomVoice-4bit"
                )
                self.is_ready = True
                logger.info("âœ… æµå¼APIå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                pass
    
    def get_voice_feature(self, voice_name: str):
        """ğŸŒŸ æ¶æ„å›å½’ï¼šåˆ©ç”¨åŸç”Ÿçš„ AssetManager è§£æç‰¹å¾ï¼Œå®Œç¾æ”¯æŒå…‹éš†"""
        if not self.is_ready:
            return {"mode": "preset", "voice": "aiden"}
            
        try:
            # AssetManager åŸæœ¬å°±èƒ½è¯†åˆ« .cinecast_role_voices.json é‡Œçš„å…‹éš†è®°å½•
            return self.asset_manager.load_role(voice_name)
        except Exception as e:
            logger.warning(f"éŸ³è‰² {voice_name} æœªåœ¨é¡¹ç›®ä¸­æ‰¾åˆ°ï¼Œå›é€€åˆ°é»˜è®¤: {e}")
            return {"mode": "preset", "voice": "aiden"}
            logger.error(f"âŒ å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

# å…¨å±€ä¸Šä¸‹æ–‡
voice_context = VoiceContext()

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨åˆå§‹åŒ–"""
    await voice_context.initialize()

@app.get("/")
async def root():
    return {
        "message": "CineCast Streaming TTS API - Production Ready",
        "status": "running",
        "ready": voice_context.is_ready
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "ready": voice_context.is_ready,
        "current_voice": voice_context.current_voice
    }

@app.get("/voices")
async def list_voices():
    """åˆ—å‡ºå¯ç”¨éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    preset_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
    return {
        "preset_voices": preset_voices,
        "current_voice": voice_context.current_voice
    }

@app.post("/set_voice")
async def set_voice(voice_name: str = Form(...)):
    """è®¾ç½®å½“å‰éŸ³è‰²"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    try:
        # éªŒè¯éŸ³è‰²åç§°
        valid_voices = ["aiden", "dylan", "ono_anna", "ryan", "sohee", "uncle_fu", "vivian", "eric", "serena"]
        if voice_name.lower() not in valid_voices:
            return {"error": f"Invalid voice name. Valid options: {valid_voices}"}
        
        voice_context.current_voice = voice_name.lower()
        logger.info(f"âœ… éŸ³è‰²å·²è®¾ç½®ä¸º: {voice_context.current_voice}")
        
        return {
            "status": "success",
            "voice_name": voice_context.current_voice
        }
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®éŸ³è‰²å¤±è´¥: {e}")
        return {"error": str(e)}



# =====================================================================
# ğŸŒŸ ä¿®å¤äºŒï¼šä¸“ä¸º Anxreader ç­‰é˜…è¯» App è®¾è®¡çš„å•å¤´æ•´æ®µå“åº”æ¶æ„
# =====================================================================
@app.post("/v1/audio/speech")
async def openai_compatible_tts(request: Request, body: OpenAITTSRequest):
    if not voice_context.is_ready:
        raise HTTPException(status_code=503, detail="TTS æœåŠ¡æœªå°±ç»ª")
    
    try:
        feature = voice_context.get_voice_feature(body.voice)
        
        # æš´åŠ›æ¸…æ´—ç‰¹æ®Šç¬¦å·
        safe_text = re.sub(r'[â€¦]+', 'ã€‚', body.input)
        safe_text = re.sub(r'\.{2,}', 'ã€‚', safe_text)
        safe_text = re.sub(r'[â€”]+', 'ï¼Œ', safe_text)
        safe_text = re.sub(r'[-]{2,}', 'ï¼Œ', safe_text)
        safe_text = re.sub(r'[~ï½]+', 'ã€‚', safe_text)
        safe_text = re.sub(r'\s+', ' ', safe_text).strip()
        
        sentences = [s.strip() for s in re.split(r'([ã€‚ï¼ï¼Ÿ!?])', safe_text) if s.strip()]
        merged_sentences = []
        for i in range(0, len(sentences)-1, 2):
            merged_sentences.append(sentences[i] + sentences[i+1])
        if len(sentences) % 2 != 0:
            merged_sentences.append(sentences[-1])
            
        logger.info(f"ğŸ§ æ”¶åˆ° App è¯·æ±‚ï¼Œåˆ‡åˆ†ä¸º {len(merged_sentences)} å¥ï¼Œä½¿ç”¨éŸ³è‰²: {feature['mode']}")
        
        all_audio_chunks = []
        
        for i, sentence in enumerate(merged_sentences):
            # ğŸš¨ æé€Ÿå¹¶å‘é˜²å¾¡ï¼šåœ¨ç”Ÿæˆæ¯ä¸€å¥è¯å‰ï¼Œæ£€æŸ¥ App æ˜¯å¦å·²ç»è·³æ®µæˆ–æ–­å¼€ï¼
            # è¿™æ ·å°±èƒ½åŠæ—¶åˆ¹è½¦é‡Šæ”¾ GPUï¼Œé˜²æ­¢å µæ­»åç»­çš„è¯·æ±‚ï¼
            if await request.is_disconnected():
                logger.warning(f"âš ï¸ App å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œç«‹å³ç»ˆæ­¢æœ¬æ®µå‰©ä½™ç”Ÿæˆï¼Œé‡Šæ”¾ GPU èµ„æºã€‚")
                return Response(status_code=499) # 499 Client Closed Request
                
            pure_text = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿï¼›ã€,.!?;:\'"()\s-]', '', sentence)
            if not pure_text:
                continue
                
            # å°† CPU/GPU è®¡ç®—æ”¾å…¥çº¿ç¨‹ï¼Œè®©å¼‚æ­¥äº‹ä»¶å¾ªç¯å¯ä»¥æ£€æµ‹åˆ°å®¢æˆ·ç«¯æ–­å¼€
            def generate_sync():
                return voice_context.engine.generate_with_feature(sentence, feature, language="zh")
                
            logger.info(f"ğŸµ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{len(merged_sentences)} å¥...")
            audio_data = await asyncio.to_thread(generate_sync)
            
            if audio_data is not None and audio_data.size > 0:
                all_audio_chunks.append(audio_data)

        if not all_audio_chunks:
            raise HTTPException(status_code=400, detail="ç”ŸæˆéŸ³é¢‘ä¸ºç©º")

        # ğŸš¨ æ ¸å¿ƒè§†å¬ä¿®å¤ï¼šå°†åˆ†å¥æ•°ç»„åœ¨å†…å­˜ä¸­æ— ç¼æ‹¼æ¥ï¼
        # æŠ›å¼ƒ yieldï¼Œä¸€æ¬¡æ€§è½¬ä¸ºä¸€ä¸ªå¸¦æœ‰å•ä¸€ MP3 å¤´çš„å®Œæ•´éŸ³é¢‘ã€‚
        # App æ’­æ”¾å™¨ä¼šæŠŠå®ƒå½“æˆä¸€é¦–æ­£å¸¸æ­Œæ›²å¹³æ»‘æ’­å®Œï¼Œå½»åº•è§£å†³åªè¯»ç¬¬ä¸€å¥å°±è·³è¿‡çš„é—®é¢˜ï¼
        final_audio = np.concatenate(all_audio_chunks)
        final_audio = np.clip(final_audio, -1.0, 1.0) # é˜²çˆ†éŸ³
        
        audio_segment = AudioSegment(
            (final_audio * 32767).astype(np.int16).tobytes(),
            frame_rate=24000, sample_width=2, channels=1
        )
        
        mp3_buf = io.BytesIO()
        audio_segment.export(mp3_buf, format="mp3", parameters=["-write_xing", "0", "-id3v2_version", "0"])
        
        logger.info(f"âœ… æ•´æ®µè½éŸ³é¢‘åˆæˆå®Œæ¯•ï¼Œå‘é€ç»™ App ({len(mp3_buf.getvalue())} bytes)")
        return Response(content=mp3_buf.getvalue(), media_type="audio/mpeg")
        
    except Exception as e:
        logger.error(f"âŒ API å“åº”å¼‚å¸¸: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/read_stream")
async def read_stream(text: str, voice: str = "aiden"):
    """æµå¼æœ—è¯»APIï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    if len(text) > 1000:  # é™åˆ¶é•¿åº¦
        return {"error": "Text too long (max 1000 characters)"}
    
    # ä½¿ç”¨å½“å‰è®¾ç½®çš„éŸ³è‰²æˆ–æŒ‡å®šéŸ³è‰²
    voice_name = voice_context.current_voice if voice == "aiden" else voice
    
    logger.info(f"ğŸ“– å¼€å§‹æµå¼æœ—è¯»: {text[:50]}... ä½¿ç”¨éŸ³è‰²: {voice_name}")
    
    return StreamingResponse(
        generate_mp3_chunks(text, voice_name),
        media_type="audio/mpeg",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )

@app.post("/generate_batch")
async def generate_batch(request: dict):
    """æ‰¹é‡ç”ŸæˆAPIï¼ˆéæµå¼ï¼‰"""
    if not voice_context.is_ready:
        return {"error": "Service not ready"}
    
    text = request.get("text", "")
    voice_name = request.get("voice", voice_context.current_voice)
    
    if not text.strip():
        return {"error": "Text cannot be empty"}
    
    try:
        # ç›´æ¥ç”Ÿæˆå®Œæ•´éŸ³é¢‘
        render_engine = voice_context.engine._ensure_render_engine()
        render_engine._load_mode("preset")
        results = list(render_engine.model.generate(text=text, voice=voice_name))
        
        if results:
            audio_array = results[0].audio
            mx.eval(audio_array)
            audio_data = np.array(audio_array)
            
            # è½¬æ¢ä¸ºå­—èŠ‚æµ
            audio_buffer = io.BytesIO()
            sf.write(audio_buffer, audio_data, 24000, format='WAV')
            audio_bytes = audio_buffer.getvalue()
            
            return StreamingResponse(
                io.BytesIO(audio_bytes),
                media_type="audio/wav",
                headers={"Content-Disposition": "attachment; filename=tts_output.wav"}
            )
        else:
            return {"error": "Failed to generate audio"}
            
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ CineCast æµå¼ TTS API (ç”Ÿäº§å°±ç»ªç‰ˆ)...")
    print("ğŸ“ æœåŠ¡åœ°å€: http://localhost:8888")
    print("ğŸ“Š APIæ–‡æ¡£: http://localhost:8888/docs")
    print("ğŸ¥ å¥åº·æ£€æŸ¥: http://localhost:8888/health")
    print("ğŸ¤ éŸ³è‰²åˆ—è¡¨: http://localhost:8888/voices")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 50)
    
    uvicorn.run(
        "stream_api_production:app",
        host="0.0.0.0",
        port=8888,
        reload=False,
        log_level="info"
    )